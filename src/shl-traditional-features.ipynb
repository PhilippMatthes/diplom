{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using traditional models and feature engineering to classify SHL timeseries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "location = 'shl-dataset/train/Hand/'\r\n",
    "\r\n",
    "acc_x = pd.read_csv(location + 'Acc_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_x Import Done')\r\n",
    "acc_y = pd.read_csv(location + 'Acc_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_y Import Done')\r\n",
    "acc_z = pd.read_csv(location + 'Acc_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_z Import Done')\r\n",
    "mag_x = pd.read_csv(location + 'Mag_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_x Import Done')\r\n",
    "mag_y = pd.read_csv(location + 'Mag_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_y Import Done')\r\n",
    "mag_z = pd.read_csv(location + 'Mag_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_z Import Done')\r\n",
    "gyr_x = pd.read_csv(location + 'Gyr_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_x Import Done')\r\n",
    "gyr_y = pd.read_csv(location + 'Gyr_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_y Import Done')\r\n",
    "gyr_z = pd.read_csv(location + 'Gyr_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_z Import Done')\r\n",
    "\r\n",
    "y = pd.read_csv(location + 'Label.txt', header=None, sep=' ').mode(axis=1).to_numpy().flatten()\r\n",
    "print('Label Import Done')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Label Import Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "from scipy import signal\r\n",
    "from scipy.special import entr\r\n",
    "\r\n",
    "\r\n",
    "def magnitude(x,y,z):\r\n",
    "  return np.sqrt(x**2 + y**2 + z**2)\r\n",
    "\r\n",
    "def entrop(pk,axis=0):\r\n",
    "     pk = pk / np.sum(pk, axis=axis, keepdims=True)\r\n",
    "     vec = entr(pk)\r\n",
    "     S = np.sum(vec, axis=axis)\r\n",
    "     return S\r\n",
    "\r\n",
    "def autocorr(x,axis=0):\r\n",
    "    result = np.correlate(x, x, mode='full')\r\n",
    "    return result[result.size // 2:]\r\n",
    "\r\n",
    "\r\n",
    "# Magnitude Calculation\r\n",
    "acc_MAG = magnitude(acc_x,acc_y,acc_z)\r\n",
    "mag_MAG = magnitude(mag_x,mag_y,mag_z)\r\n",
    "gyr_MAG = magnitude(gyr_x,gyr_y,gyr_z)\r\n",
    "\r\n",
    "# Statistical Feature Calculation\r\n",
    "acc_mean = np.mean(acc_MAG,axis=1)\r\n",
    "acc_std = np.std(acc_MAG,axis=1)\r\n",
    "acc_max = np.max(acc_MAG,axis=1)\r\n",
    "acc_min = np.min(acc_MAG,axis=1)\r\n",
    "mag_mean = np.mean(mag_MAG,axis=1)\r\n",
    "mag_std = np.std(mag_MAG,axis=1)\r\n",
    "mag_max = np.max(mag_MAG,axis=1)\r\n",
    "mag_min = np.min(mag_MAG,axis=1)\r\n",
    "gyr_mean = np.mean(gyr_MAG,axis=1)\r\n",
    "gyr_std = np.std(gyr_MAG,axis=1)\r\n",
    "gyr_max = np.max(gyr_MAG,axis=1)\r\n",
    "gyr_min = np.min(gyr_MAG,axis=1)\r\n",
    "\r\n",
    "# Frequency Domain Feature Calculation\r\n",
    "fs = 100\r\n",
    "acc_FREQ,acc_PSD = signal.welch(acc_MAG,fs,nperseg=500,axis=1)\r\n",
    "mag_FREQ,mag_PSD = signal.welch(mag_MAG,fs,nperseg=500,axis=1)\r\n",
    "\r\n",
    "# Max PSD value\r\n",
    "acc_PSDmax = np.max(acc_PSD,axis=1)\r\n",
    "mag_PSDmax = np.max(mag_PSD,axis=1)\r\n",
    "\r\n",
    "# Frequency Entropy\r\n",
    "acc_entropy = entrop(acc_PSD,axis=1)\r\n",
    "mag_entropy = entrop(mag_PSD,axis=1)\r\n",
    "\r\n",
    "# Frequency Center\r\n",
    "acc_fc = np.sum((acc_FREQ*acc_PSD),axis=1) / np.sum(acc_PSD,axis=1)\r\n",
    "mag_fc = np.sum((mag_FREQ*mag_PSD),axis=1) / np.sum(mag_PSD,axis=1)\r\n",
    "\r\n",
    "# Autocorrelation Calculation\r\n",
    "acc_acr = np.apply_along_axis(autocorr,1,acc_MAG)\r\n",
    "print(acc_acr.shape)\r\n",
    "\r\n",
    "acc_features = np.stack((acc_mean,acc_std,acc_max,acc_min,acc_PSDmax,acc_entropy,acc_fc),axis=1)\r\n",
    "mag_features = np.stack((mag_mean,mag_std,mag_max,mag_min,mag_PSDmax,mag_entropy,mag_fc),axis=1)\r\n",
    "gyr_features = np.stack((gyr_mean,gyr_std,gyr_max,gyr_min),axis=1)\r\n",
    "\r\n",
    "X = np.concatenate([acc_features,mag_features,gyr_features],axis=1)\r\n",
    "\r\n",
    "print(\"X shape: \",X.shape)\r\n",
    "print(\"y shape: \",y.shape)\r\n",
    "\r\n",
    "print(\"Feature Extraction Done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(196072, 500)\n",
      "X shape:  (196072, 18)\n",
      "y shape:  (196072,)\n",
      "Feature Extraction Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Code source: Gaël Varoquaux\r\n",
    "#              Andreas Müller\r\n",
    "# Modified for documentation by Jaques Grobler\r\n",
    "# License: BSD 3 clause\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
    "from sklearn.gaussian_process.kernels import RBF\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\r\n",
    "\r\n",
    "names = [\r\n",
    "    \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\r\n",
    "    \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\r\n",
    "    \"Naive Bayes\", \"QDA\"\r\n",
    "]\r\n",
    "\r\n",
    "classifiers = [\r\n",
    "    KNeighborsClassifier(3),\r\n",
    "    SVC(kernel=\"linear\", C=0.025),\r\n",
    "    SVC(gamma=2, C=1),\r\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\r\n",
    "    DecisionTreeClassifier(max_depth=5),\r\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\r\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\r\n",
    "    AdaBoostClassifier(),\r\n",
    "    GaussianNB(),\r\n",
    "    QuadraticDiscriminantAnalysis()\r\n",
    "]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=1337)\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "X_train = scaler.fit_transform(X_train)\r\n",
    "X_test = scaler.transform(X_test)\r\n",
    "\r\n",
    "accuracies = []\r\n",
    "for model_name, model in tqdm(zip(names, classifiers)):\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = accuracy_score(y_test, y_pred)\r\n",
    "    accuracies.append(accuracy)\r\n",
    "    print(f'Acc of {model_name}: {accuracy}')\r\n",
    "\r\n",
    "plt.bar(names, accuracies)\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46323b457e08462fa50a014b9568e2ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc of Nearest Neighbors: 0.6532053659742829\n",
      "Acc of Linear SVM: 0.6275500741839762\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### License for [parts of this code](https://github.com/farhanfuadabir/SHL-2020/blob/master/LICENSE)\r\n",
    "\r\n",
    "MIT License\r\n",
    "\r\n",
    "Copyright (c) 2020 Farhan Fuad\r\n",
    "\r\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\r\n",
    "of this software and associated documentation files (the 'Software'), to deal\r\n",
    "in the Software without restriction, including without limitation the rights\r\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n",
    "copies of the Software, and to permit persons to whom the Software is\r\n",
    "furnished to do so, subject to the following conditions:\r\n",
    "\r\n",
    "The above copyright notice and this permission notice shall be included in all\r\n",
    "copies or substantial portions of the Software.\r\n",
    "\r\n",
    "THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n",
    "SOFTWARE."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "097461492b3eec731f5f36facfab7d83b93854d821dc66544771e2db489a1966"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}