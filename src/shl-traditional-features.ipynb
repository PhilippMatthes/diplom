{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using traditional models and feature engineering to classify SHL timeseries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "from tools.dataset import load_zipped_shl_dataset\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "\r\n",
    "# We are going to train the models on a small subsample of the whole dataset\r\n",
    "# The assumption behind this is that traditional models require significantly\r\n",
    "# less amount of training data\r\n",
    "dataset = load_zipped_shl_dataset(pathlib.Path('shl-dataset/challenge-2019-train_torso.zip'), tqdm=tqdm)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Extracting shl-dataset\\challenge-2019-train_torso.zip:   0%|          | 0/22 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7a9a6e2883d4aadbcd9ed3d3be3be8c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Acc_mag Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Mag_mag Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Gyr_mag Import Done\n",
      "Labels Import Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.preprocessing import PowerTransformer\r\n",
    "\r\n",
    "acc_scaler = PowerTransformer()\r\n",
    "mag_scaler = PowerTransformer()\r\n",
    "gyr_scaler = PowerTransformer()\r\n",
    "acc_mag_scaled = acc_scaler.fit_transform(dataset.acc_mag)\r\n",
    "mag_mag_scaled = mag_scaler.fit_transform(dataset.mag_mag)\r\n",
    "gyr_mag_scaled = gyr_scaler.fit_transform(dataset.gyr_mag)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "from scipy import signal\r\n",
    "from scipy.special import entr\r\n",
    "\r\n",
    "\r\n",
    "def magnitude(x,y,z):\r\n",
    "  return np.sqrt(x**2 + y**2 + z**2)\r\n",
    "\r\n",
    "def entrop(pk,axis=0):\r\n",
    "     pk = pk / np.sum(pk, axis=axis, keepdims=True)\r\n",
    "     vec = entr(pk)\r\n",
    "     S = np.sum(vec, axis=axis)\r\n",
    "     return S\r\n",
    "\r\n",
    "def autocorr(x,axis=0):\r\n",
    "    result = np.correlate(x, x, mode='full')\r\n",
    "    return result[result.size // 2:]\r\n",
    "\r\n",
    "# Statistical Feature Calculation\r\n",
    "acc_mean = np.mean(acc_mag_scaled,axis=1)\r\n",
    "acc_std = np.std(acc_mag_scaled,axis=1)\r\n",
    "acc_max = np.max(acc_mag_scaled,axis=1)\r\n",
    "acc_min = np.min(acc_mag_scaled,axis=1)\r\n",
    "\r\n",
    "mag_mean = np.mean(mag_mag_scaled,axis=1)\r\n",
    "mag_std = np.std(mag_mag_scaled,axis=1)\r\n",
    "mag_max = np.max(mag_mag_scaled,axis=1)\r\n",
    "mag_min = np.min(mag_mag_scaled,axis=1)\r\n",
    "\r\n",
    "gyr_mean = np.mean(gyr_mag_scaled,axis=1)\r\n",
    "gyr_std = np.std(gyr_mag_scaled,axis=1)\r\n",
    "gyr_max = np.max(gyr_mag_scaled,axis=1)\r\n",
    "gyr_min = np.min(gyr_mag_scaled,axis=1)\r\n",
    "\r\n",
    "# Frequency Domain Feature Calculation\r\n",
    "fs = 100\r\n",
    "acc_FREQ,acc_PSD = signal.welch(acc_mag_scaled,fs,nperseg=500,axis=1)\r\n",
    "mag_FREQ,mag_PSD = signal.welch(mag_mag_scaled,fs,nperseg=500,axis=1)\r\n",
    "gyr_FREQ,gyr_PSD = signal.welch(gyr_mag_scaled,fs,nperseg=500,axis=1)\r\n",
    "\r\n",
    "# Max PSD value\r\n",
    "acc_PSDmax = np.max(acc_PSD,axis=1)\r\n",
    "mag_PSDmax = np.max(mag_PSD,axis=1)\r\n",
    "gyr_PSDmax = np.max(gyr_PSD,axis=1)\r\n",
    "acc_PSDmin = np.min(acc_PSD,axis=1)\r\n",
    "mag_PSDmin = np.min(mag_PSD,axis=1)\r\n",
    "gyr_PSDmin = np.min(gyr_PSD,axis=1)\r\n",
    "\r\n",
    "# Frequency Entropy\r\n",
    "acc_entropy = entrop(acc_PSD,axis=1)\r\n",
    "mag_entropy = entrop(mag_PSD,axis=1)\r\n",
    "gyr_entropy = entrop(gyr_PSD,axis=1)\r\n",
    "\r\n",
    "# Frequency Center\r\n",
    "acc_fc = np.sum((acc_FREQ*acc_PSD),axis=1) / np.sum(acc_PSD,axis=1)\r\n",
    "mag_fc = np.sum((mag_FREQ*mag_PSD),axis=1) / np.sum(mag_PSD,axis=1)\r\n",
    "gyr_fc = np.sum((gyr_FREQ*gyr_PSD),axis=1) / np.sum(gyr_PSD,axis=1)\r\n",
    "\r\n",
    "# Autocorrelation Calculation\r\n",
    "acc_acr = np.apply_along_axis(autocorr,1,acc_mag_scaled)\r\n",
    "mag_acr = np.apply_along_axis(autocorr,1,mag_mag_scaled)\r\n",
    "gyr_acr = np.apply_along_axis(autocorr,1,gyr_mag_scaled)\r\n",
    "\r\n",
    "acc_features = np.stack((acc_mean,acc_std,acc_max,acc_min,acc_PSDmax,acc_PSDmin,acc_entropy,acc_fc),axis=1)\r\n",
    "mag_features = np.stack((mag_mean,mag_std,mag_max,mag_min,mag_PSDmax,mag_PSDmin,mag_entropy,mag_fc),axis=1)\r\n",
    "gyr_features = np.stack((gyr_mean,gyr_std,gyr_max,gyr_min,gyr_PSDmax,gyr_PSDmin,gyr_entropy,gyr_fc),axis=1)\r\n",
    "\r\n",
    "X = np.concatenate([acc_features,mag_features,gyr_features],axis=1)\r\n",
    "y = dataset.labels\r\n",
    "\r\n",
    "print(\"X shape: \",X.shape)\r\n",
    "print(\"y shape: \",y.shape)\r\n",
    "\r\n",
    "print(\"Feature Extraction Done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape:  (196072, 24)\n",
      "y shape:  (196072,)\n",
      "Feature Extraction Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Install imblearn, a package with functionalities to balance our dataset\r\n",
    "import sys\r\n",
    "!{sys.executable} -m pip install imbalanced-learn"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\anwender\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\anwender\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from imbalanced-learn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\anwender\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from imbalanced-learn) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\anwender\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\anwender\\appdata\\roaming\\python\\python36\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anwender\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You are using pip version 18.1, however version 21.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Weight dataset classes using SMOTE\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "\r\n",
    "oversampler = SMOTE()\r\n",
    "X, y = oversampler.fit_resample(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Check that classes are now balanced\r\n",
    "from sklearn.utils.class_weight import compute_class_weight\r\n",
    "print(compute_class_weight('balanced', classes=np.unique(y), y=y), y.shape, X.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1.] (253864,) (253864, 24)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import time\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
    "from sklearn.gaussian_process.kernels import RBF\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\r\n",
    "\r\n",
    "train_set_size = 5000 # Train on smaller subset of the training data\r\n",
    "\r\n",
    "names = [\r\n",
    "    \"Nearest Neighbors\", \"Linear SVM\", \"Gaussian Process\",\r\n",
    "    \"Decision Tree\", \"Random Forest\", \"MLP\", \"AdaBoost\",\r\n",
    "    \"Naive Bayes\", \"QDA\"\r\n",
    "]\r\n",
    "\r\n",
    "classifiers = [\r\n",
    "    KNeighborsClassifier(3),\r\n",
    "    SVC(kernel=\"linear\", C=0.025),\r\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\r\n",
    "    DecisionTreeClassifier(max_depth=5),\r\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\r\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\r\n",
    "    AdaBoostClassifier(),\r\n",
    "    GaussianNB(),\r\n",
    "    QuadraticDiscriminantAnalysis()\r\n",
    "]\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=1337)\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "X_train = scaler.fit_transform(X_train)\r\n",
    "X_test = scaler.transform(X_test)\r\n",
    "\r\n",
    "accuracies = []\r\n",
    "for model_name, model in zip(names, classifiers):\r\n",
    "    start_time = time.time()\r\n",
    "    model.fit(X_train[:train_set_size], y_train[:train_set_size])\r\n",
    "    print(f'Training of {model_name} took {time.time() - start_time}')\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = accuracy_score(y_test, y_pred)\r\n",
    "    accuracies.append(accuracy)\r\n",
    "    print(f'Acc of {model_name}: {accuracy}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training of Nearest Neighbors took 0.002001047134399414\n",
      "Acc of Nearest Neighbors: 0.7159687738731857\n",
      "Training of Linear SVM took 0.3549995422363281\n",
      "Acc of Linear SVM: 0.7242766424751719\n",
      "Training of Gaussian Process took 7295.569003582001\n",
      "Acc of Gaussian Process: 0.7749355423987777\n",
      "Training of Decision Tree took 0.1380002498626709\n",
      "Acc of Decision Tree: 0.6909735485103132\n",
      "Training of Random Forest took 0.1379992961883545\n",
      "Acc of Random Forest: 0.691248090145149\n",
      "Training of MLP took 5.168997526168823\n",
      "Acc of MLP: 0.761673987776929\n",
      "Training of AdaBoost took 0.7510027885437012\n",
      "Acc of AdaBoost: 0.4831335943468296\n",
      "Training of Naive Bayes took 0.003994941711425781\n",
      "Acc of Naive Bayes: 0.6426900305576776\n",
      "Training of QDA took 0.06499695777893066\n",
      "Acc of QDA: 0.6734625668449198\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "097461492b3eec731f5f36facfab7d83b93854d821dc66544771e2db489a1966"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}