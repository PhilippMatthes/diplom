{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### License for [parts of the following code](https://github.com/farhanfuadabir/SHL-2020/blob/master/LICENSE)\r\n",
    "\r\n",
    "MIT License\r\n",
    "\r\n",
    "Copyright (c) 2020 Farhan Fuad\r\n",
    "\r\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\r\n",
    "of this software and associated documentation files (the 'Software'), to deal\r\n",
    "in the Software without restriction, including without limitation the rights\r\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n",
    "copies of the Software, and to permit persons to whom the Software is\r\n",
    "furnished to do so, subject to the following conditions:\r\n",
    "\r\n",
    "The above copyright notice and this permission notice shall be included in all\r\n",
    "copies or substantial portions of the Software.\r\n",
    "\r\n",
    "THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n",
    "SOFTWARE."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "location = 'shl-dataset/train/Hand/'\r\n",
    "\r\n",
    "acc_x = pd.read_csv(location + 'Acc_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_x Import Done')\r\n",
    "acc_y = pd.read_csv(location + 'Acc_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_y Import Done')\r\n",
    "acc_z = pd.read_csv(location + 'Acc_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Acc_z Import Done')\r\n",
    "mag_x = pd.read_csv(location + 'Mag_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_x Import Done')\r\n",
    "mag_y = pd.read_csv(location + 'Mag_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_y Import Done')\r\n",
    "mag_z = pd.read_csv(location + 'Mag_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Mag_z Import Done')\r\n",
    "gyr_x = pd.read_csv(location + 'Gyr_x.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_x Import Done')\r\n",
    "gyr_y = pd.read_csv(location + 'Gyr_y.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_y Import Done')\r\n",
    "gyr_z = pd.read_csv(location + 'Gyr_z.txt', header=None, sep=' ').to_numpy()\r\n",
    "print('Gyr_z Import Done')\r\n",
    "\r\n",
    "labels = pd.read_csv(location + 'Label.txt', header=None, sep=' ').mode(axis=1).to_numpy().flatten()\r\n",
    "print('Label Import Done')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Label Import Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# Select the acceleration magnitude as the main feature\r\n",
    "acc = np.sqrt(acc_x**2 + acc_y**2 + acc_z**2)\r\n",
    "\r\n",
    "print(acc.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(196072, 500)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "\r\n",
    "X = np.resize(acc, (acc.shape[0], 256)) # Use n samples for each label\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "X = scaler.fit_transform(X)\r\n",
    "\r\n",
    "y = labels\r\n",
    "\r\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\r\n",
    "\r\n",
    "idx = np.random.permutation(len(X))\r\n",
    "X = X[idx]\r\n",
    "y = y[idx]\r\n",
    "\r\n",
    "print(X.shape, y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(196072, 256, 1) (196072,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "# Check that we can use our GPU, to not wait forever during training\r\n",
    "from tensorflow.python.client import device_lib\r\n",
    "device_lib.list_local_devices()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 17812630953663744454,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 3215029044\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 11882337018855110940\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 770, pci bus id: 0000:01:00.0, compute capability: 3.0\"]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def make_model():\r\n",
    "    input_layer = keras.layers.Input((256, 1))\r\n",
    "\r\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\r\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\r\n",
    "    conv1 = keras.layers.ReLU()(conv1)\r\n",
    "\r\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\r\n",
    "    conv2 = keras.layers.BatchNormalization()(conv2)\r\n",
    "    conv2 = keras.layers.ReLU()(conv2)\r\n",
    "\r\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\r\n",
    "    conv3 = keras.layers.BatchNormalization()(conv3)\r\n",
    "    conv3 = keras.layers.ReLU()(conv3)\r\n",
    "\r\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv3)\r\n",
    "\r\n",
    "    output_layer = keras.layers.Dense(9, activation=\"softmax\")(gap)\r\n",
    "\r\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\r\n",
    "\r\n",
    "model = make_model()\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 256, 64)           256       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 256, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 256, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256, 64)           256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 256, 64)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 585       \n",
      "=================================================================\n",
      "Total params: 26,313\n",
      "Trainable params: 25,929\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Model training\r\n",
    "\r\n",
    "epochs = 200\r\n",
    "batch_size = 32\r\n",
    "\r\n",
    "callbacks = [\r\n",
    "    keras.callbacks.ModelCheckpoint(\r\n",
    "        'shl-model.h5', save_best_only=True, monitor='val_loss'\r\n",
    "    ),\r\n",
    "    keras.callbacks.ReduceLROnPlateau(\r\n",
    "        monitor='val_loss', factor=0.5, patience=20, min_lr=0.0001\r\n",
    "    ),\r\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, verbose=1),\r\n",
    "]\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    optimizer='adam',\r\n",
    "    loss='sparse_categorical_crossentropy',\r\n",
    "    metrics=['sparse_categorical_accuracy'],\r\n",
    ")\r\n",
    "\r\n",
    "history = model.fit(\r\n",
    "    X, \r\n",
    "    y,\r\n",
    "    epochs=epochs, \r\n",
    "    batch_size=batch_size, \r\n",
    "    callbacks=callbacks, \r\n",
    "    validation_split=0.2, \r\n",
    "    verbose=1\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 156857 samples, validate on 39215 samples\n",
      "Epoch 1/200\n",
      "156857/156857 [==============================] - 58s 369us/step - loss: 1.9537 - sparse_categorical_accuracy: 0.2275 - val_loss: 1.9534 - val_sparse_categorical_accuracy: 0.2277\n",
      "Epoch 2/200\n",
      "156857/156857 [==============================] - 56s 359us/step - loss: 1.9484 - sparse_categorical_accuracy: 0.2298 - val_loss: 1.9521 - val_sparse_categorical_accuracy: 0.2250\n",
      "Epoch 3/200\n",
      "156857/156857 [==============================] - 56s 357us/step - loss: 1.9463 - sparse_categorical_accuracy: 0.2310 - val_loss: 1.9464 - val_sparse_categorical_accuracy: 0.2291\n",
      "Epoch 4/200\n",
      "156857/156857 [==============================] - 56s 358us/step - loss: 1.9438 - sparse_categorical_accuracy: 0.2319 - val_loss: 1.9496 - val_sparse_categorical_accuracy: 0.2252\n",
      "Epoch 5/200\n",
      "156857/156857 [==============================] - 56s 358us/step - loss: 1.9412 - sparse_categorical_accuracy: 0.2340 - val_loss: 1.9448 - val_sparse_categorical_accuracy: 0.2356\n",
      "Epoch 6/200\n",
      "156857/156857 [==============================] - 56s 358us/step - loss: 1.9397 - sparse_categorical_accuracy: 0.2347 - val_loss: 1.9542 - val_sparse_categorical_accuracy: 0.2229\n",
      "Epoch 7/200\n",
      "156857/156857 [==============================] - 56s 359us/step - loss: 1.9375 - sparse_categorical_accuracy: 0.2356 - val_loss: 1.9495 - val_sparse_categorical_accuracy: 0.2242\n",
      "Epoch 8/200\n",
      " 26272/156857 [====>.........................] - ETA: 43s - loss: 1.9377 - sparse_categorical_accuracy: 0.2318"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fb387805d23f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "097461492b3eec731f5f36facfab7d83b93854d821dc66544771e2db489a1966"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}