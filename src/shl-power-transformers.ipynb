{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fit and configure scalers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get needed auxiliary files for colab\r\n",
    "!git clone https://github.com/philippmatthes/diplom\r\n",
    "%cd /content/diplom/src\r\n",
    "!mkdir shl-dataset\r\n",
    "!wget -nc -O shl-dataset/challenge-2019-train_torso.zip http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_torso.zip\r\n",
    "!wget -nc -O shl-dataset/challenge-2019-train_bag.zip http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_bag.zip\r\n",
    "!wget -nc -O shl-dataset/challenge-2019-train_hips.zip http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_hips.zip\r\n",
    "!wget -nc -O shl-dataset/challenge-2020-train_hand.zip http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2020/challenge-2020-train_hand.zip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Switch to src dir and select tensorflow\r\n",
    "%cd /content/diplom/src\r\n",
    "%tensorflow_version 2.x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.preprocessing import PowerTransformer\r\n",
    "\r\n",
    "acc_scaler = PowerTransformer()\r\n",
    "mag_scaler = PowerTransformer()\r\n",
    "gyr_scaler = PowerTransformer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pathlib import Path\r\n",
    "\r\n",
    "DATASET_DIRS = [\r\n",
    "    Path('shl-dataset/challenge-2019-train_torso.zip'),\r\n",
    "    Path('shl-dataset/challenge-2019-train_bag.zip'),\r\n",
    "    Path('shl-dataset/challenge-2019-train_hips.zip'),\r\n",
    "    Path('shl-dataset/challenge-2020-train_hand.zip'),\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load the dataset\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "\r\n",
    "from tools.dataset import load_zipped_shl_dataset\r\n",
    "\r\n",
    "acc_mag_conc = None\r\n",
    "mag_mag_conc = None\r\n",
    "gyr_mag_conc = None\r\n",
    "\r\n",
    "for dataset_dir in DATASET_DIRS:\r\n",
    "    # Load dataset from zip file into temporary directory\r\n",
    "    dataset = load_zipped_shl_dataset(dataset_dir, tqdm=tqdm)\r\n",
    "    if acc_mag_conc is None:\r\n",
    "        acc_mag_conc = dataset.acc_mag\r\n",
    "    else:\r\n",
    "        acc_mag_conc = np.concatenate((acc_mag_conc, dataset.acc_mag), axis=0)\r\n",
    "    if mag_mag_conc is None:\r\n",
    "        mag_mag_conc = dataset.mag_mag\r\n",
    "    else:\r\n",
    "        mag_mag_conc = np.concatenate((mag_mag_conc, dataset.mag_mag), axis=0)\r\n",
    "    if gyr_mag_conc is None:\r\n",
    "        gyr_mag_conc = dataset.gyr_mag\r\n",
    "    else:    \r\n",
    "        gyr_mag_conc = np.concatenate((gyr_mag_conc, dataset.gyr_mag), axis=0)\r\n",
    "    del dataset"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting shl-dataset\\challenge-2019-train_torso.zip: 100%|██████████| 22/22 [03:06<00:00,  8.48s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Acc_mag Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Mag_mag Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Gyr_mag Import Done\n",
      "Labels Import Done\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting shl-dataset\\challenge-2019-train_bag.zip: 100%|██████████| 22/22 [03:36<00:00,  9.85s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Acc_mag Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Mag_mag Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Gyr_mag Import Done\n",
      "Labels Import Done\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting shl-dataset\\challenge-2019-train_hips.zip: 100%|██████████| 22/22 [03:37<00:00,  9.88s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Acc_mag Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Mag_mag Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Gyr_mag Import Done\n",
      "Labels Import Done\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Extracting shl-dataset\\challenge-2020-train_hand.zip: 100%|██████████| 23/23 [03:47<00:00,  9.87s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acc_x Import Done\n",
      "Acc_y Import Done\n",
      "Acc_z Import Done\n",
      "Acc_mag Import Done\n",
      "Mag_x Import Done\n",
      "Mag_y Import Done\n",
      "Mag_z Import Done\n",
      "Mag_mag Import Done\n",
      "Gyr_x Import Done\n",
      "Gyr_y Import Done\n",
      "Gyr_z Import Done\n",
      "Gyr_mag Import Done\n",
      "Labels Import Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Check that we don't have NaNs in our dataset\r\n",
    "assert not np.isnan(acc_mag_conc).any()\r\n",
    "assert not np.isnan(mag_mag_conc).any()\r\n",
    "assert not np.isnan(gyr_mag_conc).any()\r\n",
    "\r\n",
    "# Fit and export scalers\r\n",
    "print('Fitting acc scaler...')\r\n",
    "acc_mag_scaled = acc_scaler.fit_transform(acc_mag_conc)\r\n",
    "print('Fitting mag scaler...')\r\n",
    "mag_mag_scaled = mag_scaler.fit_transform(mag_mag_conc)\r\n",
    "print('Fitting gyr scaler...')\r\n",
    "gyr_mag_scaled = gyr_scaler.fit_transform(gyr_mag_conc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting acc scaler...\n",
      "Fitting mag scaler...\n",
      "Fitting gyr scaler...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Export transformers\r\n",
    "\r\n",
    "import json\r\n",
    "import joblib\r\n",
    "\r\n",
    "for transformer, dir in [\r\n",
    "    (acc_scaler, 'models/acc-scaler'),\r\n",
    "    (mag_scaler, 'models/mag-scaler'),\r\n",
    "    (gyr_scaler, 'models/gyr-scaler'),\r\n",
    "]:\r\n",
    "    # Platform independent export\r\n",
    "    transformer_params = {\r\n",
    "        'lambdas': list(transformer.lambdas_),\r\n",
    "    }\r\n",
    "    with open(dir + '.json', 'w') as f:\r\n",
    "        f.write(json.dumps(transformer_params))\r\n",
    "    # Python export\r\n",
    "    joblib.dump(transformer, dir + '.joblib')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "097461492b3eec731f5f36facfab7d83b93854d821dc66544771e2db489a1966"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}