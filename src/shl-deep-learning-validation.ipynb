{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.8 64-bit"
    },
    "interpreter": {
      "hash": "097461492b3eec731f5f36facfab7d83b93854d821dc66544771e2db489a1966"
    },
    "colab": {
      "name": "shl-deep-learning-timeseries.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Get needed auxiliary files for colab\r\n",
        "!git clone https://github.com/philippmatthes/diplom\r\n",
        "%cd /content/diplom/src\r\n",
        "!mkdir shl-dataset\r\n",
        "!wget -nc -O shl-dataset/challenge-2020-validation.zip http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2020/challenge-2020-validation.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diplom'...\n",
            "remote: Enumerating objects: 1375, done.\u001b[K\n",
            "remote: Counting objects: 100% (712/712), done.\u001b[K\n",
            "remote: Compressing objects: 100% (445/445), done.\u001b[K\n",
            "remote: Total 1375 (delta 344), reused 582 (delta 229), pack-reused 663\u001b[K\n",
            "Receiving objects: 100% (1375/1375), 27.92 MiB | 20.42 MiB/s, done.\n",
            "Resolving deltas: 100% (720/720), done.\n",
            "/content/diplom/src\n",
            "--2021-08-07 09:10:53--  http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_torso.zip\n",
            "Resolving www.shl-dataset.org (www.shl-dataset.org)... 37.187.125.22\n",
            "Connecting to www.shl-dataset.org (www.shl-dataset.org)|37.187.125.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5852446972 (5.5G) [application/zip]\n",
            "Saving to: ‘shl-dataset/challenge-2019-train_torso.zip’\n",
            "\n",
            "shl-dataset/challen 100%[===================>]   5.45G  9.25MB/s    in 9m 48s  \n",
            "\n",
            "2021-08-07 09:20:41 (9.49 MB/s) - ‘shl-dataset/challenge-2019-train_torso.zip’ saved [5852446972/5852446972]\n",
            "\n",
            "--2021-08-07 09:20:41--  http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_bag.zip\n",
            "Resolving www.shl-dataset.org (www.shl-dataset.org)... 37.187.125.22\n",
            "Connecting to www.shl-dataset.org (www.shl-dataset.org)|37.187.125.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5628524721 (5.2G) [application/zip]\n",
            "Saving to: ‘shl-dataset/challenge-2019-train_bag.zip’\n",
            "\n",
            "shl-dataset/challen 100%[===================>]   5.24G  8.83MB/s    in 9m 46s  \n",
            "\n",
            "2021-08-07 09:30:28 (9.16 MB/s) - ‘shl-dataset/challenge-2019-train_bag.zip’ saved [5628524721/5628524721]\n",
            "\n",
            "--2021-08-07 09:30:28--  http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2019/challenge-2019-train_hips.zip\n",
            "Resolving www.shl-dataset.org (www.shl-dataset.org)... 37.187.125.22\n",
            "Connecting to www.shl-dataset.org (www.shl-dataset.org)|37.187.125.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5871677913 (5.5G) [application/zip]\n",
            "Saving to: ‘shl-dataset/challenge-2019-train_hips.zip’\n",
            "\n",
            "shl-dataset/challen 100%[===================>]   5.47G  8.76MB/s    in 10m 21s \n",
            "\n",
            "2021-08-07 09:40:50 (9.02 MB/s) - ‘shl-dataset/challenge-2019-train_hips.zip’ saved [5871677913/5871677913]\n",
            "\n",
            "--2021-08-07 09:40:50--  http://www.shl-dataset.org/wp-content/uploads/SHLChallenge2020/challenge-2020-train_hand.zip\n",
            "Resolving www.shl-dataset.org (www.shl-dataset.org)... 37.187.125.22\n",
            "Connecting to www.shl-dataset.org (www.shl-dataset.org)|37.187.125.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6040097130 (5.6G) [application/zip]\n",
            "Saving to: ‘shl-dataset/challenge-2020-train_hand.zip’\n",
            "\n",
            "shl-dataset/challen 100%[===================>]   5.62G  9.54MB/s    in 10m 23s \n",
            "\n",
            "2021-08-07 09:51:13 (9.25 MB/s) - ‘shl-dataset/challenge-2020-train_hand.zip’ saved [6040097130/6040097130]\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OlIByJSIr6U",
        "outputId": "244a8540-0305-47ec-bb18-342640aa53fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Switch to src dir and select tensorflow\r\n",
        "%cd /content/diplom/src\r\n",
        "%tensorflow_version 2.x"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diplom/src\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZAJlKdu06f1",
        "outputId": "b8d19249-1141-4ff4-9d71-3a165664d7f0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Define all datasets to train our model on\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "DATASET_DIR = Path('shl-dataset/challenge-2020-validation.zip')"
      ],
      "outputs": [],
      "metadata": {
        "id": "l-Q5C3EOivKT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from tensorflow import keras\r\n",
        "\r\n",
        "# Check that we can use our GPU, to not wait forever during training\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "device_lib.list_local_devices()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16864235248065555050,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 3215029044\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 2269128632353336532\n",
              " physical_device_desc: \"device: 0, name: GeForce GTX 770, pci bus id: 0000:01:00.0, compute capability: 3.0\"]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPcUNZfPIZ0g",
        "outputId": "9fc9bfa0-a355-4d43-9b21-57e9e5d566c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "from tools.dataset import load_zipped_shl_dataset\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "dataset = load_zipped_shl_dataset(DATASET_DIR, tqdm=tqdm, subdir_in_zip='validation')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting shl-dataset\\challenge-2020-validation.zip: 100%|██████████| 89/89 [01:56<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc_x Import Done\n",
            "Acc_y Import Done\n",
            "Acc_z Import Done\n",
            "Acc_mag Import Done\n",
            "Mag_x Import Done\n",
            "Mag_y Import Done\n",
            "Mag_z Import Done\n",
            "Mag_mag Import Done\n",
            "Gyr_x Import Done\n",
            "Gyr_y Import Done\n",
            "Gyr_z Import Done\n",
            "Gyr_mag Import Done\n",
            "Labels Import Done\n",
            "Acc_x Import Done\n",
            "Acc_y Import Done\n",
            "Acc_z Import Done\n",
            "Acc_mag Import Done\n",
            "Mag_x Import Done\n",
            "Mag_y Import Done\n",
            "Mag_z Import Done\n",
            "Mag_mag Import Done\n",
            "Gyr_x Import Done\n",
            "Gyr_y Import Done\n",
            "Gyr_z Import Done\n",
            "Gyr_mag Import Done\n",
            "Labels Import Done\n",
            "Acc_x Import Done\n",
            "Acc_y Import Done\n",
            "Acc_z Import Done\n",
            "Acc_mag Import Done\n",
            "Mag_x Import Done\n",
            "Mag_y Import Done\n",
            "Mag_z Import Done\n",
            "Mag_mag Import Done\n",
            "Gyr_x Import Done\n",
            "Gyr_y Import Done\n",
            "Gyr_z Import Done\n",
            "Gyr_mag Import Done\n",
            "Labels Import Done\n",
            "Acc_x Import Done\n",
            "Acc_y Import Done\n",
            "Acc_z Import Done\n",
            "Acc_mag Import Done\n",
            "Mag_x Import Done\n",
            "Mag_y Import Done\n",
            "Mag_z Import Done\n",
            "Mag_mag Import Done\n",
            "Gyr_x Import Done\n",
            "Gyr_y Import Done\n",
            "Gyr_z Import Done\n",
            "Gyr_mag Import Done\n",
            "Labels Import Done\n"
          ]
        }
      ],
      "metadata": {
        "id": "v483oiTGIZ0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9c5303-f25b-4533-d8ce-85e21cdde1c4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Check that we don't have NaNs in our dataset\r\n",
        "assert not np.isnan(dataset.acc_mag).any()\r\n",
        "assert not np.isnan(dataset.mag_mag).any()\r\n",
        "assert not np.isnan(dataset.gyr_mag).any()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import joblib\r\n",
        "\r\n",
        "from sklearn.preprocessing import PowerTransformer\r\n",
        "\r\n",
        "acc_scaler = joblib.load('models/acc-scaler.joblib')\r\n",
        "mag_scaler = joblib.load('models/mag-scaler.joblib')\r\n",
        "gyr_scaler = joblib.load('models/gyr-scaler.joblib')\r\n",
        "\r\n",
        "acc_mag_scaled = acc_scaler.transform(dataset.acc_mag)\r\n",
        "mag_mag_scaled = mag_scaler.transform(dataset.mag_mag)\r\n",
        "gyr_mag_scaled = gyr_scaler.transform(dataset.gyr_mag)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "# Prepare testing data\r\n",
        "X = np.stack([\r\n",
        "    acc_mag_scaled,\r\n",
        "    mag_mag_scaled, \r\n",
        "    gyr_mag_scaled,\r\n",
        "], axis=2)\r\n",
        "\r\n",
        "del acc_mag_scaled\r\n",
        "del mag_mag_scaled\r\n",
        "del gyr_mag_scaled"
      ],
      "outputs": [],
      "metadata": {
        "id": "r2u2cD7JfZl_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\r\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(dataset.labels), y=dataset.labels)\r\n",
        "class_weights = dict(zip(np.unique(dataset.labels), class_weights)) # Keras adaption\r\n",
        "class_weights[0] = 0 # NULL label\r\n",
        "class_weights"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 0.6030878163231105,\n",
              " 2: 0.688732057416268,\n",
              " 3: 6.484009009009009,\n",
              " 4: 1.4950664727877025,\n",
              " 5: 0.8787851037851038,\n",
              " 6: 1.960035403050109,\n",
              " 7: 0.8249942686840899,\n",
              " 8: 0.8287943344081069,\n",
              " 0: 0}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "id": "LNEjy7ZLTXsR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "MODEL_DIRS = [\r\n",
        "    Path('models/shl-baseline-cnn.h5'),\r\n",
        "    Path('models/shl-resnet.h5'),\r\n",
        "]\r\n",
        "\r\n",
        "for model_dir in MODEL_DIRS:\r\n",
        "    model = keras.models.load_model(model_dir)\r\n",
        "\r\n",
        "    score = model.evaluate(X, dataset.labels, verbose=0) \r\n",
        "\r\n",
        "    print(f'{model_dir} Test loss:', score[0]) \r\n",
        "    print(f'{model_dir} Test accuracy:', score[1])"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown layer: Functional",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-edf0e2273dc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMODEL_DIRS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No model found in config file.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m    308\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[0;32m    309\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects)\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       printable_module_name='layer')\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    161\u001b[0m       \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unknown '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'from_config'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m       \u001b[0marg_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Unknown layer: Functional"
          ]
        }
      ],
      "metadata": {
        "id": "m-Xd0mWdi5ri"
      }
    }
  ]
}