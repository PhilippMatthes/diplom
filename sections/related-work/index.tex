\chapter{Verwandte Arbeiten}\label{ch:verwandte-arbeiten}

In diesem Kapitel wird näher auf die wissenschaftlichen Arbeiten eingegangen, deren Forschungsthema und Anforderungen sich mit dem dieser Arbeit stark überschneiden. Dazu wird zunächst ein taxonomischer Überblick über Kategorien gegeben, in welche sich verwandte Arbeiten eingliedern lassen. Anschließend werden die Konzepte und Ergebnisse näher diskutiert und verglichen.

\section{Forschungsüberblick}

Der Forschungsbereich Machine Learning erhält aktuell eine große Aufmerksamkeit, allein in 2020 wurden geschätzt 25800 Publikationen mit dem Begriff \enquote{Machine Learning} im Titel veröffentlicht\footnote{Quelle: Google Scholar, erweiterte Suchfunktion. Teile dieser Ergebnisse können auch wiss. Artikel, Patente oder ähnliche Veröffentlichungen ohne garantierte wiss. Qualität (z.B. durch Peer-Review) sein.}. Ein Teil dieser Arbeiten fokussiert sich auf den Fachbereich \acrshort{har}, \cite{demrozi_human_2020} zählten in 2020 insgesamt 149 wissenschaftliche Publikationen, davon 53 mit Fokus auf Deep Learning und 96 mit Fokus auf traditionellen Machine-Learning-Ansätzen. Dabei sind die auf Deep Learning basierenden Ansätze in der Erkennungsqualität nur marginal überlegen, mit einer durchschnittlichen Trefferquote von $93.0\%$ gegenüber $92.2\%$. Die meisten der in \cite{demrozi_human_2020} analysierten Arbeiten nutzen Akzelerometerdaten, gefolgt von Gyrosensordaten, Magnetometerdaten und weiteren Sensordaten. Unter den Ansätzen befinden sich teils aber auch unkonventionelle Ideen, \cite{wang_sound-based_2019} verwenden beispielsweise das Mikrofon als Sensor. Um die verwandten Arbeiten aus den über 100 Publikationen (neben relevanten Metaanalysen) zu extrahieren, wurde systematisch und anforderungsbezogen gesucht und die Referenzen gefundener Arbeiten weiterverfolgt (\textit{Snowballing}). Hierbei werden auch Arbeiten aus dem Bereich HAR berücksichtigt, wenn sich das darin aufgeführte Konzept auf den konkreten Anwendungsfall der Verkehrsmittelerkennung überführen lässt. In der nachfolgenden Tabelle ist eine Auswahl der so gefundenen Arbeiten gegenübergestellt und in verschiedene Kategorien eingeordnet. In den unteren zwei Sektionen der Tabelle befinden sich Ansätze, welche eine Verkehrsmittelklassifikation über Machine-Learning-Modelle realisieren, ohne konkreten Fokus auf eine Portierung oder die Lauffähigkeit des Ansatzes auf Smartphones. Unter anderem ordnen sich hier auch die bekannten Movebis-Ansätze ein. Darüber befinden sich Ansätze, welche einen allgemeineren Klassifikationsschwerpunkt (\acrshort{har}) ohne Fokus auf Verkehrsmittel haben, gleichzeitig jedoch für Smartphones ausgelegt wurden. Im obersten Teil der Tabelle sind zwei Ansätze gezeigt, welche eine Verkehrsmittelklassifikation auf Smartphones über Machine-Learning-Modelle realisieren, sowie eine Arbeit, die nochmals limitiertere Smartwatches betrachtet.

\begin{landscape}
  \begin{table}[]
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{@{}llp{3cm}p{2cm}p{7cm}p{4cm}p{2cm}p{3cm}p{4cm}@{}}
  \toprule
    Arbeit &
    Kat. &
    Labels &
    Daten &
    Preprocessing &
    Features &
    Modell(e) &
    Regularisierung &
    Training \\ \midrule
  \cite{bhattacharya_smart_2016} &
    \acrshort{har}-W &
    Mehrere Varianten &
    \acrshort{acc} &
    Segmentierung, Abs. Signalstärke, \acrshort{fft} &
    Shallow &
    \acrshort{rbm} &
    Keine Angabe &
    Supervised Learning \\ \midrule
  \cite{hemminki_accelerometer-based_2013}  &
    \acrshort{vme}-S &
    Train, Bus, Stationary, Metro, Tram, Car &
    \acrshort{acc} &
    Tiefpass, Segmentierung, Elimination der Gravitation, Berechnung der Features &
    Shallow &
    \acrshort{hmm} und \acrshort{dt} &
    Limitierung der Modellgröße &
    Ensemble Learning \\
  \cite{byon_real-time_2014} &
    \acrshort{vme}-S &
    Walk, Bike, Automobile, Bus, Car &
    \acrshort{gnss}, \acrshort{acc}, \acrshort{mag} &
    Keine Angabe &
    Vorverarbeitete Daten &
    FFN &
    Keine Angabe &
    Supervised Learning \\ \midrule
  \cite{mairittha_-device_2021} &
    \acrshort{har}-S &
    12 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} &
    Keine Angabe &
    Transfer Learning, On-Device Fine-Tuning \\
  \cite{mairittha_improving_2020} &
    \acrshort{har}-S &
    6 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    Dropout &
    Supervised Learning, On-Device Fine-Tuning \\
  \cite{mairittha_-device_2019} &
    \acrshort{har}-S &
    6 Aktivitäten &
    \acrshort{acc} &
    Segmentierung, Feature-Berechnung &
    Shallow &
    \acrshort{rnn}-\acrshort{lstm} &
    Keine Angabe &
    Supervised Learning \\
  \cite{nutter_design_2018} &
    \acrshort{har}-S &
    9 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Glättung, Hochpass, Tiefpass, Elimination der Gravitation &
    Non-Shallow &
    \acrshort{cnn} &
    Dropout, Batch-Normalization &
    Transfer Learning \\
  \cite{zebin_design_2019} &
    \acrshort{har}-S &
    5 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Segmentierung, Windowing, Normalisierung &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    Dropout, Batch-Normalization &
    Supervised Learning \\
  \cite{ravi_deep_2016} &
    \acrshort{har}-S &
    Mehrere Varianten &
    \acrshort{gyr}, \acrshort{acc} &
    Feature-Berechnung, \acrshort{fft} &
    Non-Shallow &
    \acrshort{cnn} &
    Weight Decay, Momentum, Dropout &
    Supervised Learning \\ \midrule
  \cite{liang_convolutional_2017} &
    \acrshort{vme} &
    Bike, Car, Walk, Train, Metro, Bus, Stationary &
    \acrshort{acc} &
    Elimination der Gravitation, Gleitfenster, Abs. Signalstärke &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    L2-Regularisierung &
    Supervised Learning \\
  \cite{friedrich_transportation_2019} &
    \acrshort{vme} &
    Stationary, Walk, Run, Bike, Car, Bus, Train, Metro &
    \acrshort{acc}, \acrshort{gyr}, \acrshort{mag}, BAR &
    Datensatzgewichtung, Abs. Signalstärke, Normalisierung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} &
    Dropout &
    Supervised Learning \\ \midrule
  \cite{werner_kontinuierliche_2020} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    Skalierung, Interpolation, \acrshort{ahrs}, Glättung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning, Validierung mith. Semi-Supervised Learning \\
  \cite{stojanov_continuous_2020} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train, Boat &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    \acrshort{ahrs}, Normalisierung, Alignment, Abs. Signalstärke, Downsampling, \acrshort{fft}, Gleitfenster, Segmentierung &
    Shallow &
    \acrshort{cnn} und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning \\
  \cite{matusek_anwendung_2019} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    Interpolation und Alignment, GPS-Korrektur, Rauschfilterung über Moving Average, Zeitfenster &
    Vorverarbeitete Daten &
    FFN (Kernkonzept) &
    Early Stopping &
    Supervised Learning \\ \bottomrule
  \end{tabular}
  \caption[Vergleichender Überblick über verwandte Arbeiten.]{\footnotesize{Vergleichender Überblick über verwandte Arbeiten. Abkürzungen wie folgt. Kategorien: \acrshort{vme} (Verkehrsmittelerkennung), \acrshort{vme}-W (\acrshort{vme} auf Wearables), \acrshort{vme}-S (\acrshort{vme} auf Smartphones), \acrshort{har} (Human Activity Recognition), \acrshort{har}-S (\acrshort{har} auf Smartphones). Daten: \acrshort{acc} (Akzelerometer), \acrshort{gyr} (Gyrosensor), \acrshort{mag} (Magnetometer), BAR (Barometer - Luftdruck). Preprocessing: \acrshort{fft} (Fast Fourier Transformation). Modelle: \acrshort{rbm} (Restricted Boltzmann Machine), \acrshort{hmm} (Hidden Markov Model), \acrshort{dt} (Decision Tree), FFN (Feed-Forward-Network), \acrshort{rnn}-\acrshort{lstm} (Recurrent Neural Network mit Long-Short-Term-Memory-Neuronen), \acrshort{cnn} (Convolutional Neural Network).}}
  }
  \end{table}
\end{landscape}

Die Übersicht zeigt eine engere Auswahl der verwandten Arbeiten. Analysiert wurden darüber hinaus auch Konzepte aus \cites{chen_deep_2015, ravi_deep_2017, kwapisz_activity_2011, jahangiri_applying_2015, nurhanim_classification_2017, zeng_convolutional_2014, abu_alsheikh_deep_2015, inoue_deep_2018}. In der Übersicht spiegelt sich die Beobachtung aus \cite{demrozi_human_2020} wieder, dass die gewählten konzeptuellen Kernkomponenten der Datenverarbeitungspipelines mitunter sehr heterogen sind. Dies erschwert die Auswahl vielversprechender und häufig eingesetzter Komponenten durch die Betrachtung konzeptioneller Überschneidungen. Die nachfolgenden Abschnitte dissektionieren allgemeine Gemeinsamkeiten und Unterschiede der betrachteten Arbeiten.

\paragraph{Labels und Datengrundlage:} Beginnend mit der Auswahl der Labels wird diese häufig in Abhängigkeit des Testdatensatzes durchgeführt, welcher zur Evaluation des jeweiligen Konzeptes verwendet wird. Die Ansätze sind meist nicht auf diese Labels beschränkt und können flexibel auf eine andere Auswahl (durch Modifikation einzelner Komponenten) erweitert oder reduziert werden. \cite{ravi_deep_2016} testen ihren Ansatz beispielsweise auf verschiedenen Datensätzen, mit verschiedenen zu klassifizierenden Labels. In manchen Ansätzen, die wie \cite{hemminki_accelerometer-based_2013} Ensemble Learning nutzen, ist dies möglich über das Hinzufügen und Entfernen der partiellen Klassifikatoren. Weiterhin ist auch die Wahl der Daten, auf deren Grundlage die Klassifikation stattfindet, häufig wie in \cite{ravi_deep_2016} an die Verfügbarkeit der Sensortypen im Evaluationsdatensatz gebunden. \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017,byon_real-time_2014} beziehen ihre Datensätze aus eigenen Aufzeichnungen, teils werden jedoch nur wenige Angaben zur Menge der Daten und zur Aufzeichnung selbst gemacht. Dies limitiert die allgemeine Reproduzierbarkeit der Arbeiten \cite[S. 14]{demrozi_human_2020}. \cites{zebin_design_2019,nutter_design_2018,bhattacharya_smart_2016,mairittha_-device_2019,radu_towards_2016,friedrich_transportation_2019} nutzen öffentlich verfügbare Datensätze, teils auch aus anderen Forschungsarbeiten.

\paragraph{Vorverarbeitung:} Eine Gemeinsamkeit der betrachteten Konzepte besteht darin, dass in den meisten verwandten Arbeiten die sequentiellen Daten explizit in Segmente unterteilt werden. Die Gleitfenstermethode wird hierbei häufig mit verwendet. Außerdem wird der Gravitationsvektor der Akzelerometerdaten in den meisten verwandten Arbeiten explizit als konzeptuell störender Faktor identifiziert und infolgedessen eliminiert. Auch die Skalierung der Daten wird in einigen Arbeiten explizit als Bestandteil des Vorverarbeitungskonzepts beschrieben.

Die Vorverarbeitung ist jedoch auch Gegenstand unterschiedlicher Herangehensweisen. Die Notwendigkeit und konkrete Strategien zur Synchronisation oder dem Alignment beschreiben die Movebis-Arbeiten \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} als essenziellen Bestandteil der Datenvorverarbeitung, hingegen argumentieren \cite{mairittha_improving_2020}, dass bei der Aufzeichnung der Sensoren auf demselben Gerät keine Synchronisation notwendig sei. Möglicherweise ist dieser Widerspruch zurückführbar auf die unterschiedlichen Eigenschaften und Inkonsistenzen der Datensätze und das starke Downsampling und die Interpolation auf $1Hz$ in \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020}. Eine explorative Analyse des Datensatzes kann zur Klärung herangezogen werden, inklusive einer Analyse der Gewichtungen der Labels im Datensatz \cite[S. 15ff]{sosnovshchenko_machine_2018}. Sind diese unausgeglichen, lernt das Machine-Learning-Modell unter Umständen ungleichmäßig (\textit{Bias}). Die Gleichgewichtung der Labels ist beispielsweise expliziter Bestandteil der Arbeit von \cite{friedrich_transportation_2019,mairittha_-device_2019}.

Die verwandten Arbeiten differenzieren sich weiter in der Entscheidung, ob die aufgezeichneten Daten nur praktisch verlustfrei transformiert werden (z.B. durch Segmentierung und Skalierung), oder im Voraus einer Glättung und weiteren verlustbehafteten Vorverarbeitungsmethoden (z.B. Tiefpass, Hochpass) unterzogen werden. In vielen verwandten Arbeiten wie \cite{nutter_design_2018} und auch in einer Metaanalyse von 2010 \cite{figo_preprocessing_2010} wird auf die grundlegende Problematik hingewiesen, dass die Sensordaten verrauscht sein können, und dass sich deshalb zumindest eine Glättung und die Anwendung von Frequenzbandfiltern anbietet. Es finden sich aber auch Ansätze wie \cite{mairittha_improving_2020}, welche bewusst keine dieser Signalverarbeitungsmethoden anwenden, mit der Argumentation, dass das jeweilige Machine-Learning-Modell trotzdem eine geeignete interne Repräsentation erlernen könne. \cite{demrozi_human_2020} beobachten, dass eine entsprechende Vorverarbeitung vor allem bei traditionellen Modellen außerhalb des Deep-Learning angewandt wird. Deep-Learning-Ansätze seien nach \cite[S. 14]{demrozi_human_2020} nicht zwingend auf eine transformative Datenvorverarbeitung angewiesen.

\paragraph{Machine-Learning-Modelle und Features:} Analog zur Vorverarbeitung ist auch die Wahl der konkreten Eingaben für das Machine-Learning-System sehr unterschiedlich. In einem Teil der Arbeiten werden die vorverarbeiteten Daten direkt als Input verwendet, andere wiederum erzeugen Shallow Features durch Transformationen oder die Aggregation der Segmentdaten. Hinzu kommen Ansätze, welche ein gesondertes Machine-Learning-Modell einsetzen, um eine effizientere Feature-Repräsentation zu erzeugen. \cite{nutter_design_2018} konnten so beispielsweise ohne Verlust der Ergebnisqualität 561 manuell erstellte (Shallow) Features auf 100 Non-Shallow-Features reduzieren. Die letztendlich gewählten Features sind oft eng gekoppelt an die Konfiguration der zentralen Machine-Learning-Modelle, betrachtbar ist also ein Co-Design von Modellen und Vorverarbeitungsschritten. Beispielsweise können die vorverarbeiteten Sensordaten in Spektrogramme überführt werden, für die bildhafte Klassifikation über \acrshort{cnn}s \cite{ravi_deep_2016}. \cite{demrozi_human_2020} zeigt hierbei, dass generell verschiedene Modelle gewählt werden können, ohne einen durch seine Ergebnisqualität signifikant herausstechenden Ansatz. Sowohl neuronale Netzwerke, als auch herkömmliche Machine-Learning-Modelle finden sich verteilt über die Arbeiten der Forschungsdomäne, auch im Rahmen der Verkehrsmittelererkennung auf Smartphones \cite{byon_real-time_2014,hemminki_accelerometer-based_2013}. \cite[S. 14]{demrozi_human_2020} beobachten, dass die Entscheidung zwischen traditionellen Modellen und Deep-Learning-Ansätzen vor allem von der verfügbaren Rechenleistung und den verfügbaren Daten abhängt. Traditionelle Modelle seien typischerweise weniger rechenaufwändig und benötigten weniger Trainingsdaten, was diese Modelle wiederum attraktiver für durch Hardware limitierte Anwendungen wirken lässt.

\paragraph{Training:} Abschließend lässt sich zur Forschungsübersicht erwähnen, dass zum Training der Modelle grundsätzlich verschiedene Methoden angewandt werden können. Das Reinforcement Learning findet sich allerdings in keiner der betrachteten Arbeiten wieder. Die Trainingsansätze sind nicht durch die Verfügbarkeit von Trainingsdaten limitiert, entweder durch die Nutzung eines der verschiedenen öffentlichen Datensatze oder durch die Aufzeichnung neuer Daten. Der wesentliche limitierende Faktor in den Trainingsdaten liegt nach \cite[S. 14]{demrozi_human_2020} häufig in der fehlenden Heterogenität, bedingt durch die Aufzeichnung von zu wenigen Personen, Geräten und Tragepositionen. Dies erhöhe den Generalisierungsfehler auf neuen Daten. Dabei ist die Aufzeichnung neuer Daten mit verhältnismäßig geringem Aufwand realisierbar, dies zeigen \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017,byon_real-time_2014}. Durch die gute Verfügbarkeit der Trainingsdaten wird typischerweise das Supervised Learning als primäres Trainingsverfahren angewendet. \cite[S. 30]{werner_kontinuierliche_2020} erweitert den Trainingsdatensatz zur Validierung des Modells zusätzlich um ein Verfahren aus dem Semi-Supervised Learning. \cite{nutter_design_2018} wenden auf bestehenden \acrshort{cnn}s darüberhinaus das Transfer Learning an, durch Abwandlung der äußeren Netzwerkschichten und Beibehaltung der (auf Bildern) vortrainierten Gewichtungen. Auch \cite{mairittha_-device_2021} nutzen eine Variante des Transfer Learnings, mit der Besonderheit, dass ein Teil des Netzwerkes vortrainiert und dann auf dem mobilen Gerät eingefroren wird. Ein kleiner Teil des Netzwerkes bleibt veränderlich und kann auf dem Gerät analog zu den Nutzereingaben angepasst werden (\textit{On-Device Fine-Tuning}). \cite{hemminki_accelerometer-based_2013} verwendenen mehrere miteinander kooperierende Klassifikatoren, zur Unterscheidung jeweils zueinander ähnlicher Klassen (\textit{Ensemble Learning}). Als expliziter Bestandteil der meisten Trainingskonzepte wird auch eine auf das Modell angepasste Regularisierung durchgeführt, beispielsweise wird die Dropout-Regularisierung häufig in Verbindung mit \acrshort{cnn}s verwendet, um die Ergebnisqualität zu verbessern.

\section{Movebis-Ansätze}

Die in \Cref{fig:movebis-vergleich} gezeigten Ansätze \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} bilden den Ausgangspunkt für diese Arbeit. Das im Movebis-Projekt initial verwendete heuristische Verfahren zur Verkehrsmittelererkennung konnte durch das in \cite{matusek_anwendung_2019} vorgestellte Machine-Learning-System signifikant in der Ergebnisqualität übertroffen werden. \cite{matusek_anwendung_2019} legt dabei einen starken Fokus auf die Vorverarbeitung der Daten. Als primäres Machine-Learning-Modell wählt \cite{matusek_anwendung_2019} ein FFN. Gegenüber nicht-neuronalen Modellen, hierbei einem Decision Tree und einer \acrshort{svm}, erzeugte das FFN jedoch analog zu \cite{demrozi_human_2020} im Rahmen der Evaluation keine signifikant höhere Ergebnisqualität \cite[S. 96]{matusek_anwendung_2019}. Als weiteres Ergebnis stellte \cite{matusek_anwendung_2019} jedoch fest, dass ein tiefergehendes Feature-Engineering zu besseren Ergebnissen hätte führen können. Außerdem bestehe weiteres Potenzial in der sauberen Abtrennung der Verkehrsmittel bei der Aufzeichnung von neuen Aktivitätsdaten, da insbesondere bei den Verkehrsmittelübergängen und bei der Beendigung der Aktivität wiederholt falsche Labels auftraten \cite[S. 98ff]{matusek_anwendung_2019}. Außerdem konnten Lücken in den aufgezeichneten \acrshort{gnss}-Daten festgestellt werden \cite[S. 105]{matusek_anwendung_2019}.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 606 384]{movebis-vergleich.pdf}
\caption[Vergleich der Movebis-\acrshort{vme}-Pipelines.]{Vergleich der Movebis-Pipelines zur Verkehrsmittelererkennung. Abbildung schematisch nach den in \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} beschriebenen Konzeptkomponenten.}\label{fig:movebis-vergleich}
\end{figure}

Auf dieser Grundlage entwickelten \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} ihre Konzepte mit größerem Fokus auf die Wahl der Machine-Learning-Modelle. Sie übernehmen Teilschritte der Vorverarbeitung aus \cite{matusek_anwendung_2019}. \cite{werner_kontinuierliche_2020} nutzt ein mehrschichtiges \acrshort{rnn} mit \acrshort{lstm}-Neuronen, während \cite{stojanov_continuous_2020} ein \acrshort{cnn} zur Verkehrsmittelererkennung einsetzt. Analog zur Architektur der Modelle dienen in \cite{werner_kontinuierliche_2020} die vorverarbeiteten Datenpunkte als Zeitlinien-Eingabe des \acrshort{rnn}, gleichzeitig nutzt \cite{stojanov_continuous_2020} eine Auswahl von Shallow-Features als Eingabe für das \acrshort{cnn}. Als zusätzlichen Schritt führen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} eine Nachverarbeitung der Ausgaben durch Glättung anhand der Nachbarwerte ein, welche das Ergebnis der Ansätze weiter verbessern konnte. Bei der quantitativen Evaluation der Ansätze wurde insbesondere die Accuracy-Metrik der Netzwerke auf Testdaten bestimmt.

\begin{table}[H]
  \begin{tabular}{lllll}
  Arbeit & Healing & Beste Modell-Output-Accuracy & Accuracy n. Healing \\
  \midrule
  \cite{matusek_anwendung_2019} & \xmark & 67,84 \% n. \cite[S. 98]{stojanov_continuous_2020} & k.A. \\
  \cite{werner_kontinuierliche_2020} & \cmark & 92,00 \% n. \cite[S. 58]{werner_kontinuierliche_2020} & 98,27 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \cite{stojanov_continuous_2020} & \cmark & 92,07 \% n. \cite[S. 90]{stojanov_continuous_2020} & 93,56 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \bottomrule
  \end{tabular}\label{tab:movebis-vergleich}
  \caption{Vergleich von Ergebnisqualität und Modellgröße der Movebis-Ansätze.}
\end{table}

Im Vergleich zeigen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} nach \cite{demrozi_human_2020} typische Accuracy-Werte für die Verkehrsmittelerkennung als Spezialfall der \acrshort{har} von ca. 92\%, gegenüber deutlich schlechteren 67,84\% aus \cite{matusek_anwendung_2019}. Hierbei wird das ganzheitliche Datenverarbeitungssystem, jedoch ohne Postprocessing, betrachtet. Eine isolierte Betrachtung der Machine-Learning-Modelle, beispielsweise durch Vergleich bei gleichen Vorverarbeitungsschritten, ist wegen der Unterschiedlichkeit der Vorverarbeitungskonzepte nicht möglich. Lediglich das Postprocessing wurde als Teil der Datenverarbeitungskonzepte in \cite{stojanov_continuous_2020} und \cite{werner_kontinuierliche_2020} separat betrachtet. \cite{werner_kontinuierliche_2020} konnte die Accuracy so nach eigener Evaluation auf 98,27\% steigern.

Da die Movebis-Architekturen serverseitige Ansätze darstellen, lag bei der Erstellung der dazugehörigen Konzepte kein verstärkter Fokus auf einer Optimierung oder der Messung von Energie- und Speicherverbrauch. Auch die Inferenzzeit der jeweiligen Pipeline über den Segmenten wurde in der Evaluation der Arbeiten nicht berücksichtigt. Die Eignung der Systeme für Smartphones ist dadurch fraglich. Nach den konzeptuellen Beschreibungen der Machine-Learning-Modelle kann die Modellgröße geschätzt werden. Mit $32 bit$ Fließkommazahlen ermitteln sich hierüber Modellgrößen von $335 kB$ für \cite{matusek_anwendung_2019}, $623 kB$ für \cite{werner_kontinuierliche_2020} und $1296 kB$ für \cite{stojanov_continuous_2020}. Die zur Ermittlung dieser Kennzahlen verwendeten Konfigurationen sind in \Cref{fig:ml-movebis} im Anhang beigefügt. Zumindest die Modellgröße wäre für die Integration in einer App also in einem akzeptablen Rahmen. Unklarheiten wie die genaue Lokalisation der Dropout-Schichten oder auch die finale Konfiguration der Input-Schicht des \acrshort{cnn} aus \cite{stojanov_continuous_2020} schränken die Reproduzierbarkeit und die Aussagekraft dieser Schätzungen jedoch ein. Durch die verschiedenen Architekturen lässt sich auch nicht unbedingt von der geschätzten Modellgröße auf den Energieverbrauch oder die Inferenzzeit schließen, denn Parameter können wie in Convolution-Operationen von \acrshort{cnn}s in mehreren parallelen Berechnungsoperationen involviert sein.

Abschließend lässt sich feststellen, dass insbesondere \cite{werner_kontinuierliche_2020,stojanov_continuous_2020} zwar Ergebnisse auf dem aktuellen Forschungsniveau erzielen, die Konzepte jedoch wegen der von dieser Arbeit abweichenden initialen Problemstellung nicht direkt übernommen werden können. Auch wegen der Interpolation von $1Hz$, welche größere Fensterlängen für eine hinreichende Klassifikationsgüte bedingt, ist die Echtzeitfähigkeit der Konzepte eingeschränkt. Während dies für die nachträgliche Klassifikation von Daten auf Servern kein Problem darstellt, würden Fensterlängen von über $30s$ auch eine entsprechende Wartezeit nach sich ziehen, bevor die Klassifikation auf dem Smartphone nach Start der Aufzeichnung aktiv werden könnte. Dies widerspricht den Anforderungen an die Nutzbarkeit bei Integration in eine vom Nutzer zu bedienende App. Dennoch können Teile der Konzepte für diese Arbeit wiederverwendet werden, insbesondere deren Vor- und Nachverarbeitungsschritte. Die Accuracy-Werte, welche in \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} ermittelt wurden, decken sich mit den metaanalytischen Beobachtungen aus \cite{demrozi_human_2020}. Auch hier zeigt weder das \acrshort{cnn}, noch das \acrshort{rnn} im Vergleich eine signifikant bessere Ergebnisqualität, sofern die jeweiligen Systeme ohne Postprocessing betrachtet werden. Es lässt sich somit vermuten, dass die Wahl einer speziellen Architektur gegenüber einem gezielten Co-Design der Datenverarbeitungspipeline mit dem klassifizierenden Modell keine signifikanten Zugewinne in der Ergebnisqualität verspricht. Dies zu evaluieren, ist Teil der Forschungsfragen dieser Arbeit.

\section{\acrshort{har} auf Smartphones}

Die vorigen Ausführungen zeigen, dass sich die serverseitigen Movebis-Ansätze nicht ohne weitere Anpassungen für den Einsatz auf Smartphones eignen. In der ursprünglichen Implementation kollidieren die Movebis-Ansätze beispielsweise mit der Anforderung an eine geringe Latenz, bedingt durch die große Fensterlänge. \cite{banos_window_2014} zeigen, dass HAR-Verfahren, welche eng mit Verkehrsmittelerkennungsverfahren verwandt sind, auch mit deutlich kürzeren Fensterlängen möglich sind. Entgegen der intuitiven Vermutung stechen hier sogar die Klassifikatoren mit besonders hoher Ergebnisqualität heraus, welche vergleichsweise kurze Fensterlängen von $0.25s$ bis $0.5s$ nutzen \cite[S. 20]{banos_window_2014}. Betrachtet wurden hierbei jedoch auch Ansätze, welche dedizierte Akzelerometer-Systeme mit potenziell höheren Abtastraten und Signalqualitäten, im Vergleich zu Smartphone-Akzelerometern, bieten. Die Wartezeit, welche durch die Gleitfenstermethode zu Beginn einer kontinuierlichen Klassifikation notwendig wäre, befindet sich mit diesen Fensterlängen in einem akzeptablen Bereich. Einen weiteren direkten Einfluss auf die Echtzeitfähigkeit hat die Dauer, welche die Verkehrsmittelerkennung für die Berechnung der Inferenz benötigt. Die Kernkomponenten Vorverarbeitung, Klassifikation und Nachverarbeitung tragen jeweils, je nach Komplexität, zur Gesamtinferenzzeit bei.

\subsection{Inferenzzeit}

\cite[S. 6]{zebin_design_2019} führten eine quantitative Analyse der Modell-Inferenzzeit durch. Traditionelle Machine-Learning-Modelle unterschieden sich in deren Betrachtung nicht signifikant von CNN-Modellen und lagen bei $3.53ms$ bis $12.6ms$. Ob diese Daten auf einem Computer oder auf einem Smartphone erfasst wurden, wurde nicht angegeben. Zum Teil sind die Daten auch widersprüchlich, in \cite[S. 8]{zebin_design_2019} übersteigen in der Analyse der Ausführungszeit einzelner Verarbeitungsschritte des Modells bereits einzelne Schritte mit bis zu $244.813ms$ die an anderer Stelle angegebene Gesamtinferenzzeit des Modells. Abgesehen davon konnte die kürzeste Inferenzzeit mit einem regularisierten CNN erreicht werden, welches gleichzeitig auch die höchste Ergebnisqualität, in Form einer Accuracy von $96.4\%$, produzierte. Die Ergebnisse decken sich mit den Analysen in \cite[S. 6]{ravi_deep_2016}, welche auch ein CNN-Modell testeten. Hierbei lag die Inferenzzeit bei $5.7ms$ bis $14.9ms$, wobei explizit angegeben wurde, dass die Unterschiede durch Tests auf unterschiedlichen Smartphones und Prozessoren entstanden. Die gemessenen Inferenzzeiten sind vergleichbar mit der Verarbeitungsdauer einer Fourier-Transformation, welche in denselben experimentellen Bedingungen bei $5.4ms$ bis $42ms$ gemessen wurde \cite[S. 6]{ravi_deep_2016}. Allein diese Arbeit betrachtend, scheinen Machine-Learning-Modelle also keinen besonderen Einfluss auf die Gesamtinferenzzeit zu besitzen. In anderen HAR-Arbeiten zeigen sich jedoch Ausreißer. Das auf LSTM basierende RNN-Modell aus \cite[S. 9]{mairittha_-device_2019} benötigte beispielsweise eine Inferenzzeit von $2846ms$ und damit wesentlich mehr als die langsamste CNN-Konfiguration aus \cite{ravi_deep_2016}. Hierbei ist fraglich, ob eventuell eine suboptimale Implementation vorliegt, denn in einem späteren Ansatz konnten \cite[S. 10]{mairittha_-device_2021} die Inferenzzeit auf $10.6ms$ für ein ähnliches LSTM-Modell senken. Insgesamt lässt sich daher trotz der teilweise vorhandenen experimentellen Unklarheiten vermuten, dass sowohl RNN-Modelle, als auch CNN-Modelle und traditionelle Modelle vergleichsweise gute Inferenzzeiten erreichen können. Ein bestmöglicher Ansatz ist allein anhand der obigen Betrachtungen jedoch nicht sichtbar.

\subsection{Energieverbrauch}

Ein weiterer Faktor, der bei serverseitigen Verkehrsmittelerkennungen wie \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} vernachlässigbar ist, jedoch bei Smartphone-Anwendungen einen essenziellen Faktor darstellt, ist der Energieverbrauch. \cite{ravi_deep_2016,nutter_design_2018,mairittha_improving_2020,mairittha_-device_2021} geben keine Auskunft über diesen Ressourcenparameter. \cite{mairittha_-device_2019} beschreiben, dass deren weiter oben bereits erwähntes RNN-Modell mit einer Inferenzzeit von $2846ms$ den durchschnittlichen Energieverbrauch der Applikation, im Vergleich zu einer Applikation ohne Klassifikator, um $5\%$ erhöht. Das System aus \cite{mairittha_-device_2019} verwendet jedoch auch eine Fensterlänge von $60s$, welche aus bereits genannten Gründen problematisch für die Nutzbarkeit ist und daher mit der Grundanforderung an die Latenz kollidiert. Im Zuge dessen bleiben auch die relevanten experimentellen Bedingungen zur Ermittlung des Energieverbrauchs unklar, wie zum Beispiel, ob kontinuierlich nach Ablauf von $60s$ klassifiziert wurde oder nur einmal alle $60s$. Das mit TensorFlow Lite trainierte, optimierte und exportierte CNN aus \cite[S. 9]{zebin_design_2019} verbrauchte bei dessen experimenteller Evaluation $39.30mW$ in einem kontinuierlichen Inferenzmodus. Neben der Inferenzzeit, bei der anhand der Nutzbarkeit eine Anforderung für die größtmögliche Latenz (wenige Sekunden) definiert werden konnte, ist auch die Definition eines \enquote{guten} Energieverbrauchs problematisch. Hierbei kann beispielsweise einfließen, ob es sich um einen kurzzeitigen Peak-Energieverbrauch, oder um einen langfristigen Durchschnittsverbrauch handelt. Da sich der Energieverbrauch durch die Fläche unter der Kurve bildet, welche Laufdauer mit dem Momentanverbrauch in Verbindung setzt, sind vor allem langfristige Lasten problematisch und sollten vorrangig betrachtet werden. Eine Möglichkeit der Betrachtung der Akzeptierbarkeit eines Energieverbrauchs liegt in dem Vergleich mit dem Verbrauch anderer, alltäglicher Applikationen. \cite[S. 9]{zebin_design_2019} setzen dies beispielsweise in Relation mit der Youtube-App, welche $116mW$ verbrauche, und schlussfolgern, dass $39.30mW$ entsprechend einen akzeptablen kontinuierlichen Energieaufwand darstelle.

\subsection{Speicherverbrauch}

\section{\acrshort{vme} auf Smartphones}

\todo[inline]{Konkrete Paraphrasierung zweier Ansätze}

% Konkrete betrachtung zweier Ansätze

\section{Modelloptimierung}

% Wahl der Segmentlänge
% \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} betrachtet Segmente von $10s$ bis $180s$ Länge. Es lässt sich vermuten, dass die Präzision der Klassifikation bei kürzeren Segmentlängen geringer ist, wie die experimentellen Daten aus \cite{matusek_anwendung_2019} suggerieren. Wie in \Cref{sec:datenerfassung-und-verarbeitung} gezeigt, ist es durch Interpolation der verschiedenen Spuren möglich, diese im Rahmen der Synchronisation zu beliebigen Raten abzutasten. Bei näherer Betrachtung fällt hierbei auf, dass \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} Datenpunkte mit $1Hz$ (Abtastrate des \acrshort{gnss}-Systems) abtasten, die mit deutlich höheren Frequenzen im dreistelligen Hertz-Bereich aufgenommenen Beschleunigungs-, Auslenkungs- und Orientierungsdaten also stark reduziert werden (Downsampling). Vermutlich bietet dies eine Möglichkeit zur Verbesserung der Konzepte aus \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020}, unter der Berücksichtigung, dass mit $1Hz$ Abtastrate lediglich Bewegungsabläufe mit Frequenzen $f \leq 0.5Hz$ nach dem Nyquist-Shannon-Abtasttheorem\footnote{\url{https://de.wikipedia.org/wiki/Nyquist-Shannon-Abtasttheorem} (Abgerufen am 14.4.2021)} erhalten bleiben, Frequenzen $f > 0.5Hz$ tragen zum Rauschen der abgetasteten Daten bei. Alternativ wäre daher auch ein Upsampling der korrigierten \acrshort{gnss}-Daten auf eine höhere Frequenz von ca. $100 Hz$ möglich. \cite{banos_window_2014} konnten zeigen, dass sich unter dieser Voraussetzung insbesondere kürzere Segmente von $0.25s$ bis $2s$ Länge für die Aktivitätserkennung eignen, gegenüber den von \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} verwendeten Segmentlängen von $10s$ bis $180s$.
