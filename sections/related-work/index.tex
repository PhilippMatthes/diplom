\chapter{Verwandte Arbeiten}\label{ch:verwandte-arbeiten}

In diesem Kapitel wird näher auf die wissenschaftlichen Arbeiten eingegangen, deren Forschungsthema sich mit dem dieser Arbeit stark überschneidet. Dazu wird zunächst ein taxonomischer Überblick über Kategorien gegeben, in welche sich verwandte Arbeiten eingliedern lassen. Anschließend werden die Konzepte und Ergebnisse näher diskutiert und verglichen.

\section{Forschungsüberblick}

Der Forschungsbereich Machine Learning erhält aktuell eine große Aufmerksamkeit, allein in 2020 wurden geschätzt 25800 Publikationen mit dem Begriff \enquote{Machine Learning} im Titel veröffentlicht\footnote{Quelle: Google Scholar, erweiterte Suchfunktion. Teile dieser Ergebnisse können auch wiss. Artikel, Patente oder ähnliche Veröffentlichungen ohne garantierte wiss. Qualität (z.B. durch Peer-Review) sein.}. Ein Teil dieser Arbeiten fokussiert sich auf den Fachbereich HAR, \cite{demrozi_human_2020} zählten in 2020 insgesamt 149 wissenschaftliche Publikationen, davon 53 mit Fokus auf Deep Learning (unter anderem künstliche neuronale Netzwerke) und 96 mit Fokus auf konventionellen Machine-Learning-Ansätzen wie Random Forests, Support Vector Machines, k-Means-Clustering und weiteren. Dabei sind die auf Deep Learning basierenden Ansätze in der Erkennungsqualität nur marginal überlegen, mit einer durchschnittlichen Trefferquote von $93.0\%$ gegenüber $92.2\%$. Die meisten der in \cite{demrozi_human_2020} analysierten Arbeiten nutzen Akzelerometerdaten, gefolgt von Gyrosensordaten, Magnetometerdaten und weiteren Sensordaten. Unter den Ansätzen befinden sich teils aber auch unkonventionelle Ideen, \cite{wang_sound-based_2019} verwenden beispielsweise das Mikrofon als Sensor. Um die verwandten Arbeiten aus den über 100 Publikationen (neben relevanten Metaanalysen) zu extrahieren, wurde systematisch nach bestimmten Kriterien gesucht und die Referenzen gefundener Arbeiten weiterverfolgt (\textit{Snowballing}). Insbesondere sollten die Arbeiten hierbei neben der Realisation einer Aktivitätserkennung über Machine-Learning-Modelle nach Möglichkeit auch auf Smartphones ausführbar oder für diese optimiert sein. Als weiteres Kriterium sollten die Arbeiten auch den Spezialfall der Verkehrsmittelerkennung aus dem HAR-Forschungsbereich behandeln. Dies ist jedoch optional, da sich die Arbeiten auch in der Regel flexibel auf diesen Spezialfall überführen lassen. In der nachfolgenden Tabelle ist eine Auswahl der so gefundenen Arbeiten gegenübergestellt und in verschiedene Kategorien eingeordnet. In den unteren zwei Sektionen der Tabelle befinden sich Ansätze, welche eine Verkehrsmittelklassifikation über Machine-Learning-Modelle realisieren, ohne konkreten Fokus auf eine Portierung oder die Lauffähigkeit des Ansatzes auf Edge-Geräten. Unter anderem ordnen sich hier auch die bekannten Movebis-Ansätze ein. Darüber befinden sich Ansätze, welche einen allgemeineren Klassifikationsschwerpunkt (HAR) ohne Fokus auf Verkehrsmittel haben, gleichzeitig jedoch für Smartphones ausgelegt wurden. Im obersten Teil der Tabelle sind zwei Ansätze gezeigt, welche eine Verkehrsmittelklassifikation auf Smartphones über Machine-Learning-Modelle realisieren, sowie eine Arbeit, die nochmals limitiertere Edge-Geräte (Smartwatches) betrachtet.

\begin{landscape}
  \begin{table}[]
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{@{}llp{3cm}p{2cm}p{7cm}p{4cm}p{2cm}p{3cm}p{4cm}@{}}
  \toprule
    Arbeit &
    Kat. &
    Labels &
    Daten &
    Preprocessing &
    Features &
    Modell(e) &
    Regularisierung &
    Training \\ \midrule
  \cite{bhattacharya_smart_2016} &
    HAR-W &
    Mehrere Varianten &
    ACC &
    Segmentierung, Abs. Signalstärke, FFT &
    Shallow &
    RBM &
    Keine Angabe &
    Supervised Learning \\ \midrule
  \cite{hemminki_accelerometer-based_2013}  &
    VME-S &
    Train, Bus, Stationary, Metro, Tram, Car &
    ACC &
    Tiefpass, Segmentierung, Elimination der Gravitation, Berechnung der Features &
    Shallow &
    HMM und DT &
    Limitierung der Modellgröße &
    Ensemble Learning \\
  \cite{byon_real-time_2014} &
    VME-S &
    Walk, Bike, Automobile, Bus, Car &
    GNSS, ACC, MAG &
    Keine Angabe &
    Vorverarbeitete Daten &
    FFN &
    Keine Angabe &
    Supervised Learning \\ \midrule
  \cite{mairittha_-device_2021} &
    HAR-S &
    12 Aktivitäten &
    GYR, ACC &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    RNN-LSTM &
    Keine Angabe &
    Transfer Learning, On-Device Fine-Tuning \\
  \cite{mairittha_improving_2020} &
    HAR-S &
    6 Aktivitäten &
    GYR, ACC &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    CNN &
    Dropout &
    Supervised Learning, On-Device Fine-Tuning \\
  \cite{mairittha_-device_2019} &
    HAR-S &
    6 Aktivitäten &
    ACC &
    Segmentierung, Feature-Berechnung &
    Shallow &
    RNN-LSTM &
    Keine Angabe &
    Supervised Learning \\
  \cite{nutter_design_2018} &
    HAR-S &
    9 Aktivitäten &
    GYR, ACC &
    Glättung, Hochpass, Tiefpass, Elimination der Gravitation &
    Non-Shallow &
    CNN &
    Dropout, Batch-Normalization &
    Transfer Learning \\
  \cite{zebin_design_2019} &
    HAR-S &
    5 Aktivitäten &
    GYR, ACC &
    Segmentierung, Windowing, Normalisierung &
    Vorverarbeitete Daten &
    CNN &
    Dropout, Batch-Normalization &
    Supervised Learning \\
  \cite{ravi_deep_2016} &
    HAR-S &
    Mehrere Varianten &
    GYR, ACC &
    Feature-Berechnung, FFT &
    Non-Shallow &
    CNN &
    Weight Decay, Momentum, Dropout &
    Supervised Learning \\ \midrule
  \cite{liang_convolutional_2017} &
    VME &
    Bike, Car, Walk, Train, Metro, Bus, Stationary &
    ACC &
    Elimination der Gravitation, Gleitfenster, Abs. Signalstärke &
    Vorverarbeitete Daten &
    CNN &
    L2-Regularisierung &
    Supervised Learning \\
  \cite{friedrich_transportation_2019} &
    VME &
    Stationary, Walk, Run, Bike, Car, Bus, Train, Metro &
    ACC, GYR, MAG, BAR &
    Datensatzgewichtung, Abs. Signalstärke, Normalisierung &
    Vorverarbeitete Daten &
    RNN-LSTM &
    Dropout &
    Supervised Learning \\ \midrule
  \cite{werner_kontinuierliche_2020} &
    VME &
    Walk, Bike, Car, Bus, Tram, Train &
    GNSS, ACC, ROT, MAG &
    Skalierung, Interpolation, AHRS, Glättung &
    Vorverarbeitete Daten &
    RNN-LSTM und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning, Validierung mith. Semi-Supervised Learning \\
  \cite{stojanov_continuous_2020} &
    VME &
    Walk, Bike, Car, Bus, Tram, Train, Boat &
    GNSS, ACC, ROT, MAG &
    AHRS, Normalisierung, Alignment, Abs. Signalstärke, Downsampling, FFT, Gleitfenster, Segmentierung &
    Shallow &
    CNN und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning \\
  \cite{matusek_anwendung_2019} &
    VME &
    Walk, Bike, Car, Bus, Tram, Train &
    GNSS, ACC, ROT, MAG &
    Interpolation und Alignment, GPS-Korrektur, Rauschfilterung über Moving Average, Zeitfenster &
    Vorverarbeitete Daten &
    FFN (Kernkonzept) &
    Early Stopping &
    Supervised Learning \\ \bottomrule
  \end{tabular}
  \caption[Vergleichender Überblick über verwandte Arbeiten.]{\footnotesize{Vergleichender Überblick über verwandte Arbeiten. Abkürzungen wie folgt. Kategorien: VME (Verkehrsmittelerkennung), VME-W (VME auf Wearables), VME-S (VME auf Smartphones), HAR (Human Activity Recognition), HAR-S (HAR auf Smartphones). Daten: ACC (Akzelerometer), GYR (Gyrosensor), MAG (Magnetometer), BAR (Barometer - Luftdruck). Preprocessing: FFT (Fast Fourier Transformation). Modelle: RBM (Restricted Boltzmann Machine), HMM (Hidden Markov Model), DT (Decision Tree), FFN (Feed-Forward-Network), RNN-LSTM (Recurrent Neural Network mit Long-Short-Term-Memory-Neuronen), CNN (Convolutional Neural Network).}}
  }
  \end{table}
\end{landscape}

\paragraph{Labels und Datengrundlage:} Auf Machine-Learning basierende HAR-Ansätze wie \cites{chen_deep_2015, ravi_deep_2017, kwapisz_activity_2011, jahangiri_applying_2015, nurhanim_classification_2017, zeng_convolutional_2014, abu_alsheikh_deep_2015, inoue_deep_2018}, die keinen expliziten Fokus auf Edge-Deployment oder die Verkehrsmittelerkennung besitzen, wurden in der Tabelle nicht berücksichtigt. In der Übersicht spiegelt sich die Beobachtung aus \cite{demrozi_human_2020} wieder, dass die gewählten konzeptuellen Kernkomponenten mitunter sehr heterogen sind. Die Wahl der Labels wird häufig in Abhängigkeit des Testdatensatzes durchgeführt, welcher zur Evaluation des jeweiligen Konzeptes verwendet wird. Die Ansätze sind meist nicht auf diese Labels beschränkt und können flexibel auf eine andere Auswahl (durch Modifikation einzelner Komponenten) von Labels erweitert oder reduziert werden. \cite{ravi_deep_2016} testen ihren Ansatz beispielsweise auf verschiedenen Datensätzen, mit verschiedenen zu klassifizierenden Labels. In manchen Ansätzen, die wie \cite{hemminki_accelerometer-based_2013} das Ensemble Learning nutzen, würde dies über das Hinzufügen und Entfernen der partiellen Klassifikatoren möglich sein. Weiterhin ist auch die Wahl der Daten, auf deren Grundlage die Klassifikation stattfindet, häufig wie in \cite{ravi_deep_2016} an die Verfügbarkeit der Sensortypen im Evaluationsdatensatz gebunden. \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017,byon_real-time_2014} beziehen ihre Datensätze aus eigenen Aufzeichnungen, teils werden jedoch nur wenige Angaben zur Menge der Daten und zur Aufzeichnung selbst gemacht. \cites{zebin_design_2019,nutter_design_2018,bhattacharya_smart_2016,mairittha_-device_2019,radu_towards_2016,friedrich_transportation_2019} nutzen öffentlich verfügbare Datensätze, teils aus anderen Forschungsarbeiten.

\paragraph{Vorverarbeitung:} In der Vorverarbeitung und den genutzten Features zeigen sich weitere Unterschiede und Gemeinsamkeiten zwischen den einzelnen Konzepten. Eine Gemeinsamkeit besteht zunächst darin, dass in den meisten verwandten Arbeiten die sequentiellen Daten explizit in Segmente unterteilt werden, die Gleitfenstermethode wird hierbei häufig mit verwendet. Außerdem wird der Gravitationsvektor der Akzelerometerdaten in den meisten verwandten Arbeiten explizit als konzeptuell störender Faktor identifiziert und infolgedessen eliminiert. Auch die Skalierung der Daten wird in den meisten Arbeiten explizit als Bestandteil des Vorverarbeitungskonzepts beschrieben. Darüberhinausgehend unterscheiden sich die Konzepte im Rahmen des wissenschaftlichen Diskurses. Die Notwendigkeit und konkrete Strategien zur Synchronisation oder dem Alignment beschreiben die Movebis-Arbeiten \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} als essenziellen Bestandteil der Datenvorverarbeitung, hingegen argumentieren \cite{mairittha_improving_2020}, dass bei der Aufzeichnung der Sensoren auf demselben Gerät keine Synchronisation notwendig sei. Möglicherweise ist dieser Widerspruch zurückführbar auf die unterschiedlichen Eigenschaften und Inkonsistenzen der Datensätze und das starke Downsampling und die Interpolation auf $1Hz$ in \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020}. Eine explorative Analyse des Datensatzes sollte bei der Differenzierung des Konzepts durchgeführt werden \cite[S. 15ff]{sosnovshchenko_machine_2018}, inklusive einer Analyse der Gewichtungen der Labels im Datensatz. Sind diese unausgeglichen, lernt das Machine-Learning-Modell unter Umständen ungleichmäßig (\textit{Bias}). Die Gleichgewichtung der Labels ist beispielsweise expliziter Bestandteil der Arbeit von \cite{friedrich_transportation_2019,mairittha_-device_2019}.

Die verwandten Arbeiten differenzieren sich weiter in der Entscheidung, ob die aufgezeichneten Daten nur verlustfrei transformiert werden (z.B. durch Segmentierung und Skalierung), oder im Voraus einer Glättung und weiteren verlustbehafteten Vorverarbeitungsmethoden (z.B. Tiefpass, Hochpass) unterzogen werden. In vielen verwandten Arbeiten wie \cite{nutter_design_2018} und auch in einer Metaanalyse von 2010 \cite{figo_preprocessing_2010} wird auf die grundlegende Problematik hingewiesen, dass die Sensordaten verrauscht sein können, und dass sich deshalb zumindest eine Glättung und die Anwendung von Frequenzbandfiltern anbietet. Es finden sich aber auch Ansätze wie \cite{mairittha_improving_2020}, welche bewusst keine dieser Signalverarbeitungsmethoden anwenden, mit der Argumentation, dass das jeweilige Machine-Learning-Modell trotzdem eine geeignete interne Repräsentation erlernen könne.

\paragraph{Machine-Learning-Modelle und Features:} Analog zur Vorverarbeitung ist auch die Wahl der konkreten Eingaben für das Machine-Learning-System sehr unterschiedlich. In einem Teil der Arbeiten werden die vorverarbeiteten Daten direkt als Input verwendet, andere wiederum erzeugen Shallow Features durch Transformationen oder die Aggregation der Segmentdaten. Hinzu kommen Ansätze, welche ein gesondertes Machine-Learning-Modell einsetzen, um eine effizientere Feature-Repräsentation zu erzeugen. \cite{nutter_design_2018} konnten so beispielsweise ohne Verlust der Ergebnisqualität 561 manuell erstellte (Shallow) Features auf 100 Non-Shallow-Features reduzieren. Die letztendlich gewählten Features sind oft eng gekoppelt an die Konfiguration der zentralen Machine-Learning-Modelle. Beispielsweise können die vorverarbeiteten Sensordaten in Spektrogramme überführt werden, für die Klassifikation über CNNs \cite{ravi_deep_2016}. \cite{demrozi_human_2020} zeigt, dass generell verschiedene Modelle gewählt werden können, ohne einen durch seine Ergebnisqualität signifikant herausstechenden Ansatz. Sowohl neuronale Netzwerke, als auch herkömmliche Machine-Learning-Modelle finden sich verteilt über die verwandten Arbeiten, auch im Rahmen der Verkehrsmittelererkennung auf Smartphones \cite{byon_real-time_2014,hemminki_accelerometer-based_2013}. Als expliziter Bestandteil der meisten Konzepte wird auch eine auf das Modell angepasste Regularisierung durchgeführt, beispielsweise wird die Dropout-Regularisierung häufig in Verbindung mit CNNs verwendet, um die Ergebnisqualität zu verbessern.

\paragraph{Training:} Abschließend lässt sich zur Forschungsübersicht erwähnen, dass zum Training der Modelle grundsätzlich verschiedene Methoden angewandt werden können, das Reinforcement Learning findet sich allerdings in keiner der betrachteten Arbeiten wieder. Die Trainingsansätze sind nicht durch die Verfügbarkeit von Trainingsdaten limitiert, entweder durch die Nutzung eines der verschiedenen öffentlichen Datensatze oder durch die Aufzeichnung neuer Daten. Letzteres ist mit verhältnismäßig geringem Aufwand realisierbar, dies zeigen \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017,byon_real-time_2014}. Daher ist es nicht verwunderlich, dass die betrachteten Ansätze alle Varianten des Supervised Learning nutzen. \cite[S. 30]{werner_kontinuierliche_2020} erweitert zur Validierung des Modells den Trainingsdatensatz zusätzlich um ein Verfahren aus dem Semi-Supervised Learning. \cite{nutter_design_2018} wenden auf bestehenden CNNs darüberhinaus das Transfer Learning an, durch Abwandlung der äußeren Netzwerkschichten und Beibehaltung der (auf Bildern) vortrainierten Gewichtungen. Auch \cite{mairittha_-device_2021} nutzen eine Variante des Transfer Learnings, mit der Besonderheit, dass ein Teil des Netzwerkes vortrainiert und dann auf dem mobilen Gerät eingefroren wird. Ein kleiner Teil des Netzwerkes bleibt veränderlich und kann auf dem Gerät analog zu den Nutzereingaben angepasst werden (\textit{On-Device Fine-Tuning}). \cite{hemminki_accelerometer-based_2013} verwendenen mehrere miteinander kooperierende Klassifikatoren (\textit{Ensemble Learning}).

\section{Movebis-Ansätze}

Die in \Cref{fig:movebis-vergleich} gezeigten Ansätze \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} bilden den Ausgangspunkt für diese Arbeit. Das im Movebis-Projekt initial verwendete heuristische Verfahren zur Verkehrsmittelererkennung konnte durch das in \cite{matusek_anwendung_2019} vorgestellte Machine-Learning-System signifikant in der Ergebnisqualität übertroffen werden. \cite{matusek_anwendung_2019} legt dabei einen starken Fokus auf die Vorverarbeitung der Daten. Als primäres Machine-Learning-Modell wählt \cite{matusek_anwendung_2019} ein FFN. Gegenüber nicht-neuronalen Modellen, hierbei einem Decision Tree und einer SVM, erzeugte das FFN jedoch im Rahmen der Evaluation keine signifikant höhere Ergebnisqualität \cite[S. 96]{matusek_anwendung_2019}. Als weiteres Ergebnis stellte \cite{matusek_anwendung_2019} fest, dass ein tiefergehendes Feature-Engineering zu besseren Ergebnissen hätte führen können. Außerdem bestehe weiteres Potenzial in der sauberen Abtrennung der Verkehrsmittel bei der Aufzeichnung von neuen Aktivitätsdaten, da insbesondere bei den Verkehrsmittelübergängen und bei der Beendigung der Aktivität wiederholt falsche Labels auftraten \cite[S. 98ff]{matusek_anwendung_2019}. Außerdem konnten Lücken in den aufgezeichneten GNSS-Daten festgestellt werden \cite[S. 105]{matusek_anwendung_2019}.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 606 384]{movebis-vergleich.pdf}
\caption[Vergleich der Movebis-VME-Pipelines.]{Vergleich der Movebis-Pipelines zur Verkehrsmittelererkennung. Abbildung schematisch nach den in \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} beschriebenen Konzeptkomponenten.}\label{fig:movebis-vergleich}
\end{figure}

Auf dieser Grundlage entwickelten \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} ihre Konzepte mit größerem Fokus auf die Wahl der Machine-Learning-Modelle. Sie übernehmen Teilschritte der Vorverarbeitung aus \cite{matusek_anwendung_2019}. \cite{werner_kontinuierliche_2020} nutzt ein mehrschichtiges RNN mit LSTM-Neuronen, während \cite{stojanov_continuous_2020} ein CNN zur Verkehrsmittelererkennung einsetzt. Analog zur Architektur der Modelle dienen in \cite{werner_kontinuierliche_2020} die vorverarbeiteten Datenpunkte als Zeitlinien-Eingabe des RNN, gleichzeitig nutzt \cite{stojanov_continuous_2020} eine Auswahl von Shallow-Features als Eingabe für das CNN. Als zusätzlichen Schritt führen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} eine Nachverarbeitung der Ausgaben durch Glättung anhand der Nachbarwerte ein, welche das Ergebnis der Ansätze weiter verbessern konnte. Bei der quantitativen Evaluation der Ansätze wurde insbesondere die Accuracy-Metrik der Netzwerke auf Testdaten bestimmt.

\begin{table}[H]
  \begin{tabular}{lllll}
  Arbeit & Healing & Beste Modell-Output-Accuracy & Accuracy n. Healing \\
  \midrule
  \cite{matusek_anwendung_2019} & \xmark & 67,84 \% n. \cite[S. 98]{stojanov_continuous_2020} & k.A. \\
  \cite{werner_kontinuierliche_2020} & \cmark & 92,00 \% n. \cite[S. 58]{werner_kontinuierliche_2020} & 98,27 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \cite{stojanov_continuous_2020} & \cmark & 92,07 \% n. \cite[S. 90]{stojanov_continuous_2020} & 93,56 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \bottomrule
  \end{tabular}\label{tab:movebis-vergleich}
  \caption{Vergleich von Ergebnisqualität und Modellgröße der Movebis-Ansätze.}
\end{table}

Im Vergleich zeigen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} nach \cite{demrozi_human_2020} typische Accuracy-Werte für die Verkehrsmittelerkennung als Spezialfall der HAR von ca. 92 \%, gegenüber deutlich schlechteren 67,84 \% aus \cite{matusek_anwendung_2019}. Hierbei wird das ganzheitliche Datenverarbeitungssystem ohne Postprocessing betrachtet, eine isolierte Betrachtung der Machine-Learning-Modelle, beispielsweise durch Vergleich bei gleichen Vorverarbeitungsschritten, ist wegen der Unterschiedlichkeit der Vorverarbeitungskonzepte nicht möglich. Lediglich das Postprocessing wurde als Teil der Datenverarbeitungskonzepte separat betrachtet. \cite{werner_kontinuierliche_2020} konnte die Accuracy so nach eigener Evaluation auf 98,27 \% steigern.

Da die Movebis-Architekturen serverseitige Ansätze darstellen, lag bei der Erstellung der dazugehörigen Konzepte kein verstärkter Fokus auf einer Optimierung oder der Messung von Energie- und Speicherverbrauch. Auch die Inferenzzeit wurde in der Evaluation der Arbeiten nicht berücksichtigt. Diese Faktoren sind jedoch von zentraler Bedeutung, um zu beurteilen, welcher dieser Ansätze für die Nutzbarkeit auf mobilen Geräten am besten geeignet ist. Nach den konzeptuellen Beschreibungen der Machine-Learning-Modelle kann die Modellgröße geschätzt werden. Mit $32 bit$ Fließkommazahlen ermitteln sich hierüber Modellgrößen von $335 kB$ für \cite{matusek_anwendung_2019}, $623 kB$ für \cite{werner_kontinuierliche_2020} und $1296 kB$ für \cite{stojanov_continuous_2020}. Die zur Ermittlung dieser Kennzahlen verwendeten Konfigurationen in \Cref{fig:ml-movebis} im Anhang beigefügt. Unklarheiten wie die genaue Lokalisation der Dropout-Schichten oder auch die endgültige Konfiguration der Input-Schicht des CNN aus \cite{stojanov_continuous_2020} schränken die Aussagekraft dieser Werte jedoch ein. Durch die verschiedenen Architekturen lässt sich auch nicht unbedingt von der geschätzten Modellgröße auf den Energieverbrauch oder die Inferenzzeit schließen, denn Parameter können wie in Convolution-Operationen von CNNs in mehreren parallelen Berechnungsoperationen involviert sein.

Auch beteiligt, vor allem am Energie- und Zeitverbrauch, sind die diversen Vorverarbeitungsschritte der Ansätze. \todo{Vorverarbeitung diesbezüglich analysieren}

% Konzepte erzielen zwar gute Ergebnisse, lösen Problem aber nicht hinreichend, weil:
% - Keine Lösungen für die Portierung und Optimierung
% - Keine Aussagen zu Speicherverbrauch und Energieverbrauch der Modelle
% - Fensterlängen von 30s und mehr sind unbrauchbar für Echtzeit-Use-Cases

\section{HAR auf Smartphones}

\section{VME auf Smartphones}

\section{Modelloptimierung}

% Wahl der Segmentlänge
% \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} betrachtet Segmente von $10s$ bis $180s$ Länge. Es lässt sich vermuten, dass die Präzision der Klassifikation bei kürzeren Segmentlängen geringer ist, wie die experimentellen Daten aus \cite{matusek_anwendung_2019} suggerieren. Wie in \Cref{sec:datenerfassung-und-verarbeitung} gezeigt, ist es durch Interpolation der verschiedenen Spuren möglich, diese im Rahmen der Synchronisation zu beliebigen Raten abzutasten. Bei näherer Betrachtung fällt hierbei auf, dass \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} Datenpunkte mit $1Hz$ (Abtastrate des GNSS-Systems) abtasten, die mit deutlich höheren Frequenzen im dreistelligen Hertz-Bereich aufgenommenen Beschleunigungs-, Auslenkungs- und Orientierungsdaten also stark reduziert werden (Downsampling). Vermutlich bietet dies eine Möglichkeit zur Verbesserung der Konzepte aus \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020}, unter der Berücksichtigung, dass mit $1Hz$ Abtastrate lediglich Bewegungsabläufe mit Frequenzen $f \leq 0.5Hz$ nach dem Nyquist-Shannon-Abtasttheorem\footnote{\url{https://de.wikipedia.org/wiki/Nyquist-Shannon-Abtasttheorem} (Abgerufen am 14.4.2021)} erhalten bleiben, Frequenzen $f > 0.5Hz$ tragen zum Rauschen der abgetasteten Daten bei. Alternativ wäre daher auch ein Upsampling der korrigierten GNSS-Daten auf eine höhere Frequenz von ca. $100 Hz$ möglich. \cite{banos_window_2014} konnten zeigen, dass sich unter dieser Voraussetzung insbesondere kürzere Segmente von $0.25s$ bis $2s$ Länge für die Aktivitätserkennung eignen, gegenüber den von \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} verwendeten Segmentlängen von $10s$ bis $180s$.
