\chapter{Verwandte Arbeiten}\label{ch:verwandte-arbeiten}

In diesem Kapitel wird näher auf die wissenschaftlichen Arbeiten eingegangen, deren Forschungsthema und Anforderungen sich mit dem dieser Arbeit stark überschneiden. Dazu wird zunächst ein taxonomischer Überblick über Kategorien gegeben, in welche sich verwandte Arbeiten eingliedern lassen. Anschließend werden die Konzepte und Ergebnisse näher diskutiert und verglichen.

\section{Forschungsüberblick}

Der Forschungsbereich Machine Learning erhält aktuell eine große Aufmerksamkeit, allein in 2020 wurden geschätzt 25800 Publikationen mit dem Begriff \enquote{Machine Learning} im Titel veröffentlicht\footnote{Quelle: Google Scholar, erweiterte Suchfunktion. Teile dieser Ergebnisse können auch wiss. Artikel, Patente oder ähnliche Veröffentlichungen ohne garantierte wiss. Qualität (z.B. durch Peer-Review) sein.}. Ein Teil dieser Arbeiten fokussiert sich auf den Fachbereich \acrshort{har}, \cite{demrozi_human_2020} zählten in 2020 insgesamt 149 wissenschaftliche Publikationen, davon 53 mit Fokus auf Deep Learning und 96 mit Fokus auf traditionellen Machine-Learning-Ansätzen. Dabei sind die auf Deep Learning basierenden Ansätze in der Erkennungsqualität nur marginal überlegen, mit einer durchschnittlichen Trefferquote von $93.0\%$ gegenüber $92.2\%$. Die meisten der in \cite{demrozi_human_2020} analysierten Arbeiten nutzen Akzelerometerdaten, gefolgt von Gyrosensordaten, Magnetometerdaten und weiteren Sensordaten. Unter den Ansätzen befinden sich teils aber auch unkonventionelle Ideen, \cite{wang_sound-based_2019} verwenden beispielsweise das Mikrofon als Sensor. Um die verwandten Arbeiten aus den über 100 Publikationen (neben relevanten Metaanalysen) zu extrahieren, wurde systematisch und anforderungsbezogen gesucht und die Referenzen gefundener Arbeiten weiterverfolgt (\textit{Snowballing}). Hierbei werden auch Arbeiten aus dem Bereich HAR berücksichtigt, wenn sich das darin aufgeführte Konzept auf den konkreten Anwendungsfall der Verkehrsmittelerkennung überführen lässt. In der nachfolgenden Tabelle ist eine Auswahl der so gefundenen Arbeiten gegenübergestellt und in verschiedene Kategorien eingeordnet, welche in Verlauf des Kapitels noch erweitert werden. In den unteren zwei Sektionen der Tabelle befinden sich Ansätze, welche eine Verkehrsmittelklassifikation über Machine-Learning-Modelle realisieren, ohne konkreten Fokus auf eine Portierung oder die Lauffähigkeit des Ansatzes auf Smartphones. Unter anderem ordnen sich hier auch die bekannten Movebis-Ansätze, sowie die meisten Forschungsansätze für VME ein. Darüber befinden sich Ansätze, welche einen allgemeineren Klassifikationsschwerpunkt (\acrshort{har}) ohne Fokus auf Verkehrsmittel haben, gleichzeitig jedoch für Smartphones ausgelegt wurden. Im obersten Teil der Tabelle ist ein Ansatz gezeigt, welcher eine Verkehrsmittelklassifikation explizit auf Smartphones über Machine-Learning-Modelle realisiert, sowie eine Arbeit, die nochmals limitiertere Smartwatches betrachtet und somit wertvolle Erkenntnisse für diese Arbeit bieten können.

\begin{landscape}
  \begin{table}[]
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{@{}llp{3cm}p{2cm}p{7cm}p{4cm}p{2cm}p{3cm}p{4cm}@{}}
  \toprule
    Arbeit &
    Kat. &
    Labels &
    Daten &
    Preprocessing &
    Features &
    Modell(e) &
    Regularisierung &
    Training \\ \midrule
  \cite{bhattacharya_smart_2016} &
    \acrshort{har}-W &
    Mehrere Varianten &
    \acrshort{acc} &
    Segmentierung, Abs. Signalstärke, \acrshort{fft} &
    Shallow &
    \acrshort{rbm} &
    Keine Angabe &
    Supervised Learning \\ \midrule
  \cite{hemminki_accelerometer-based_2013}  &
    \acrshort{vme}-S &
    Train, Bus, Stationary, Metro, Tram, Car &
    \acrshort{acc} &
    Tiefpass, Segmentierung, Elimination der Gravitation, Berechnung der Features &
    Shallow &
    \acrshort{dt} &
    Limitierung der Modellgröße &
    Supervised Learning, Ensemble Learning \\
  \midrule
  \cite{mairittha_-device_2021} &
    \acrshort{har}-S &
    12 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} &
    Keine Angabe &
    Supervised Learning, Transfer Learning, On-Device Fine-Tuning \\
  \cite{mairittha_improving_2020} &
    \acrshort{har}-S &
    6 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Abs. Signalstärke, Segmentierung &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    Dropout &
    Supervised Learning, On-Device Fine-Tuning \\
  \cite{mairittha_-device_2019} &
    \acrshort{har}-S &
    6 Aktivitäten &
    \acrshort{acc} &
    Segmentierung, Feature-Berechnung &
    Shallow &
    \acrshort{rnn}-\acrshort{lstm} &
    Keine Angabe &
    Supervised Learning \\
  \cite{nutter_design_2018} &
    \acrshort{har}-S &
    9 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Glättung, Hochpass, Tiefpass, Elimination der Gravitation &
    Non-Shallow &
    \acrshort{cnn} &
    Dropout, Batch-Normalization &
    Transfer Learning \\
  \cite{zebin_design_2019} &
    \acrshort{har}-S &
    5 Aktivitäten &
    \acrshort{gyr}, \acrshort{acc} &
    Segmentierung, Windowing, Normalisierung &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    Dropout, Batch-Normalization &
    Supervised Learning \\
  \cite{ravi_deep_2016} &
    \acrshort{har}-S &
    Mehrere Varianten &
    \acrshort{gyr}, \acrshort{acc} &
    Feature-Berechnung, \acrshort{fft} &
    Non-Shallow &
    \acrshort{cnn} &
    Weight Decay, Momentum, Dropout &
    Supervised Learning \\ \midrule
  \cite{liang_convolutional_2017} &
    \acrshort{vme} &
    Bike, Car, Walk, Train, Metro, Bus, Stationary &
    \acrshort{acc} &
    Elimination der Gravitation, Gleitfenster, Abs. Signalstärke &
    Vorverarbeitete Daten &
    \acrshort{cnn} &
    L2-Regularisierung &
    Supervised Learning \\
  \cite{friedrich_transportation_2019} &
    \acrshort{vme} &
    Stationary, Walk, Run, Bike, Car, Bus, Train, Metro &
    \acrshort{acc}, \acrshort{gyr}, \acrshort{mag}, BAR &
    Datensatzgewichtung, Abs. Signalstärke, Normalisierung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} &
    Dropout &
    Supervised Learning \\ \midrule
  \cite{werner_kontinuierliche_2020} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    Skalierung, Interpolation, \acrshort{ahrs}, Glättung &
    Vorverarbeitete Daten &
    \acrshort{rnn}-\acrshort{lstm} und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning, Validierung mith. Semi-Supervised Learning \\
  \cite{stojanov_continuous_2020} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train, Boat &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    \acrshort{ahrs}, Normalisierung, Alignment, Abs. Signalstärke, Downsampling, \acrshort{fft}, Gleitfenster, Segmentierung &
    Shallow &
    \acrshort{cnn} und Postprocessing &
    Dropout, Early Stopping &
    Supervised Learning \\
  \cite{matusek_anwendung_2019} &
    \acrshort{vme} &
    Walk, Bike, Car, Bus, Tram, Train &
    \acrshort{gnss}, \acrshort{acc}, ROT, \acrshort{mag} &
    Interpolation und Alignment, GPS-Korrektur, Rauschfilterung über Moving Average, Zeitfenster &
    Vorverarbeitete Daten &
    FFN (Kernkonzept) &
    Early Stopping &
    Supervised Learning \\ \bottomrule
  \end{tabular}
  \caption[Vergleichender Überblick über eine Auswahl verwandte Arbeiten.]{\footnotesize{Vergleichender Überblick über eine Auswahl verwandte Arbeiten. Abkürzungen wie folgt. Kategorien: \acrshort{vme} (Verkehrsmittelerkennung), \acrshort{vme}-W (\acrshort{vme} auf Wearables), \acrshort{vme}-S (\acrshort{vme} auf Smartphones), \acrshort{har} (Human Activity Recognition), \acrshort{har}-S (\acrshort{har} auf Smartphones). Daten: \acrshort{acc} (Akzelerometer), \acrshort{gyr} (Gyrosensor), \acrshort{mag} (Magnetometer), BAR (Barometer - Luftdruck). Preprocessing: \acrshort{fft} (Fast Fourier Transformation). Modelle: \acrshort{rbm} (Restricted Boltzmann Machine), \acrshort{dt} (Decision Tree), FFN (Feed-Forward-Network), \acrshort{rnn}-\acrshort{lstm} (Recurrent Neural Network mit Long-Short-Term-Memory-Neuronen), \acrshort{cnn} (Convolutional Neural Network).}}
  }
  \end{table}
\end{landscape}

Die Übersicht zeigt eine engere Auswahl der verwandten Arbeiten. Analysiert wurden darüber hinaus beispielsweise auch \cites{chen_deep_2015, ravi_deep_2017, kwapisz_activity_2011, jahangiri_applying_2015, nurhanim_classification_2017, zeng_convolutional_2014, abu_alsheikh_deep_2015, inoue_deep_2018}. In der Übersicht spiegelt sich die Beobachtung aus \cite{demrozi_human_2020} wieder, dass die gewählten konzeptuellen Kernkomponenten der Datenverarbeitungspipelines mitunter sehr heterogen sind. Dies erschwert die Auswahl vielversprechender und häufig eingesetzter Komponenten durch die Betrachtung konzeptioneller Überschneidungen. Die nachfolgenden Abschnitte dissektionieren daher zunächst allgemeine Gemeinsamkeiten und Unterschiede der betrachteten Arbeiten.

\paragraph{Labels und Datengrundlage:} Beginnend mit der Auswahl der Labels wird diese häufig in Abhängigkeit des Testdatensatzes durchgeführt, welcher zur Evaluation des jeweiligen Konzeptes verwendet wird. Die Ansätze sind meist nicht auf diese Labels beschränkt und können flexibel auf eine andere Auswahl (durch Modifikation einzelner Komponenten) erweitert oder reduziert werden. \cite{ravi_deep_2016} testen ihren Ansatz beispielsweise auf verschiedenen Datensätzen, mit verschiedenen zu klassifizierenden Labels. In manchen Ansätzen, die wie \cite{hemminki_accelerometer-based_2013} Ensemble Learning nutzen, ist dies möglich über das Hinzufügen, Modifizieren und Entfernen der partiellen Klassifikatoren. Weiterhin ist auch die Wahl der Daten, auf deren Grundlage die Klassifikation stattfindet, häufig wie in \cite{ravi_deep_2016} an die Verfügbarkeit der Sensortypen im Evaluationsdatensatz gebunden. \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017} und beispielsweise auch \cite{byon_real-time_2014} beziehen ihre Datensätze aus eigenen Aufzeichnungen, teils werden jedoch nur wenige Angaben zur Menge der Daten und zur Aufzeichnung selbst gemacht. Dies limitiert die allgemeine Reproduzierbarkeit der Arbeiten \cite[S. 14]{demrozi_human_2020}. \cites{zebin_design_2019,nutter_design_2018,bhattacharya_smart_2016,mairittha_-device_2019,radu_towards_2016,friedrich_transportation_2019} nutzen öffentlich verfügbare Datensätze, teils auch aus anderen Forschungsarbeiten.

\paragraph{Vorverarbeitung:} Eine Gemeinsamkeit der betrachteten Konzepte besteht darin, dass in den meisten verwandten Arbeiten die sequentiellen Daten explizit in Segmente unterteilt werden. Die Gleitfenstermethode wird hierbei häufig mit verwendet. Außerdem wird der Gravitationsvektor der Akzelerometerdaten in den meisten verwandten Arbeiten explizit als konzeptuell störender Faktor identifiziert und infolgedessen eliminiert. Auch die Skalierung der Daten wird in einigen Arbeiten explizit als Bestandteil des Vorverarbeitungskonzepts beschrieben.

Die Vorverarbeitung ist jedoch auch Gegenstand unterschiedlicher Herangehensweisen. Die Notwendigkeit und konkrete Strategien zur Synchronisation oder dem Alignment beschreiben die Movebis-Arbeiten \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} als essenziellen Bestandteil der Datenvorverarbeitung, hingegen argumentieren \cite{mairittha_improving_2020}, dass bei der Aufzeichnung der Sensoren auf demselben Gerät keine Synchronisation notwendig sei. Möglicherweise ist dieser Widerspruch zurückführbar auf die unterschiedlichen Eigenschaften und Inkonsistenzen der Datensätze und das starke Downsampling und die Interpolation auf $1Hz$ in \cites{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020}. Eine explorative Analyse des Datensatzes kann zur Klärung herangezogen werden, inklusive einer Analyse der Gewichtungen der Labels im Datensatz \cite[S. 15ff]{sosnovshchenko_machine_2018}. Sind diese unausgeglichen, lernt das Machine-Learning-Modell unter Umständen ungleichmäßig (\textit{Bias}). Die Gleichgewichtung der Labels ist beispielsweise expliziter Bestandteil der Arbeit von \cite{friedrich_transportation_2019,mairittha_-device_2019}.

Die verwandten Arbeiten differenzieren sich weiter in der Entscheidung, ob die aufgezeichneten Daten nur praktisch verlustfrei transformiert werden (z.B. durch Segmentierung und Skalierung), oder im Voraus einer Glättung und weiteren verlustbehafteten Vorverarbeitungsmethoden (z.B. Tiefpass, Hochpass) unterzogen werden. In vielen verwandten Arbeiten wie \cite{nutter_design_2018} und auch in einer Metaanalyse von 2010 \cite{figo_preprocessing_2010} wird auf die grundlegende Problematik hingewiesen, dass die Sensordaten verrauscht sein können, und dass sich deshalb zumindest eine Glättung und die Anwendung von Frequenzbandfiltern anbietet. Es finden sich aber auch Ansätze wie \cite{mairittha_improving_2020}, welche bewusst keine dieser Signalverarbeitungsmethoden anwenden, mit der Argumentation, dass das jeweilige Machine-Learning-Modell trotzdem eine geeignete interne Repräsentation erlernen könne. \cite{demrozi_human_2020} beobachten, dass eine entsprechende Vorverarbeitung vor allem bei traditionellen Modellen außerhalb des Deep-Learning angewandt wird. Deep-Learning-Ansätze seien nach \cite[S. 14]{demrozi_human_2020} nicht zwingend auf eine transformative Datenvorverarbeitung angewiesen.

\paragraph{Machine-Learning-Modelle und Features:} Analog zur Vorverarbeitung ist auch die Wahl der konkreten Eingaben für das Machine-Learning-System sehr unterschiedlich. In einem Teil der Arbeiten werden die vorverarbeiteten Daten direkt als Input verwendet, andere wiederum erzeugen Shallow Features durch Transformationen oder die Aggregation der Segmentdaten. In der Regel werden Shallow Features bei traditionellen Machine-Learning-Ansätzen verwendet, aktuelle Deep-Learning-Ansätze sind nicht zwingend auf die Auswahl von Features angewiesen und erreichen auch auf Zeitliniendaten sehr gute Ergebnisqualitäten \cite[S. 2]{friedrich_combining_2020}. Hinzu kommen Ansätze, welche ein gesondertes Machine-Learning-Modell einsetzen, um eine effizientere Feature-Repräsentation zu erzeugen. \cite{nutter_design_2018} konnten so beispielsweise ohne Verlust der Ergebnisqualität 561 manuell erstellte (Shallow) Features auf 100 Non-Shallow-Features reduzieren. Die letztendlich gewählten Features sind oft eng gekoppelt an die Konfiguration der zentralen Machine-Learning-Modelle, betrachtbar ist also ein Co-Design von Modellen und Vorverarbeitungsschritten. Beispielsweise können die vorverarbeiteten Sensordaten in Spektrogramme überführt werden, für die bildhafte Klassifikation über \acrshort{cnn}s \cite{ravi_deep_2016}. \cite{demrozi_human_2020} zeigt hierbei, dass generell verschiedene Modelle gewählt werden können, ohne einen durch seine Ergebnisqualität signifikant herausstechenden Ansatz.

\begin{figure}[h]
  \includegraphics[width=0.5\linewidth, bb=0 0 287 148]{deep-learning-trad-vergleich.pdf}
  \caption[Die Performanz von Deep-Learning-Ansätzen im Vergleich zu traditionellen Machine-Learning-Modellen.]{Die Performanz von Deep-Learning-Ansätzen im Vergleich zu traditionellen Machine-Learning-Modellen nach \cite[S. 7]{alom_state---art_2019}. Skalierung nicht linear oder maßstabsgerecht, nur zur Illustration.}\label{fig:deep-learning-trad-vergleich}
\end{figure}

Seit deren Erfindung in 2015 \cite{lecun_deep_2015} werden Deep-Learning-Modelle in der KI-Forschung als vielversprechendere Ansätze im Vergleich zu traditionellen Verfahren betrachtet, da sich mit diesen komplexere Probleme lösen lassen, sofern ausreichend Trainingsdaten vorliegen \cite[S. 7]{alom_state---art_2019}. Analog zu \Cref{fig:deep-learning-trad-vergleich} scheint HAR als Anwendungsfall der Machine-Learning-Klassifikation prinzipiell jedoch in einen Komplexitätsbereich zu fallen, der sowohl durch traditionelle, als auch durch Deep-Learning-Ansätze bedienbar ist. Sowohl Deep-Learning-Modelle, als auch traditionelle Machine-Learning-Modelle finden sich verteilt über die Arbeiten der Forschungsdomäne HAR. \cite[S. 14]{demrozi_human_2020} beobachten, dass die Entscheidung zwischen traditionellen Modellen und Deep-Learning-Ansätzen vor allem von der verfügbaren Rechenleistung abhängt, neben den verfügbaren Daten. Die Entscheidungsgrundlage ist also der Tradeoff. Traditionelle Modelle seien typischerweise weniger rechenaufwändig und benötigten weniger Trainingsdaten, was diese Modelle wiederum attraktiver für durch Hardware limitierte Anwendungen wirken lässt.

\paragraph{Training:} Abschließend lässt sich zur Forschungsübersicht erwähnen, dass zum Training der Modelle grundsätzlich verschiedene Methoden angewandt werden können. Das Reinforcement Learning findet sich allerdings in keiner der betrachteten Arbeiten wieder. Die Trainingsansätze sind nicht durch die Verfügbarkeit von Trainingsdaten limitiert, entweder durch die Nutzung eines der verschiedenen öffentlichen Datensatze oder durch die Aufzeichnung neuer Daten. Der wesentliche limitierende Faktor in den Trainingsdaten liegt nach \cite[S. 14]{demrozi_human_2020} häufig in der fehlenden Heterogenität, bedingt durch die Aufzeichnung von zu wenigen Personen, Geräten und Tragepositionen. Dies erhöhe den Generalisierungsfehler auf neuen Daten. Dabei ist die Aufzeichnung neuer Daten mit verhältnismäßig geringem Aufwand realisierbar, dies zeigen \cites{liang_convolutional_2017,hemminki_accelerometer-based_2013,ravi_deep_2017}. Durch die gute Verfügbarkeit der Trainingsdaten wird typischerweise das Supervised Learning als primäres Trainingsverfahren angewendet. \cite[S. 30]{werner_kontinuierliche_2020} erweitert den Trainingsdatensatz zur Validierung des Modells zusätzlich um ein Verfahren aus dem Semi-Supervised Learning. \cite{nutter_design_2018} wenden auf bestehenden \acrshort{cnn}s darüberhinaus das Transfer Learning an, durch Abwandlung der äußeren Netzwerkschichten und Beibehaltung der (auf Bildern) vortrainierten Gewichtungen. Auch \cite{mairittha_-device_2021} nutzen eine Variante des Transfer Learnings, mit der Besonderheit, dass ein Teil des Netzwerkes vortrainiert und dann auf dem mobilen Gerät eingefroren wird. Ein kleiner Teil des Netzwerkes bleibt veränderlich und kann auf dem Gerät analog zu den Nutzereingaben angepasst werden (\textit{On-Device Fine-Tuning}). \cite{hemminki_accelerometer-based_2013} verwendenen mehrere miteinander kooperierende Klassifikatoren, zur Unterscheidung jeweils zueinander ähnlicher Klassen (\textit{Ensemble Learning}). Als expliziter Bestandteil der meisten Trainingskonzepte wird auch eine auf das Modell angepasste Regularisierung durchgeführt, beispielsweise wird die Dropout-Regularisierung häufig in Verbindung mit \acrshort{cnn}s verwendet, um die Ergebnisqualität zu verbessern.

\section{Movebis-Ansätze}

Die in \Cref{fig:movebis-vergleich} gezeigten Ansätze \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} bilden den Ausgangspunkt für diese Arbeit. Das im Movebis-Projekt initial verwendete heuristische Verfahren zur Verkehrsmittelerkennung konnte durch das in \cite{matusek_anwendung_2019} vorgestellte Machine-Learning-System signifikant in der Ergebnisqualität übertroffen werden. \cite{matusek_anwendung_2019} legt dabei einen starken Fokus auf die Vorverarbeitung der Daten. Als primäres Machine-Learning-Modell wählt \cite{matusek_anwendung_2019} ein FFN. Gegenüber nicht-neuronalen Modellen, hierbei einem Decision Tree und einer \acrshort{svm}, erzeugte das FFN jedoch analog zu \cite{demrozi_human_2020} im Rahmen der Evaluation keine signifikant höhere Ergebnisqualität \cite[S. 96]{matusek_anwendung_2019}. Als weiteres Ergebnis stellte \cite{matusek_anwendung_2019} jedoch fest, dass ein tiefergehendes Feature-Engineering zu besseren Ergebnissen hätte führen können. Außerdem bestehe weiteres Potenzial in der sauberen Abtrennung der Verkehrsmittel bei der Aufzeichnung von neuen Aktivitätsdaten, da insbesondere bei den Verkehrsmittelübergängen und bei der Beendigung der Aktivität wiederholt falsche Labels auftraten \cite[S. 98ff]{matusek_anwendung_2019}. Außerdem konnten Lücken in den aufgezeichneten \acrshort{gnss}-Daten festgestellt werden \cite[S. 105]{matusek_anwendung_2019}.

\begin{figure}[h]
\includegraphics[width=\linewidth, bb=0 0 606 384]{movebis-vergleich.pdf}
\caption[Vergleich der Movebis-\acrshort{vme}-Pipelines.]{Vergleich der Movebis-Pipelines zur Verkehrsmittelerkennung. Abbildung schematisch nach den in \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} beschriebenen Konzeptkomponenten.}\label{fig:movebis-vergleich}
\end{figure}

Auf dieser Grundlage entwickelten \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} ihre Konzepte mit größerem Fokus auf die Wahl der Machine-Learning-Modelle. Sie übernehmen Teilschritte der Vorverarbeitung aus \cite{matusek_anwendung_2019}. \cite{werner_kontinuierliche_2020} nutzt ein mehrschichtiges \acrshort{rnn} mit \acrshort{lstm}-Neuronen, während \cite{stojanov_continuous_2020} ein \acrshort{cnn} zur Verkehrsmittelerkennung einsetzt. Analog zur Architektur der Modelle dienen in \cite{werner_kontinuierliche_2020} die vorverarbeiteten Datenpunkte als Zeitlinien-Eingabe des \acrshort{rnn}, gleichzeitig nutzt \cite{stojanov_continuous_2020} eine Auswahl von Shallow-Features als Eingabe für das \acrshort{cnn}. Als zusätzlichen Schritt führen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} eine Nachverarbeitung der Ausgaben durch Glättung anhand der Nachbarwerte ein, welche das Ergebnis der Ansätze weiter verbessern konnte. Bei der quantitativen Evaluation der Ansätze wurde insbesondere die Accuracy-Metrik der Netzwerke auf Testdaten bestimmt.

\begin{table}[h]
  \begin{tabular}{lllll}
  \toprule
  Arbeit & Healing & Beste Modell-Output-Accuracy & Accuracy n. Healing \\
  \midrule
  \cite{matusek_anwendung_2019} & \xmark & 67,84 \% n. \cite[S. 98]{stojanov_continuous_2020} & k.A. \\
  \cite{werner_kontinuierliche_2020} & \cmark & 92,00 \% n. \cite[S. 58]{werner_kontinuierliche_2020} & 98,27 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \cite{stojanov_continuous_2020} & \cmark & 92,07 \% n. \cite[S. 90]{stojanov_continuous_2020} & 93,56 \% n. \cite[S. 98]{stojanov_continuous_2020} \\
  \bottomrule
  \end{tabular}\label{tab:movebis-vergleich}
  \caption{Vergleich von Ergebnisqualität und Modellgröße der Movebis-Ansätze.}
\end{table}

Im Vergleich zeigen \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} nach \cite{demrozi_human_2020} typische Accuracy-Werte für die Verkehrsmittelerkennung als Spezialfall der \acrshort{har} von ca. 92\%, gegenüber deutlich schlechteren 67,84\% aus \cite{matusek_anwendung_2019}. Hierbei wird das ganzheitliche Datenverarbeitungssystem, jedoch ohne Postprocessing, betrachtet. Eine isolierte Betrachtung der Machine-Learning-Modelle, beispielsweise durch Vergleich bei gleichen Vorverarbeitungsschritten, ist wegen der Unterschiedlichkeit der Vorverarbeitungskonzepte nicht möglich. Lediglich das Postprocessing wurde als Teil der Datenverarbeitungskonzepte in \cite{stojanov_continuous_2020} und \cite{werner_kontinuierliche_2020} separat betrachtet. \cite{werner_kontinuierliche_2020} konnte die Accuracy so nach eigener Evaluation auf 98,27\% steigern.

Da die Movebis-Architekturen serverseitige Ansätze darstellen, lag bei der Erstellung der dazugehörigen Konzepte kein verstärkter Fokus auf einer Optimierung oder der Messung von Energie- und Speicherverbrauch. Auch die Inferenzzeit der jeweiligen Pipeline über den Segmenten wurde in der Evaluation der Arbeiten nicht berücksichtigt. Die Eignung der Systeme für Smartphones ist dadurch fraglich. Nach den konzeptuellen Beschreibungen der Machine-Learning-Modelle kann die Modellgröße geschätzt werden. Mit $32 bit$ Fließkommazahlen ermitteln sich hierüber Modellgrößen von $335 kB$ für \cite{matusek_anwendung_2019}, $623 kB$ für \cite{werner_kontinuierliche_2020} und $1296 kB$ für \cite{stojanov_continuous_2020}. Die zur Ermittlung dieser Kennzahlen verwendeten Konfigurationen sind in \Cref{fig:ml-movebis} im Anhang beigefügt. Zumindest die Modellgröße wäre für die Integration in einer App also in einem akzeptablen Rahmen. Unklarheiten wie die genaue Lokalisation der Dropout-Schichten oder auch die finale Konfiguration der Input-Schicht des \acrshort{cnn} aus \cite{stojanov_continuous_2020} schränken die Reproduzierbarkeit und die Aussagekraft dieser Schätzungen jedoch ein. Durch die verschiedenen Architekturen lässt sich auch nicht unbedingt von der geschätzten Modellgröße auf den Energieverbrauch oder die Inferenzzeit schließen, denn Parameter können wie in Convolution-Operationen von \acrshort{cnn}s in mehreren parallelen Berechnungsoperationen involviert sein.

Abschließend lässt sich feststellen, dass insbesondere \cite{werner_kontinuierliche_2020,stojanov_continuous_2020} zwar Ergebnisse auf dem aktuellen Forschungsniveau erzielen, die Konzepte jedoch wegen der von dieser Arbeit abweichenden initialen Problemstellung nicht direkt übernommen werden können. Auch wegen der Interpolation von $1Hz$, welche größere Fensterlängen für eine hinreichende Klassifikationsgüte bedingt, ist die Echtzeitfähigkeit der Konzepte eingeschränkt. Während dies für die nachträgliche Klassifikation von Daten auf Servern kein Problem darstellt, würden Fensterlängen von über $30s$ auch eine entsprechende Wartezeit nach sich ziehen, bevor die Klassifikation auf dem Smartphone nach Start der Aufzeichnung aktiv werden könnte. Dies widerspricht den Anforderungen an die Nutzbarkeit bei Integration in eine vom Nutzer zu bedienende App. Dennoch können Teile der Konzepte für diese Arbeit wiederverwendet werden, insbesondere deren Vor- und Nachverarbeitungsschritte. Die Accuracy-Werte, welche in \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} ermittelt wurden, decken sich mit den metaanalytischen Beobachtungen aus \cite{demrozi_human_2020}. Auch hier zeigt weder das \acrshort{cnn}, noch das \acrshort{rnn} im Vergleich eine signifikant bessere Ergebnisqualität, sofern die jeweiligen Systeme ohne Postprocessing betrachtet werden. Es lässt sich somit vermuten, dass die Wahl einer speziellen Architektur gegenüber einem gezielten Co-Design der Datenverarbeitungspipeline mit dem klassifizierenden Modell keine signifikanten Zugewinne in der Ergebnisqualität verspricht. Dies zu evaluieren, ist Teil der Forschungsfragen dieser Arbeit.

\section{\acrshort{har} auf Smartphones}

Die vorigen Ausführungen zeigen, dass sich die serverseitigen Movebis-Ansätze nicht ohne weitere Anpassungen für den Einsatz auf Smartphones eignen. In der ursprünglichen Implementation kollidieren die Movebis-Ansätze beispielsweise mit der Anforderung an eine geringe Latenz, bedingt durch die große Fensterlänge. \cite{banos_window_2014} zeigen, dass HAR-Verfahren, welche eng mit Verkehrsmittelerkennungsverfahren verwandt sind, auch mit deutlich kürzeren Fensterlängen möglich sind. Entgegen der intuitiven Vermutung stechen hier sogar die Klassifikatoren mit besonders hoher Ergebnisqualität heraus, welche vergleichsweise kurze Fensterlängen von $0,25s$ bis $0,5s$ nutzen \cite[S. 20]{banos_window_2014}. Betrachtet wurden hierbei jedoch auch Ansätze, welche dedizierte Akzelerometer-Systeme mit potenziell höheren Abtastraten und Signalqualitäten bieten, im Vergleich zu Smartphone-Akzelerometern. Die Wartezeit, welche durch die Gleitfenstermethode zu Beginn einer kontinuierlichen Klassifikation notwendig wäre, befindet sich mit diesen Fensterlängen in einem akzeptablen Bereich. Einen weiteren direkten Einfluss auf die Echtzeitfähigkeit hat die Dauer, welche die Verkehrsmittelerkennung für die Berechnung der Inferenz benötigt. Die Kernkomponenten Vorverarbeitung, Klassifikation und Nachverarbeitung tragen jeweils, je nach Komplexität, zur Gesamtinferenzzeit bei.

\subsection{Inferenzzeit}

\cite[S. 6]{zebin_design_2019} führten eine quantitative Analyse der Modell-Inferenzzeit durch. Traditionelle Machine-Learning-Modelle unterschieden sich in deren Betrachtung nicht signifikant von CNN-Modellen und lagen bei $3,53ms$ bis $12,6ms$. Ob diese Daten auf einem Computer oder auf einem Smartphone erfasst wurden, wurde nicht angegeben. Zum Teil sind die beschriebenen Daten auch widersprüchlich, in \cite[S. 8]{zebin_design_2019} übersteigen in der Analyse der Ausführungszeit einzelner Verarbeitungsschritte des Modells bereits einzelne Schritte mit bis zu $244,813ms$ die an anderer Stelle angegebene Gesamtinferenzzeit des Modells. Abgesehen davon konnte die kürzeste Inferenzzeit mit einem regularisierten CNN erreicht werden, welches gleichzeitig auch die höchste Ergebnisqualität, in Form einer Accuracy von $96,4\%$, produzierte. Die Ergebnisse decken sich mit den Analysen in \cite[S. 6]{ravi_deep_2016}, welche auch ein CNN-Modell testeten. Hierbei lag die Inferenzzeit bei $5,7ms$ bis $14,9ms$, wobei explizit angegeben wurde, dass die Unterschiede durch Tests auf unterschiedlichen Smartphones und Prozessoren entstanden. Die gemessenen Inferenzzeiten sind vergleichbar mit der Verarbeitungsdauer einer Fourier-Transformation, welche in denselben experimentellen Bedingungen bei $5,4ms$ bis $42ms$ gemessen wurde \cite[S. 6]{ravi_deep_2016}. Allein diese Arbeit betrachtend, scheinen Machine-Learning-Modelle also keinen besonderen Einfluss auf die Gesamtinferenzzeit zu besitzen. In anderen HAR-Arbeiten zeigen sich jedoch Ausreißer. Das auf LSTM basierende RNN-Modell aus \cite[S. 9]{mairittha_-device_2019} benötigte beispielsweise eine Inferenzzeit von $2846ms$ und damit wesentlich mehr als die langsamste CNN-Konfiguration aus \cite{ravi_deep_2016}. Hierbei ist fraglich, ob eventuell eine suboptimale Implementation vorliegt, denn in einem späteren Ansatz konnten \cite[S. 10]{mairittha_-device_2021} die Inferenzzeit auf $10,6ms$ für ein ähnliches LSTM-Modell senken. Insgesamt lässt sich daher trotz der teilweise vorhandenen experimentellen Unklarheiten vermuten, dass sowohl RNN-Modelle, als auch CNN-Modelle und traditionelle Modelle vergleichsweise gute Inferenzzeiten erreichen können. Ein bestmöglicher Ansatz ist allein anhand der obigen Betrachtungen jedoch nicht sichtbar.

\subsection{Energieverbrauch}

Ein weiterer Faktor, der bei serverseitigen Verkehrsmittelerkennungen wie \cite{matusek_anwendung_2019,werner_kontinuierliche_2020,stojanov_continuous_2020} vernachlässigbar ist, jedoch bei Smartphone-Anwendungen einen essenziellen Faktor darstellt, ist der Energieverbrauch. \cite{ravi_deep_2016,nutter_design_2018,mairittha_improving_2020,mairittha_-device_2021} geben keine Auskunft über diesen Ressourcenparameter. \cite{mairittha_-device_2019} beschreiben, dass deren weiter oben bereits erwähntes RNN-Modell mit einer Inferenzzeit von $2846ms$ den durchschnittlichen Energieverbrauch der Applikation, im Vergleich zu einer Applikation ohne Klassifikator, um $5\%$ erhöht. Das System aus \cite{mairittha_-device_2019} verwendet jedoch auch eine Fensterlänge von $60s$, welche aus bereits genannten Gründen problematisch für die Nutzbarkeit ist und daher mit der Grundanforderung an die Latenz kollidiert. Im Zuge dessen bleiben auch die relevanten experimentellen Bedingungen zur Ermittlung des Energieverbrauchs unklar, wie zum Beispiel, ob kontinuierlich nach Ablauf von $60s$ klassifiziert wurde oder nur einmal alle $60s$. Das mit TensorFlow Lite trainierte, optimierte und exportierte CNN aus \cite[S. 9]{zebin_design_2019} verbrauchte bei dessen experimenteller Evaluation $39,30mW$ in einem kontinuierlichen Inferenzmodus. Neben der Inferenzzeit, bei der anhand der Nutzbarkeit eine Anforderung für die größtmögliche Latenz (wenige Sekunden) definiert werden konnte, ist auch die Definition eines \enquote{guten} Energieverbrauchs problematisch. Hierbei kann beispielsweise einfließen, ob es sich um einen kurzzeitigen Peak-Energieverbrauch, oder um einen langfristigen Durchschnittsverbrauch handelt. Da sich der Energieverbrauch durch die Fläche unter der Kurve bildet, welche Laufdauer mit dem Momentanverbrauch in Verbindung setzt, sind vor allem langfristige Lasten problematisch und sollten vorrangig betrachtet werden. Eine Möglichkeit der Betrachtung der Akzeptierbarkeit eines Energieverbrauchs liegt in dem Vergleich mit dem Verbrauch anderer, alltäglicher Applikationen. \cite[S. 9]{zebin_design_2019} setzen dies beispielsweise in Relation mit der Youtube-App, welche $116mW$ verbrauche, und schlussfolgern, dass $39,30mW$ entsprechend einen akzeptablen kontinuierlichen Energieaufwand darstelle.

\subsection{Speicherverbrauch}

Soll ein Machine-Learning-Modell auf Smartphones lauffähig sein, so stellt neben der Inferenzzeit und dem Energieverbrauch noch der Speicherverbrauch einen zentralen Ressourcenparameter dar, der zur Ermittlung des Tradeoffs betrachtet werden muss. Bei Machine-Learning-Modellen ist es leicht, durch Erhöhung der Größe der internen Repräsentation komplexe Aufgaben besser lösen zu können, sofern kein Overfitting vorliegt. Die betrachteten Modelle aus dem Anwendungsbereich Smartphone-HAR können jedoch auch mit Modellgrößen von wenigen hunderten von Kilobyte zufriedenstellende Ergebnisse erzielen. \cite{mairittha_-device_2021} zeigen beispielsweise mit einem LSTM-RNN im Umfang von $520kB$, dass auch kleine Modelle für die Aktivitätserkennung geeignet sind. Hierbei hängt der Speicherverbrauch indirekt auch mit der Inferenzeit und dem Energieverbrauch zusammen, über die verbrauchte Zeit und Energie bei der Prozessierung der gespeicherten Parameter. Durch Optimierung, in Form einer Verkleinerung des Modells, können somit auch die Inferenzzeit und der Energieverbrauch gesenkt werden. \cite[S. 10]{zebin_design_2019} konnten allein durch 8-Bit-Quantisierung eines 32-Bit-Modells dessen Größe um das bis zu $7,62$-Fache reduzieren, bei einem Verlust der Accuracy von $96,4\%$ auf $93,6\%$. \cite{mairittha_-device_2021} verwenden Pruning zur Verkleinerung des Netzwerks, hierbei konnte eine $1,6$-Fache Reduktion bei einem vernachlässigbarem Verlust der Accuracy von $0,18\%$, sowie eine weitere Reduktion um das $1,7$-Fache durch verlustfreie Kompression erreicht werden.

\subsection{Ergebnisqualität}

Die erreichten Ergebnisqualitäten sind in der nachfolgenden Tabelle dargestellt.

\begin{table}[H]
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{llll}
  \toprule
  Arbeit & Modell & Acc. ($\%$) & Evaluationsgrundlage \\
  \midrule
    \multirow{3}{*}{\cite{ravi_deep_2016}} & Flaches CNN & $95,1$ & 4,4 Mio. Samples, 7 Aktivitäten \cite{esprit_team_of_the_hamlyn_centre_and_the_institute_of_global_health_innovation_imperial_college_london_activemiles_2012} \\
     & Flaches CNN & $98,2$ & 1,1 Mio. Samples, 6 Aktivitäten \cite{wisdm_lab_department_of_computer__information_science_fordham_university_bronx_ny_wisdm_2013} \\
     & Flaches CNN & $95,9$ & 1,9 Mio. Samples, 2 Aktivitäten \cite{daniel_roggen_uci_2013} \\
    \midrule
    \multirow{5}{*}{\cite{zebin_design_2019}} & 4-Layer CNN & $92$ & \multirow{5}{*}{1,3 Mio. Samples, 5 Aktivitäten, Eigener Datensatz} \\
     & Regularisiertes 4-Layer CNN & $96,4$ & \\
     & Quantisiertes 4-Layer CNN & $93,6$ & \\
     & Quadratische SVM & $93,4$ & \\
     & Multi-Layer-Perzeptron & $91$ & \\
    \midrule
    \cite{nutter_design_2018} & MobileNet & $>95$ & 29,1 Mio. Samples, 9 Aktivitäten \cite{garcia-gonzalez_public_2020} \\
    \midrule
    \cite{mairittha_-device_2019} & LSTM-RNN & $97,5$ & 1,1 Mio. Samples, 6 Aktivitäten \cite{wisdm_lab_department_of_computer__information_science_fordham_university_bronx_ny_wisdm_2013}\\
    \cite{mairittha_improving_2020} & 3-Layer CNN & $92$ & 6 Aktivitäten, Eigener Datensatz \\
    \cite{mairittha_-device_2021} & LSTM-RNN & $97,5$ & 12 Aktivitäten, Eigener Datensatz \\
  \bottomrule
  \end{tabular}\label{tab:har-vergleich}
  \caption{Vergleich der Accuracy verschiedener Machine-Learning-Ansätze für HAR auf Smartphones.}
  }
\end{table}

In der Tabelle bestätigt sich die eingangs erwähnte Analyse von \cite{demrozi_human_2020}, mit typischen Accuracy-Werten für den betrachteten Anwendungsfall. Je nach Datensatz und den betrachteten Aktivitäten kann die Accuracy variieren, dies zeigt die starke Abhängigkeit der Ergebnisqualität von der Datengrundlage \cite{ravi_deep_2016}. Gleichzeitig kann bei CNNs beobachtet werden, dass das Hinzufügen von Hidden Layers die Ergebnisqualität erhöht. \cite{zebin_design_2019} zeigen dies, indem sie verschiedene Anzahlen von Hidden Layers betrachten, beginnend bei einem einschichtigen CNN mit $12,9\%$ geringerer Accuracy als ein vierschichtiges Modell. Gleichzeitig erhöht sich die Dauer des Trainings. Die beste Accuracy erzielten \cite{zebin_design_2019} mit dem vierschichtigen Modell, konfiguriert durch eine Filtergröße von $1\times2$ und einer Pooling-Größe von $1\times2$. \cite{zebin_design_2019} betrachteten auch traditionelle Modelle, welche analog zu \cite{demrozi_human_2020} nur marginal schlechter abschnitten als die betrachteten CNN-Architekturen. \cite{nutter_design_2018} nutzten einen besonders umfangreichen Datensatz und konnten über das Transfer Learning von verschiedenen mobilen CNN-Architekturen zeigen, dass hierdurch eine Accuracy von mehr als $95\%$ erreicht werden kann. Am besten schnitt hierbei das in \cite{howard_mobilenets_2017} konzeptionierte MobileNet ab, im Vergleich zu anderen auf dem ImageNet-Datensatz\footnote{\url{https://image-net.org/} (Abgerufen am 13.7.2021)} vortrainierten Netzwerken wie InceptionV3 \cite{szegedy_rethinking_2015}.

\section{\acrshort{vme} und Portabilität auf Smartphones}

In den vorigen Abschnitten wurde gezeigt, wie sich verwandte HAR-Ansätze in ihren, für den Tradeoff relevanten, Charakteristika unterscheiden. Dafür wurden Ansätze betrachtet, welche explizit für Smartphones konzipiert wurden. Diese Ansätze sind jedoch zur Erkennung von Aktivitäten wie \enquote{Gehen}, \enquote{Treppensteigen} oder \enquote{Stehen} gedacht und eignen sich damit in ihrer ursprünglichen Form nicht für die Verkehrsmittelerkennung. Insbesondere steht hierbei die Frage im Raum, ob eine Verkehrsmittelerkennung bezüglich der erforderlichen Komplexität mehr oder weniger Aufwand als HAR-Ansätze erfordert, durch die Unterschiedlichkeiten in den betrachteten Signalverläufen. Diese Frage soll nachfolgend anhand von Arbeiten diskutiert werden, welche ebendiesen spezielleren Anwendungsfall betrachten. Hierbei soll auch darauf eingegangen werden, welche Modifikationen an den diskutierten Ansätzen zur HAR auf Smartphones gegebenenfalls nötig wären.

\begin{table}[H]
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{llllp{5cm}}
  \toprule
  Arbeit & Modell & Acc. ($\%$) & Portierbarkeit als & Evaluationsgrundlage \\
         &        &             & Konzeptbestandteil \\
  \midrule
  \cite{hemminki_accelerometer-based_2013} & Mehrere Decision Trees & $93,60$ & \cmark & Eigener Datensatz, 150h Aufzeichnung, 6 Verkehrsmittel\\
  \cite{reddy_using_2010} & DT und HMM & $93,6$ & \cmark & Eigener Datensatz, 120h Aufzeichnung, 6 Verkehrsmittel \\
  \cite{fang_transportation_2016} & SVM & $86$ & \cmark & HTC-Datensatz \cite{yu_big_2014}, 8311h Aufzeichnung (1249h öffentlich verfügbar), 10 Verkehrsmittel \\
  \midrule
  \cite{liang_convolutional_2017} & 6-Layer-CNN & $94,48$ & \xmark & Eigener Datensetz, 14h Aufzeichnung, 7 Verkehrsmittel \\
  \cite{liono_inferring_2018} & Random Forest & $91$ & \xmark & Crowdsignal-Datensatz \cite{welbourne_crowdsignals_2014}, $>$2000h Aufzeichnung (5h öffentlich verfügbar), 10 Verkehrsmittel \\
  \midrule
  \cite{friedrich_transportation_2019} & LSTM-RNN & $84,22$ & \xmark & \multirow{4}{*}{\parbox{5cm}{SHL-Datensatz \cite{gjoreski_versatile_2017}, 700h Aufzeichnung, 8 Verkehrsmittel}} \\
  \cite{friedrich_combining_2020} & LSTM und CNN & $99,74$ & \xmark & \\
  \cite{antar_comparative_2018} & Random Forest & $92$ & \xmark & \\
  \cite{jeyakumar_deep_2018} & LSTM & $98,1$ & \xmark & \\
  \bottomrule
  \end{tabular}\label{tab:vme-vergleich}
  \caption{Vergleich verschiedener Machine-Learning-Ansätze für VME.}
  }
\end{table}

Die Accuracy der betrachteten Ansätze ist mit einem Median von $93.6\%$ vergleichbar mit der durchschnittlichen Accuracy von HAR-Ansätzen nach \cite{demrozi_human_2020}. Besonders gut schneiden hierbei aktuelle serverseitigen Deep-Learning-Ansätze ab, wie \cite{friedrich_combining_2020} mit $99.74\%$. Während frühe Ansätze wie \cite{reddy_using_2010} noch hauptsächlich auf GNSS-Signalen beruht und Akzelerometersignale als Hilfsmittel evaluiert, gehen aktuelle Ansätze wegen der inhärenten Probleme der GNSS-Signalerfassung dazu über, ausschließlich lokale kinematische Messparameter für die Klassifikation zu verwenden \cite{friedrich_combining_2020}. \cite{friedrich_combining_2020} zeigen, dass bei Verwendung eines Deep-Learning-Ansatzes herausragende Ergebnisse bei minimaler Vorverarbeitung der Daten erreicht werden können. \cite{friedrich_combining_2020} wenden lediglich ein Tiefpassfilter bei $25Hz$ an, sowie einen Skalierungsschritt. Anschließend werden die aufgezeichneten Daten direkt in ein neuronales Netzwerk überführt, welches hauptsächlich aus LSTM-Schichten und Convolution-Schichten zusammengesetzt ist.

\begin{figure}[h]
  \includegraphics[width=\linewidth, bb=0 0 577 239]{friedrich.pdf}
  \caption[Architektur des neuronalen Netzes aus \cite{friedrich_combining_2020}.]{Architektur des neuronalen Netzes aus \cite{friedrich_combining_2020}, welches eine herausragende Ergebnisqualität erzielt. Abkürzungen: Beschleunigung (Acc), Gravitationsvektor (Gra), Winkelauslenkung (Gyr), Lineare Beschleunigung (LAcc), Magnetfeld (Mag), Orientierung (Ori), Luftdruck (Pre)}\label{fig:friedrich}
\end{figure}

\Cref{fig:friedrich} zeigt die Architektur des neuronalen Netzes aus \cite{friedrich_combining_2020}. Die Inputs setzen sich zusammen aus den Hardware-Signalen des Akzelerometer, Gyrosensor, Magnetometer und Barometer, sowie aus durch Software aufbereiteten Signalen lineare Beschleunigung, Gravitation und Orientierung. Auffallend ist bei der Architektur aus \cite{friedrich_combining_2020}, dass sie im Vergleich zu anderen Ansätzen besonders tief ist. \cite[S. 5]{zebin_design_2019} zeigen, dass sich durch eine tiefere Architektur höhere Accuracy-Werte erzielen lassen. Gleichzeitig erhöht sich durch eine solche Architektur auch die Ressourcenintensität. Für das Training der Architektur nutzten \cite{friedrich_combining_2020} Server aus einem spezialisierten High-Performance-Cluster, ausgestattet unter anderem mit einer NVIDIA Tesla P-100 GPU (16GB VRAM) sowie 256 GB RAM und 2 Intel-Xeon-CPU mit je 12 Kernen und 2.2GHz Taktfrequenz. Ausreichend Daten standen hierbei durch Nutzung des SHL-Datensatzes \cite{gjoreski_versatile_2017} mit 700h Material zur Verfügung, jedoch benötigte das Netzwerk insgesamt mehr als 3 Tage zum Training. Auf der spezialisierten Hardware konnte das Netzwerk in 146 Sekunden den Testdatensatz klassifizieren, welcher aus 57573 Samples mit $N_{Sample}=500$ bestand, wobei jeweils 5 Sekunden abgetastet wurden. Dies entspricht rechnerisch einer Inferenzzeit von $2,5ms$, die sich aber in dieser Form nicht direkt auf Smartphones übertragen lässt.

\paragraph{Portabilität:} Auch im Bereich der VME auf Smartphones lassen sich viele Arbeiten identifizieren, welche zwar gute bis sehr gute Ergebnisqualitäten erzielen, jedoch nicht für Smartphones geeignet sind. Beispielsweise ist es bei dem Konzept von \cite{friedrich_combining_2020} fraglich, ob sich das neuronale Netzwerk überhaupt auf Smartphones portieren ließe, in Angesicht der großen Tiefe und der erheblichen Trainingsdauer. Nur wenige der betrachteten VME-Ansätze betrachten die Anwendungsfälle, die sich aus einer Portierung der Ansätze auf Smartphones ergeben, und versuchen den Ressourcenverbrauch möglichst gering zu halten. Meist ist das zentrale Motiv der Forschungsarbeiten die Verbesserung der Ergebnisqualität durch Test neuer Vorverarbeitungsmöglichkeiten oder Abwandlungen in der Architektur der Machine-Learning-Modelle. In den meisten Arbeiten wird das Smartphone lediglich als Datenquelle betrachtet, nicht jedoch als Plattform für die Ausführung der Klassifikation. \cite{hemminki_accelerometer-based_2013} bieten ein auf Smartphones ausführbares Konzept mit einem vergleichsweise flachen Klassifikator-Ansatz. Im Zuge der Evaluation wurde hierbei auch der Energieverbrauch analysiert, im Vergleich mit \cite{wang_accelerometer_2010} und \cite{reddy_using_2010}. Die traditionellen Machine-Learning-Modelle besitzen eine Leistungsaufnahme von $50mW$ bis $240mW$. Es handelt sich jedoch um gerätespezifische Analysen, die zudem dem hardwaretechnischen und softwaretechnischen Fortschritt des vergangenen Jahrzehnts unterliegen. Dennoch können die Ansätze als Baseline-Modell dienen. Als solche sind die Modelle sehr einfach und können als Referenz in der Evaluation dienen oder durch Erweiterung sukzessiv verbessert werden. \cite{hemminki_accelerometer-based_2013} verwendet beispielsweise mehrere Decision Trees, um Verkehrsmittel zu unterscheiden.

\paragraph{Hierarchische versus flache Klassifikation:} Die meisten Machine-Learning-Modelle der verwandten Arbeiten können als monolithisch betrachtet werden und geben als solche einen Vektor aus, anhand dessen alle Verkehrsmittel im One-Hot-Encoding abgelesen werden können. Wie in der Grundlagensektion jedoch diskutiert, ist durch Reduktion der zu klassifizierenden Labels eine Verbesserung der Ergebnisqualität oder eine Verkleinerung der internen Repräsentation des Modells möglich. Daher verwendet \cite{hemminki_accelerometer-based_2013} einen hierarchischen Ansatz, bei dem ein Segment zunächst über einen Decision Tree mit geringer Tiefe in \enquote{Zu Fuß} oder \enquote{Im Fahrzeug} unterschieden wird. Außerdem wird durch einen weiteren Decision Tree detektiert, ob sich der Nutzer im Moment fortbewegt. Wird die Klasse \enquote{Im Fahrzeug} gefunden, so wird diese über einen eigenen Decision Tree nochmals in die einzelnen Fahrzeuge unterschieden. Die Unterscheidung zwischen \enquote{Zu Fuß} und \enquote{Im Fahrzeug} scheint verhältnismäßig einfach zu sein, mit einer Accuracy von $99\%$. Die Unterscheidung der Fahrzeuge wiederum erreicht nur eine Präzision von $80\%$. Hierbei wird also die Betrachtung genutzt, dass verschiedene Verkehrsmittel einfacher zu unterscheiden sind, als andere. Eine solche hierarchische Erkennung findet sich beispielsweise auch in dem aktuelleren Ansatz \cite{liono_inferring_2018} wieder.

\begin{figure}[h]
  \includegraphics[width=\linewidth, bb=0 0 806 345]{generated/conf-mat-rw.pdf}
  \caption[Vergleich der Konfusionsmatrizen von \cite{friedrich_combining_2020} und \cite{hemminki_accelerometer-based_2013}, einem explizit auf Smartphones lauffähigen Konzept.]{Vergleich der Konfusionsmatrizen von \cite{friedrich_combining_2020} (links) und \cite{hemminki_accelerometer-based_2013} (rechts), einem explizit auf Smartphones lauffähigen Konzept.}\label{fig:vme-s-vergleich}
\end{figure}

\paragraph{Verwechslung von Verkehrsmitteln:} In \Cref{fig:vme-s-vergleich} werden die Ansätze \cite{hemminki_accelerometer-based_2013} und \cite{friedrich_combining_2020} verglichen. Dies verdeutlicht noch einmal die herausragende Ergebnisqualität des serverseitigen Deep-Learning-Modells im Vergleich zum Baseline-Modell aus \cite{hemminki_accelerometer-based_2013}, welches als Referenz für On-Device-Ansätze dienen soll. Relativ am häufigsten werden hierbei auch die intuitiv ähnlichsten Verkehrsmittel verwechselt. In \cite{friedrich_combining_2020} sind dies die Paare $(Zug, UBahn) = 130$, $(Zug, Bus) = 65$, aber auch $(Zug, Stehen) = 78$, wobei dies vermutlich mit den längeren Standzeiten an Haltepunkten von Zügen und der damit verbundenen Aufzeichnung von Segmenten zusammenhängt, ähnlich zu \cite{hemminki_accelerometer-based_2013}. In \cite{hemminki_accelerometer-based_2013} werden am häufigsten die Klassen $(Zug, Metro) = 10879$ und $(Bus, Tram) = 10000$ verwechselt, wie in \cite{friedrich_combining_2020}.

\section{Tradeoff}

Die Unterschiede zwischen \cite{hemminki_accelerometer-based_2013} und \cite{friedrich_combining_2020} zeigen, dass prinzipiell eine große Spanne von möglichen Ressourcenverbräuchen und Ergebnisqualitäten existiert. Durch verschiedene Optimierungsmethoden wie Pruning, Kompression oder architekturelle Restrukturierung kann der Ressourcenverbrauch generell reduziert werden \cite{han_learning_2015,han_deep_2016,iandola_squeezenet_2016,howard_mobilenets_2017}. Meist liegt die Maxime der jeweiligen Arbeiten bei einer Maximierung der Ergebnisqualität und die Ressourcenverbräuche geraten in den Hintergrund der Betrachtung. Sowohl für die ressourcenlimitierte Ausführung auf Smartphones, als auch für die generelle Nachhaltigkeit \cite{strubell_energy_2019} von Machine-Learning-Systemen ist es jedoch von hoher Bedeutung, wie die Vergrößerung des Modells, dessen Energieverbrauch und sekundäre Parameter wie Speicherverbrauch und Inferenzzeit miteinander korellieren und in welcher Form kausale Zusammenhänge vorliegen. Vermuten lässt sich das Folgende - mit dem Wissen, dass beispielsweise ab einem bestimmten Punkt bei einer Verdopplung der Modellgröße nur ein marginaler Zugewinn an Ergebnisqualität zu erwarten wäre, ließen sich effizientere und nachhaltigere Modelle erstellen. \cite{brownlee_exploring_2021,brownlee_search-based_2017} betrachten vor diesem Hintergrund, dass die Relation zwischen Accuracy und Energieverbrauch tatsächlich einen Tradeoff darstellt. Das Finden der bestmöglichen Lösung ist somit äquivalent mit dem Finden eines sogenannten \textit{Pareto-Optimums}\footnote{\url{https://de.wikipedia.org/wiki/Pareto-Optimum} (Abgerufen am 16.7.2021)}. Allein anhand der in den vorigen Sektionen gezeigten Varianten ist dies nicht möglich, denn die Vergleichbarkeit der Ansätze ist wegen der Unterschiedlichkeit der jeweiligen Architekturen und Anwendungsfälle stark eingeschränkt.

\paragraph{Rastersuche:} Die Anforderungsanalyse ergab, dass der Tradeoff durch Austausch der Datenvorverarbeitung und der Modelle analysiert werden kann. \cite{brownlee_exploring_2021} zeigen eine konkrete Methodik, wie dies umgesetzt werden kann. Idee ist die \textit{Rastersuche} durch Variation einer konkreten Architektur und deren Hyperparameter. Das in \cite{brownlee_exploring_2021} selektierte und variierte Modell ist das MLP, ein traditionelles Machine-Learning-Modell. \cite{brownlee_exploring_2021} fokussieren sich dabei auf das Hyperparameter Tuning. Eine wichtige Erkenntnis der in \cite{brownlee_exploring_2021} durchgeführten Rastersuche ist, dass ein Energie-Accuracy-Tradeoff grundsätzlich besteht, jedoch stark vom betrachteten Datensatz abhängt. Bei den Ergebnissen besteht keine lineare Korellation, mit steigender Accuracy können Modelle auch zwischenzeitlich sparsamer werden. Außerdem zeigen sich in \cite{brownlee_exploring_2021} als \textit{Knee-Point} bezeichnete Sprünge in der Energieintensität, beispielsweise konnte der Energieverbrauch eines Modells um $77\%$ reduziert werden, während dessen Accuracy lediglich um $1,1\%$ auf $93,2\%$ fiel. Diese Knee-Points können also als Grundlage herangezogen werden, um Modelle zu finden, welche einen vergleichsweise guten Kompromiss zwischen Energie und Accuracy bieten. Als zentrale, zum Energieverbrauch kontribuierende Faktoren konnten außerdem unter anderem die Dimensionierung der Hidden Layer (hohe positive Korellation) und der genutzte Optimierungsalgorithmus des Gradientenabstiegsverfahren identifiziert werden.

\begin{figure}[h]
  \captionsetup[subfigure]{justification=centering}
  \centering
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=.9\linewidth, bb=0 0 283 212]{brownlee/plots/mortgage_MLP_metrics_testing_cputime_vs_cpuenergy.pdf}
    \caption{UCI Mortgage Datensatz, Inferenz, MLP.}
    \label{fig:brownlee-1}
  \end{subfigure}%
  \begin{subfigure}{.5\textwidth}
    \includegraphics[width=.9\linewidth, bb=0 0 283 212]{brownlee/plots/iris_MLP_metrics_more_training_cputime_vs_cpuenergy.pdf}
    \caption{UCI Iris Datensatz, Training, MLP.}
    \label{fig:brownlee-2}
  \end{subfigure}
  \caption[CPU-Zeit und Energieverbrauch zeigen eine nichtlineare Korellation.]{CPU-Zeit und Energieverbrauch zeigen eine nichtlineare Korellation. Abbildungen und Evaluation aus \cite{brownlee_exploring_2021}.}\label{fig:brownlee}
\end{figure}

\paragraph{CPU-Zeit und Energieverbrauch:} Ein weiteres zentrales Ergebnis aus \cite{brownlee_exploring_2021}, welches methodisch für diese Arbeit relevant ist, besteht darin, dass die in Anspruch genommene CPU-Zeit der Modelle (Training, Inferenzzeit) nicht zwangsweise linear mit der verbrauchten Energie korelliert. Beobachtet wurden die in \Cref{fig:brownlee} sichtbaren Sprünge im Energieverbrauch in der Last. Durch komplexe interne Management-Prozesse der CPU und der umliegenden Komponenten (Caches, RAM, Festspeicher) lässt sich der Energieverbrauch nach \cite{brownlee_exploring_2021} über die CPU-Zeit also nicht hinreichend modellieren und sollte mit gesonderten Tools möglichst direkt gemessen werden.

\paragraph{Plattform-Spezifizität:} \cite{dai_chamnet_2019} kommen zu dem Schluss, dass die Performanz von Machine-Learning-Modellen auch stark von der verwendeten Plattform und der spezialisierten Hardware-Komponenten abhängt. \cite{dai_chamnet_2019} schlagen einen erweiterten Ansatz zur einfachen Rastersuche vor. Hierbei werden Machine-Learning-Modelle genutzt, um den Ressourcenverbrauch (Latenz und Energie) zu einer bestimmten Modellkonfiguration auf einem Zielsystem vorherzusagen. Hierfür müssen jedoch im Voraus Modelle durch Variation getestet werden und die entsprechenden Metriken aufgezeichnet werden. Anschließend wird ein regressives Modell auf den erhobenen Daten trainiert. Das regressive Modell sagt dann den Tradeoff voraus und kann genutzt werden, um Näherungsweise, je nach Abweichung des Modells vom tatsächlichen Tradeoff, das Pareto-Optimum zu finden. Auch hier ist es jedoch wieder essenziell, dass von einer zentralen Modellarchitektur ausgegangen wird, um diese zu variieren. Es können also nicht mehrere Architekturen gleichzeitig und vergleichend einbezogen werden, beispielsweise Random Forests und CNNs. Die gefundene Pareto-optimale Lösung ist also nicht zwangsweise global die bestmögliche Lösung bezüglich des Tradeoffs.

% speicherverbrauch und inferenzzeit nicht (direkt) mit einbezogen
% -> hoher stromverbrauch = hohe inferenzzeit? hoher speicherverbrauch = viele parameter?
% nur ein modell betrachtet -> verschiedene architekturen betrachten?
% andere Datensätze betrachtet -> vme andere ergebnisse möglich?

% Tradeoff: Zusammenhang zwischen Ergebnisqualität und Ressourcenverbrauch
% - Nur wenige empirische Daten über Ressourcenparameter bekannt, sowohl bei
% traditionellen als auch bei deep-learning-ansätzen
% - Zielfrage: Wann ist der Zugewinn an Ergebnisqualität nicht mehr akzeptabel?
% - Arbeit von Brownlee et al. diskutieren
