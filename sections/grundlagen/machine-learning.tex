\section{Machine Learning}\label{sec:machine-learning}

In \Cref{sec:datenerfassung-und-vorverarbeitung} wurde detailliert beschrieben, wie sich die Aktivitätsdaten innerhalb der STADTRADELN-App strukturieren und welche Herausforderungen bei der Weiterverarbeitung der Daten zu beachten sind. In diesem Abschnitt sollen nun Methoden vorgestellt werden, mithilfe derer eine Interpretation der vorverarbeiteten Daten möglich ist.

\subsection{Verkehrsmittelerkennung}

Die Erkennung des Verkehrsmittels anhand der beschriebenen Daten, wie sie \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} umgesetzt haben, lässt sich als ein Problem der \textit{Human Activity Recognition (HAR)} interpretieren. Hierbei liegen Aktivitätsdaten einer jeweiligen Person vor, anhand dessen die ausgeführte Aktivität klassifiziert werden soll. Die formelle Definition der Verkehrsmittelerkennung ist wie folgt. Sei $D = \{d_0, \dots, d_n\} \subseteq \mathbf{R}^n$ die chronologisch sortierte Menge aller vorverarbeiteten und anhand einer Interpolation auf dieselbe Abtastrate synchronisierten Datenpunkte. Wähle ein zu klassifizierendes Segment $S \subseteq D$ der Länge $n_S$. Dann ist die Abbildung $VME(S): D^{n_S} \rightarrow L$ zu finden, wobei $L$ die Menge der möglichen \textit{Labels} von Verkehrsmitteln wie \textit{Fahrrad}, \textit{Bahn}, \textit{Bus}, \textit{zu Fuß} und weiteren ist. Durch die Aufteilung von $D$ in Segmente fester Länge können anschließend mithilfe der Abbildung $VME(S)$ entlang $D$ die genutzten Verkehrsmittel rekonstruiert werden.

\subsubsection{Segmentierung}

In der obigen Problemdarstellung wurde bereits vorweggenommen, dass die Datenpunkte gleichmäßig in Segmente unterteilt werden sollen, die sich auch überlappen können. Dieses Verfahren wird als Gleitfenstermethode bezeichnet. Über die zeitliche Kombination von mehreren aufeinanderfolgenden Datenpunkten (auch als Zeitlinie bezeichnet) können wertvolle Informationen erhalten werden, wie sich zeitlich wiederholende Bewegungsabläufe \cite[S. 4]{banos_window_2014}. Gleichzeitig sollen Wechsel zwischen den Verkehrsmitteln innerhalb der Datenpunktmenge erkannt werden, was mit einer ganzheitlichen Klassifikation der Datenpunktmenge nicht möglich wäre. \\

\todo{Abbildung der Segmente + Datenpunktvektoren einfügen}

\noindent Die Segmentlänge $n_S$ ist hierbei für die Berechnung der Erkennung von entscheidender Bedeutung. \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} betrachtet Segmente von $10s$ bis $180s$ Länge. Je kleiner $n_S$ gewählt wird, desto höher ist die zeitliche Granularität der Erkennung. Gleichzeitig lässt sich vermuten, dass die Präzision der Klassifikation bei kürzeren Segmentlängen geringer ist, wie die experimentellen Daten aus \cite{matusek_anwendung_2019} suggerieren. Wie in \Cref{sec:datenerfassung-und-vorverarbeitung} gezeigt, ist es durch Interpolation der verschiedenen Spuren (GNSS, Akzelerometer, Gyrosensor, Magnetometer) möglich, diese im Rahmen der Synchronisation zu beliebigen Raten abzutasten. Bei näherer Betrachtung fällt hierbei auf, dass \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} Datenpunkte mit $1Hz$ (Abtastrate des GNSS-Systems) abtasten, die mit deutlich höheren Frequenzen im dreistelligen Hertz-Bereich aufgenommenen Beschleunigungs-, Auslenkungs- und Orientierungsdaten also stark reduziert werden (Downsampling). Vermutlich bietet dies eine Möglichkeit zur Verbesserung der Konzepte aus \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020}, unter der Berücksichtigung, dass mit $1Hz$ Abtastrate lediglich Bewegungsabläufe mit Frequenzen $f \leq 0.5Hz$ nach dem Nyquist-Shannon-Abtasttheorem\footnote{\url{https://de.wikipedia.org/wiki/Nyquist-Shannon-Abtasttheorem} (Abgerufen am 14.4.2021)} erhalten bleiben, Frequenzen $f > 0.5Hz$ tragen zum Rauschen der abgetasteten Daten bei. Alternativ wäre daher auch ein Upsampling der korrigierten GNSS-Daten auf eine höhere Frequenz von ca. $100 Hz$ möglich. \cite{banos_window_2014} konnten zeigen, dass sich unter dieser Voraussetzung insbesondere kürzere Segmente von $0.25s$ bis $2s$ Länge für die Aktivitätserkennung eignen, gegenüber den von \cite{matusek_anwendung_2019} und \cite{werner_kontinuierliche_2020} verwendeten Segmentlängen von $10s$ bis $180s$.

\subsubsection{Feature-Engineering}

In den vorigen Sektionen wurde bereits diskutiert, wie Daten entsprechender Smartphone-Sensorsysteme akquiriert werden können, um diese schließlich bezüglich ihrer Fehlercharakteristika vorzuverarbeiten, mithilfe von Methoden zur Filtrierung, Korrektur und Standardisierung. Hieraus werden, wie in der vorigen Sektion erläutert, Segmente der Länge $n_S$ gebildet. Zur besseren Verständlichkeit wurde bisher davon ausgegangen, dass diese Segmente analog zur Abbildungsdefinition $VME(S): D^{n_S} \rightarrow L$ direkt als Input für das Machine-Learning-Modell dienen, um schließlich die Abbildung auf die Label-Menge $L$ zu realisieren. Je nach Architektur des Modells ist es jedoch üblich, einen weiteren Zwischenschritt zu integrieren, der als \textit{Feature-Extraktion} bezeichnet wird. Hierbei werden die im Segment enthaltenen Datenpunkte $d \in D$ auf einen \textit{Feature-Space} $F \in \mathbf{R}^{n_F}$ abgebildet, welcher dann nachfolgend als Input für das Machine-Learning-Modell dient.

\begin{equation}\label{eq:feature-extraktion}
d_{t=0} =
%
  \begin{bmatrix}
  ACC(t=0)_x \\ \vdots \\ MAG(t=0)_z
  \end{bmatrix}
%
   \xrightarrow{\text{Feature-Extraktion}}
%
  \begin{bmatrix}
  | ACC(t=0) | \\ \vdots \\ | MAG(t=0) | \\
  \vdots \\ FEATURE_{n_F}(S, t=0)
  \end{bmatrix}
%
\end{equation}
wobei:
\begin{conditions}
  d_{t=0} & Datenpunkt an der Stelle $t=0$ des Segments $S$
\end{conditions}

\noindent \Cref{eq:feature-extraktion} zeigt das Schema einer solchen Feature-Extraktion. Die bestehenden Daten können zusammengefasst werden, wie beispielsweise $|ACC(t=0)|$ die absolute Länge des Beschleunigungsvektors zusammenfasst. Dies stellt bereits ein simples Feature dar. Gleichzeitig können neue Informationen in Relation zum Segment ergänzt werden, in \Cref{eq:feature-extraktion} als $FEATURE_{n_F}(S, t=0)$ symbolisiert. Der Zweck dieser Abbildung ist die semantische Aufbereitung der Datenpunkte, mit dem Ziel einer Verbesserung der Erkennung. Welche Features hierbei konkret berechnet werden sollen, wird im Prozess des \textit{Feature-Engineering} bestimmt \cite{matusek_anwendung_2019}. Für den Kontext der Verkehrsmittelerkennung lassen sich prinzipiell zwei Gruppen von Features unterscheiden.

\paragraph{Shallow Features \cite{ravi_deep_2017}:} Diese Features werden direkt aus dem vorliegenden Segment abgeleitet und sind typischerweise für alle Datenpunktvektoren eines Segments identisch. Häufig verwendete shallow Features sind der Durchschnitt und die Standardabweichung bestimmter Werte eines Segments \cite{chen_deep_2015, banos_window_2014, kwapisz_activity_2011, jahangiri_applying_2015, nurhanim_classification_2017}. Diese Features beziehen sich direkt auf die Zeitlinie. Sie werden daher auch als \textit{Time Domain Features} eingeordnet \cite{chen_deep_2015}. Alternativ ist es auch üblich, sogenannte \textit{Frequency Domain Features} durch eine vorige Fourier-Transformation des Segments zu berechnen \cite{zeng_convolutional_2014, chen_deep_2015}.

\paragraph{Non-Shallow Features \cite{ravi_deep_2017}:} Während shallow Features verhältnismäßig einfach zu implementieren sind, können sie wiederum möglicherweise keine komplexen Zusammenhänge innerhalb des Segments repräsentieren \cite{abu_alsheikh_deep_2015}. Bei \textit{Non-Shallow Features}, auch bezeichnet als \textit{Data-Driven Features} oder \textit{Deep Learning Features} \cite{abu_alsheikh_deep_2015}, erfolgt die Berechnung durch Zwischenschaltung eines Machine-Learning-Modells, welches bestimmte Eingangswerte des Segments in einen Feature-Vektor überführt (Enkodierung). \cite{ravi_deep_2017} überführen beispielsweise die Segmentdaten in ein Spektrogramm, um dieses über ein Machine-Learning-Modell zu enkodieren. \cite{zeng_convolutional_2014} verwenden sogar mehrere Machine-Learning-Modelle verschiedener Art. \\

\noindent Die obigen Features lassen sich hierbei auch miteinander kombinieren, um weitere Features zu erzeugen. Für die auf Machine-Learning basierte Aktivitätserkennung nutzen \cite{kwapisz_activity_2011} beispielsweise insgesamt 43 verschiedene erzeugte Features. Auch hier ist jedoch wieder zwischen dem potenziellen Informationszugewinn und der erhöhten Dimensionalität des Feature-Vektors und der damit verbundenen Berechnungskomplexität der Aktivitätserkennung abzuwägen. Auch bei den berechneten Features ist zu beachten, dass diese je nach Architektur des Machine-Learning-Modells normalisiert oder standardisiert werden sollten (siehe \Cref{sec:datenerfassung-und-vorverarbeitung}).

\subsubsection{Einordnung in klassische Probleme des Machine Learnings}

Neben mannigfaltigen Fehlerursachen (in \Cref{sec:datenerfassung-und-vorverarbeitung} erläutert) ist auch die kontextbedingte Komplexität der ermittelten Features denkbar hoch. Smartphones können zum Beispiel in verschiedenen Positionen (Hand, Hosentasche, Rucksack, ...) am Körper bzw. am/im Verkehrsmittel getragen werden. Weitere Ursachen für zwischen Messungen gleicher Aktivität abweichenden Daten sind unterschiedlich gebaute Verkehrsmittel (zum Beispiel Rennrad vs. Mountainbike), unterschiedliche anatomische Gegebenheiten und Bewegungsmuster der jeweiligen Person, sowie die Art des Untergrundes (zum Beispiel Schotterweg vs. asphaltierte Straße) oder die allgemeine Beschaffenheit des Geländes. Daher besteht ein weiteres zentrales Problem in der Realisation der Abbildung $VME(S): D^{n_S} \rightarrow L$. Eine einfache zustandslose Implementation dieser Abbildung wäre denkbar. Hierfür könnten beispielsweise Geschwindigkeitsbereiche auf $L$ abgebildet werden, wie $\varnothing v \geq 40\frac{km}{h} \rightarrow$ \enquote{Auto fahren} oder $\varnothing v \leq 5\frac{km}{h} \rightarrow$ \enquote{zu Fuß}. Bei der Betrachtung dieses Ansatzes lassen sich jedoch schnell Fehlerszenarien konstruieren, in welchen diese Abbildung fehlschlägt, beispielsweise eine dichte Verkehrslage mit ständigem Abbremsen und Beschleunigen, oder eine besonders schnelle Fahrradfahrt bergab. Bei der Behandlung dieser Fehlerszenarien werden bereits komplexere Überlegungen notwendig, welche möglicherweise neue Fehlerszenarien erzeugen. Je näher die zu erreichende Präzision des Systems an $100\%$ liegen soll, desto komplexer würde ein solches System vermutlich werden. Für solche Probleme, die auch durch hochkomplexe algorithmische Lösungen nicht hinreichend gelöst werden können, haben sich verschiedene Methoden aus dem Forschungsspektrum der künstlichen Intelligenz etabliert.

\begin{itemize}
\item Beim \textbf{Clustering} steht die Partitionierung einer Menge von Werten in geeignete Untergruppen im Vordergrund. Verfahren für das Clustering sind beispielsweise k-Means-Clustering \cite{likas_global_2003}, t-SNE \cite{van_der_maaten_laurens_and_hinton_geoffrey_visualizing_2008} oder PCA \cite{ringner_what_2008}.
\item Die \textbf{Regression} behandelt Probleme, deren Hauptgegenstand die Nachbildung eines Kausalzusammenhangs oder einer Korrelation in einer Menge von Werten ist. Im Zentrum steht hierbei das Ziel, die Abweichung der Regression von den Daten zu minimieren.
\item Bei der \textbf{Generation} sollen neue Daten anhand eines Vorbildes erzeugt werden. Ziel ist es, bei einer Eingabe von bestimmten Daten möglichst plausible weitere Daten zu erzeugen. Klassische Anwendungsbereiche umfassen KI-Systeme für die Chat-basierte Texterzeugung \cite{brown_language_2020} oder auch das Supersampling von Bildern \cite{burgess_rtx_2020, park_semantic_2019}.
\item Möglich ist auch die \textbf{Transformation}, wenn statt ähnlichen Daten (wie bei der Generation) andersartige Daten erzeugt werden sollen. Ein charakteristischer Anwendungsbereich ist die Realisation von \textit{Text-to-Speech}- oder \textit{Speech-to-Text}-Systemen \cite{wang_tacotron_2017}.
\item Im Rahmen der \textbf{Klassifikation} werden Eingabedaten in bestimmte Klassen eingeteilt, bei einer Maximierung der Anzahl korrekter Einordnungen.
\end{itemize}

\noindent Zusammenfassend handelt es sich hierbei um Verfahren, bei denen mathematische Modelle anhand vorliegender Daten angelernt werden (Induktion, Training), um schließlich zur Lösung des vorliegenden Problems verwendet zu werden (Deduktion, Inferenz). Daher werden diese Verfahren auch als \textit{Machine-Learning}-Methoden bezeichnet. Statt algorithmische Verfahren zu entwickeln, welche ein komplexes Problem (wie oben illustriert) möglicherweise nur begrenzt lösen können, ist also die Grundidee der Machine-Learning-Methoden die Repräsentation einer Abbildung von \textit{Input} zu \textit{Output} über ein angelerntes mathematisches Modell. \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} konnten zeigen, dass solche Machine-Learning-Methoden zur Implementation der eingangs gezeigten Abbildung $VME(S): D^{n_S} \rightarrow L$ geeignet sind. Die Realisation der Abbildung von Input zu Output geschieht bei Machine-Learning-Modellen über ein mehr oder weniger komplexes System von mathematischen Parametern und Funktionen. Die Berechnung der Ausgabe (Inferenz) eines Machine-Learning-Modells lässt sich somit einfach realisieren, indem die Eingabewerte mithilfe der Parameter und Funktionen zum Ausgang überführt werden. Zentrale Probleme bestehen jedoch darin, eine geeignete Architektur für die Parameter und Funktionen zu wählen, sowie das so erstellte Modell zu trainieren. Diese zwei Probleme sollen in den folgenden Sektionen näher erläutert werden.

\subsection{Training von Machine-Learning-Modellen}

\todo{In dieser Sektion fehlen Einzelnachweise. Diese müssen noch ergänzt werden.}

In Abhängigkeit von der zu lösenden Aufgabe bieten sich verschiedene Lernverfahren an. Ziel ist es hierbei jedoch stets, das Machine-Learning-Modell so anhand der Eingangsdaten anzupassen, dass die Aufgabe innerhalb des Systems bestmöglich erfüllt werden kann. Typische Lernverfahren sind das \textit{Reinforcement Learning}, das \textit{Supervised Learning} und das \textit{Unsupervised Learning}. Diese Verfahren sollen nun vorgestellt werden.

\subsubsection{Reinforcement Learning}

Beim Reinforcement Learning werden auf Grundlage der Entscheidungen eines Machine-Learning-Modells \enquote{Belohnungen} und \enquote{Bestrafungen} definiert. Ziel ist die Maximierung eines Scores, der sich aus den gesammelten Belohnungen und Bestrafungen bildet. Dazu werden mehrere Modelle gebildet, welche sich in ihrer Parametrisierung leicht unterscheiden. Die Modelle werden getestet (meist durch Simulation) und anhand der definierten Belohnungen und Bestrafungen bewertet. Die besten Modelle werden ausgewählt und bieten die Grundlage für die nächste Generation. Hierbei wird angenommen, dass die Modelle analog zur Evolutionstheorie durch Zufall gewünschte Strategien durch Mutation hinzu erlernen. Für Klassifikationssysteme wie eine Verkehrsmittelerkennung ist dieses Lernverfahren jedoch eher unüblich.

\subsubsection{Unsupervised Learning}

Beim Unsupervised Learning wird ein Machine-Learning-Modell auf Daten trainiert, mit dem Ziel, innerhalb der Daten Muster zu erkennen bzw. diese zu reproduzieren. Das Training erfolgt ohne bekannte Labels für die Daten. Das Modell wird iterativ so angepasst, dass es eine abstrakte interne Repräsentation der Daten erlernt. Das Verfahren wird daher typischerweise für die Komprimierung von Daten (\textit{Sparse Coding}) oder die Segmentierung von Daten (durch Unterteilung der Daten in Gruppen mit ähnlichen Mustern) angewandt. Das Modell entwickelt hierbei durch Anpassung der Modellparameter Vermutungen über die Muster eines Datensatzes. Die Modellparameter werden anhand der beobachteten Daten iterativ so angepasst, dass das Modell die Daten möglichst präzise nachbildet oder segmentiert.

\subsubsection{Supervised Learning}

Ähnlich zum Unsupervised Learning wird beim Training von Machine-Learning-Modellen durch Supervised Learning eine zu minimierenden Kostenfunktion definiert. Voraussetzung ist die numerische Repräsentation der Zielwerte. Für Klassifikationssysteme wie eine Verkehrsmittelklassifikation bietet sich zum Beispiel das \textit{One-Hot-Encoding} (OHE) an \cite[S. 63]{matusek_anwendung_2019}, beispielsweise $OHE(Fahrrad) = [1, 0, 0]$, $OHE(Auto) = [0, 1, 0]$ und $OHE(Bus) = [0, 0, 1]$, je nach Anzahl der Klassen. Beispiele für Kostenfunktionen sind der \textit{Root-Mean-Square Error}\footnote{\url{https://en.wikipedia.org/wiki/Root-mean-square_deviation} (Abgerufen am 6.5.2021)} (RMSE) oder die \textit{Cross Entropy}\footnote{\url{https://en.wikipedia.org/wiki/Cross_entropy} (Abgerufen am 15.5.2021)}. Die Kostenfunktion soll beschreiben, wie stark das aktuelle Modell (anhand dessen Vorhersage) von dem Zielwert abweicht. Die Kostenfunktion wird anschließend minimiert, indem die mathematischen Parameter des Machine-Learning-Modells in Abhängigkeit von ihrem Beitrag zum Fehler angepasst werden.

\subsubsection{Erweiterte Lernverfahren}

Die oben erläuterten Lernverfahren bilden die drei wesentlichen Herangehensweisen beim Training von Machine-Learning-Modellen. Je nach der zu erfüllenden Aufgabe und den vorliegenden Daten ist eine geeignete Auswahl dieser drei Grundverfahren zum Training des Machine-Learning-Modells zu treffen. Für eine Verkehrsmittelerkennung bietet sich in erster Linie das Supervised Learning an, welches auch in \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} zum Einsatz kommt. Hierfür müssen Datensätze im Voraus händisch mit den zu erkennenden Verkehrsmittel-Klassen ausgestattet werden. Für die zahlreichen bestehenden Datensätze aus dem Movebis-Projekt ist dies jedoch unter Umständen nicht möglich. Hierbei gilt grundsätzlich, dass die Menge der Daten beim Supervised Learning je nach Komplexität und Architektur des Machine-Learning-Modells ausreichend umfangreich sein muss. Um die benötigte Menge an gelabelten Daten zu reduzieren, kann ein erweitertes Lernverfahren eingesetzt werden, das \textit{Semi-Supervised Learning}. Bei diesem Lernverfahren wird zunächst Unsupervised Learning auf den nicht gelabelten Daten durchgeführt, um das Machine-Learning-Modell auf möglichen Mustern innerhalb der Daten vorzutrainieren. Das Machine-Learning-Modell soll so bereits ein abstraktes Grundverständnis der Eingaben erhalten, um anschließend auf den händisch erstellten Daten durch Supervised Learning auf die zu erkennenden Klassen \enquote{umtrainiert} zu werden. Das \enquote{Umtrainieren} von Machine-Learning-Modellen wird im breiteren Sinn auch als \textit{Transfer Learning} bezeichnet.

\subsubsection{Gradientenabstiegsverfahren}

Je nach Art des Machine-Learning-Modells und des Lernverfahrens existieren zahlreiche Möglichkeiten der mathematischen Anpassung, um das Modell anzulernen. Von zentraler Bedeutung für Architekturen, wie sie in \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} verwendet werden, sind Gradientenabstiegsverfahren zur Minimierung einer Kostenfunktion, vor allem beim Supervised Learning. Die Minimierung einer Kostenfunktion ist ein mathematisches Optimierungsproblem. Ziel ist es, die Parameter des Machine-Learning-Modells so anzupassen, dass die Kosten minimal werden. Hierfür soll möglichst ein globales Minimum der Kostenfunktion gefunden werden. Bei einem kleinen Zustandsraum (aufgespannt durch die Modellparameter) ist dies durch einfache analytische Verfahren realisierbar. Zurückblickend sind Machine-Learning-Modelle formell lediglich mathematische Funktionen, welche Eingaben auf Ausgaben abbilden. Ist das Modell repräsentierbar durch eine differenzierbare Funktionsgleichung mit einem Funktionsparameter, so lassen sich globale Minima leicht durch Bilden der ersten und zweiten Ableitung finden. Erhält jedoch das Modell mehr als nur einen Input, so ist dies nicht mehr möglich. Ein übliches mathematisches Verfahren zur Minimierung solcher komplexer Kostenfunktionen ist die Bildung eines Gradienten (Analogon zur ersten Ableitung) durch die Ermittlung der partiellen Ableitungen der Kostenfunktion, um anschließend den Gradienten iterativ in absteigender Richtung durch Anpassung der Modellparameter zu traversieren. Ziel dieses Verfahrens ist also die iterative Konvergenz zum globalen Minimum der Kostenfunktion, anstelle der direkten Ermittlung des globalen Minimums durch Analysis.

% s. 158
\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 897 337]{generated/grad-desc-example.pdf}
\caption{Das iterative Gradientenabstiegsverfahren konvergiert bei der linearen Regression zum globalen Minimum der Kostenfunktion. Visualisierung nach \cite{christian_hill_visualizing_2016}.}\label{fig:grad-desc-example}
\end{figure}

\noindent \Cref{fig:grad-desc-example} zeigt das Gradientenabstiegsverfahren schematisch am Beispiel der linearen Regression. Die Intensität (Schrittweite auf dem Gradienten), mit der die Modellparameter bei jedem neuen Datenpunkt angepasst werden, wird als \textit{Learning Rate} bezeichnet. Die Learning Rate ist ein wichtiger Hyperparameter von Machine-Learning-Systemen. Ein zentrales Problem von Gradientenabstiegsverfahren ist, dass Gradienten neben dem idealerweise zu erreichenden globalem Minimum auch zahlreiche lokale Minima besitzen können. Ist die Learning Rate zu klein, so lernt das Modell verhältnismäßig langsam und läuft gleichzeitig Gefahr, in ein lokales Minimum des Gradienten zu fallen. Ist die Learning Rate jedoch zu hoch, besteht das Risiko, dass aus Minima \enquote{herausgesprungen} wird. Zentraler Teil des Trainings von Machine-Learning-Modellen ist es daher, das Lernverhalten zu beobachten und ggf. ein \textit{Hyperparameter Tuning} durchzuführen. Diese Betrachtung ist jedoch vereinfacht und dient nur zur Veranschaulichung des Funktionsprinzips. Bei erweiterten Optimierungsverfahren wie dem \textit{ADAM-Optimizer} wird die Learning Rate beispielsweise pro Modellparameter individuell angepasst.

\subsection{Modellvalidierung}

Da Machine-Learning-Modelle durch das Erlernen einer abstrakten internen Repräsentation der Abbildung von Eingaben auf Ausgaben trainiert werden, ist die Erklärung und Validierung von deren Funktion häufig ein nichttriviales Problem, mit dem sich unter anderem der Forschungsbereich \textit{Explainable AI} (kurz XAI) auseinandersetzt. Durch direkte Beobachtung der Modellparameter ist es in Abhängigkeit der Modellkomplexität in der Regel schwer, zu determinieren, ob ein Machine-Learning-Modell erwünschte oder unerwünschte Muster wie gewünscht erlernt. Konvergiert das Modell (ausgehend von einer fehlerfreien Implementation) wegen einer unzureichenden Anzahl an internen Parametern oder einer zu geringen Learning Rate nicht ausreichend auf den Daten, so liegt ein \textit{Underfitting} vor. Ist die Learning Rate zu hoch bzw. stehen dem Modell zu viele interne Parameter oder nicht ausreichend Daten zur Verfügung, lernt es gegebenenfalls, unerwünschte Muster zu erkennen.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 874 324]{generated/over-under-fit-example.pdf}
\caption{Mit weniger internen Parametern $k_{Kernel}$ sind die \textit{Decision Surfaces} eines SVM-Klassifikators weniger flexibel. Wird $k_{Kernel}$ zu hoch gewählt, so passen sich die Decision Surfaces zu stark den Trainingsdaten (markiert als $\triangle$) an. Die Fähigkeit zur Generalisierung auf neuen Daten (markiert als $\bigcirc$) ist dann eventuell eingeschränkt.}\label{fig:over-under-fit-example}
\end{figure}

\noindent Bei einer Verkehrsmittelklassifikation wären dies beispielsweise Störungen in den Sensorsignalen in Abhängigkeit vom Gerätetyp. Dieses \textit{Overfitting} soll verhindert werden, denn es beeinflusst die Performanz des Modells auf neuen unbekannten Daten negativ. In Abbildung \Cref{fig:over-under-fit-example} wird dies anhand eines Support-Vector-Machine-Klassifikators auf den Daten des UCI Iris Datensatzes\footnote{\url{https://archive.ics.uci.edu/ml/datasets/iris} (Abgerufen am 14.5.2021)} gezeigt. Um ein mögliches Overfitting oder Underfitting zu erkennen, muss das Modell während des Trainings kontinuierlich mithilfe von konkreten Metriken validiert werden. Lassen diese Metriken erkennen, dass das Modell ein solches unerwünschtes Verhalten zeigt, können entsprechende Schritte eingeleitet werden. Beispielsweise kann die Learning Rate angepasst, oder der Datensatz durch neue Daten ergänzt werden. Zur Erweiterung des Datensatzes können neben der Aufzeichnung neuer Daten und der Verwendung von Semi-Supervised Learning auch generative Modelle genutzt werden, oder bestehende Daten transformiert und zur Reduktion von Störsignalen vorverarbeitet werden. Zur Erkennung von Overfitting und Underfitting stehen mehrere Methoden zur Verfügung, die in den folgenden Abschnitten näher vorgestellt werden sollen, da sie später einen zentralen Teil in der Auswertung der Modellperformanz übernehmen.

\subsubsection{Trainings-, Validierungs- und Testdaten}

Die Grundlage für eine Evaluation der Modellperformanz ist die Separierung des Datensatzes in zwei Teile, wobei das Training des Modells auf den Trainingsdaten und die Evaluation auf einem isolierten Testdatensatz durchgeführt wird. Bei diesem Verfahren gehen somit je nach Größe des Testdatensatzes (typischerweise ca. $20\%$ bis $30\%$) Daten für das Training verloren. Würde jedoch das Modell auf demselben Datensatz trainiert und getestet werden, so ließe sich keine Aussage darüber treffen, wie performant das Modell auf neuen unbekannten Daten generalisiert. Je nach Abweichung des Modells von den erwarteten Ausgaben kann eine Testmetrik und eine Trainingsmetrik errechnet werden. Ist die Testmetrik signifikant schlechter als die Trainingsmetrik, so ist dies ein Hinweis auf Overfitting. Sind beide Metriken verhältnisäßig schlecht, deutet dies auf ein Underfitting hin. Ziel ist also die Maximierung der Metriken, während diese möglichst nur geringfügig voneinander abweichen sollen. Darüber hinaus kann vom Testdatensatz noch ein sogenannter Validierungsdatensatz abgespalten werden, zur Anpassung der Hyperparameter während des Trainings, während der Testdatensatz weiterhin in völliger Isolation vom Trainingsprozess verbleibt.

\subsubsection{Metriken}

In diesem Abschnitt sollen konkrete Metriken vorgestellt werden, mithilfe derer eine Evaluation und Validierung der Modellperformanz durchgeführt werden kann. Ausgehend von der Verkehrsmittelklassifikation beim Supervised Learning (mit vorhandenen Labels) kann für jede Vorhersage des Machine-Learning-Modells geprüft werden, ob diese zutrifft, oder nicht. Klassifiziert das Machine-Learning-Modell in nur zwei disjunkten boolschen Klassen (z.B. \textit{Fahrradfahren} und \textit{nicht Fahrradfahren}) ist es üblich, zur Überprüfung die Anzahl der Falsch-Negativen (Vorhersage \textit{nicht Fahrradfahren} und Label \textit{Fahrradfahren}) und Falsch-Positiven (Vorhersage \textit{Fahrradfahren} und Label \textit{nicht Fahrradfahren}) zu bestimmen. Aus diesen Zahlen lassen sich anschließend die Fehlermetriken \textit{Recall} und \textit{Precision} errechnen.

\begin{equation}\label{eq:recall-precision}
Recall = \frac{TP}{TP + FP}; Precision = \frac{TP}{TP + FN}
\end{equation}
wobei:
\begin{conditions}
  TP & Korrekte Vorhersagen (\textit{True Positive}) \\
  FP & Falsch-Positive (\textit{False Positive}) \\
  FN & Falsch-Negative (\textit{False Negative})
\end{conditions}

\noindent Die Metriken Recall und Precision bieten die Grundlage für eine darauf aufbauende Metrik, dem \textit{$F_1$-Score}.

\begin{equation}\label{eq:f1}
F_1 = 2 * \frac{Precision * Recall}{Precision + Recall}
\end{equation}

\noindent Der $F_1$-Score ist das harmonische Mittel zwischen Precision und Recall. Mithilfe dieser Metrik kann die Genauigkeit eines binären Klassifikators bestimmt werden, wobei der $F_1$-Score immer zwischen $0$ (geringstmögliche Genauigkeit) und $1$ (größtmögliche Genauigkeit) liegt. Der $F_1$-Score muss um ein weiteres Konzept erweitert werden, um für eine Klassifikation mit mehreren Klassen applizierbar zu sein. Ein solches Konzept ist die sogenannte \textit{Konfusionsmatrix}.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 834 337]{generated/conf-mat-example.pdf}
\caption{Beispiele für Konfusionsmatrizen eines Machine-Learning-Klassifikators.}\label{fig:example-conf-mat}
\end{figure}

\noindent In \Cref{fig:example-conf-mat} sind zwei Konfusionsmatrizen eines Machine-Learning-Klassifikators auf dem UCI ML Datensatz für handgeschriebene Zahlen\footnote{\url{https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits} (Abgerufen am 13.5.2021)} gezeigt. Die Diagonale der Matrizen zeigt die korrekten Klassifikationen des Machine-Learning-Modells. Abseits der Diagonale werden die falschen Klassifikationen sichtbar. Anhand der Konfusionsmatrix lässt sich also namensgebend ablesen, welche Klassen häufig verwechselt werden. Sichtbar wird hier auch, dass die Klassifikation des beispielhaften Machine-Learning-Modells auf dem Testdatensatz etwas schlechter ist, als auf dem Trainingsdatensatz. Um einen gesamten $F_1$-Score zu errechnen, ist es nun möglich, jede einzelne Klasse als binären Klassifikator zu interpretieren, indem die Spalten und Reihen der entsprechenden Klasse betrachtet werden \cite{shmueli_multi-class_2020-1}. Zum Schluss können die einzelnen $F_1$-Scores der binären Teilklassifikatoren zu einem Gesamtscore zusammengefasst werden. Hierbei können die partiellen $F_1$-Scores zum Beispiel gewichtet nach ihrem Stichprobenanteil eingehen (\textit{Weighted-$F_1$}) oder zu gleichen Anteilen gewichtet werden (\textit{Macro-$F_1$}) \cite{shmueli_multi-class_2020}.

\subsubsection{Regularisierung}

Neben diesen Hilfsmetriken kann beim Training auch kontinuierlich die Entwicklung der Kostenfunktion beobachtet werden. Zeigt sich beim Training, dass dessen Fortführung anhand der Kostenfunktion wahrscheinlich zu einem unerwünschten Overfitting (erkennbar am Generalisierungsfehler auf den Testdaten) führen würde, können Regularisierungsmethoden angewandt werden. In verschiedenen Machine-Learning-Modellarchitekturen können auch verschiedene Regularisierungstechniken integriert werden, die differenzierte Auswahl und Konfiguration muss im Rahmen eines Konzepts auf die konkrete Architektur zugeschnitten werden. Eine übergreifend für Machine-Learning-Modelle anwendbare Technik der Regularisierung ist das vorzeitige Beenden des Trainings, bevor ein Overfitting voraussichtlich eintritt. Hierfür wird eine Heuristik definiert, nach der das Training bei Erreichen eines gewünschten Ziels beendet wird. Diese Methode der Regularisierung ist auch bekannt unter dem Fachbegriff \textit{Early Stopping}\footnote{\url{https://de.wikipedia.org/wiki/Early_Stopping} (Abgerufen am 14.5.2021)}.

\subsection{Modellarchitekturen}

In den vorigen Sektionen wurde diskutiert, wie Aktivitätsdaten eines Smartphones über Sensoren aufgenommen, vorverarbeitet und schließlich zur Realisation einer Verkehrsmittelklassifikation durch die Implementation, das Training und die Validierung eines abstrakten Machine-Learning-Modells verwendet werden können. Unklar ist bisher jedoch noch, wie genau die Verkehrsmittelklassifikation als Abbildung $VME(S)$ innerhalb des Machine-Learning-Modells durch dessen innere Parameter repräsentiert wird. Hierfür existieren zahlreiche unterschiedliche Modellarchitekturen. Nachfolgend aufgelistet sind prominente Beispiele solcher Architekturen, die für eine Klassifikation von Verkehrsmitteln genutzt werden können.

\begin{itemize}
\item \textit{K-Nearest-Neighbor}\footnote{\url{https://de.wikipedia.org/wiki/N\%C3\%A4chste-Nachbarn-Klassifikation} (Abgerufen am 14.5.2021)}
\item \textit{Support Vector Machines}\footnote{\url{https://de.wikipedia.org/wiki/Support_Vector_Machine} (Abgerufen am 14.5.2021)}
\item \textit{Decision Trees} und darauf aufbauende \textit{Random Forests}\footnote{\url{https://de.wikipedia.org/wiki/Entscheidungsbaum} (Abgerufen am 14.5.2021)}
\item Künstliche neuronale Netzwerke, auch bezeichnet als \textit{Deep Learning}\footnote{\url{https://de.wikipedia.org/wiki/Deep_Learning} (Abgerufen am 14.5.2021)}
\end{itemize}

\noindent \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} nutzen künstliche neuronale Netzwerke zur Realisation der jeweiligen Konzepte. Daher sollen sich die folgenden Sektionen auf die Beschreibung dieser konkreten Machine-Learning-Architekturen fokussieren.

\subsubsection{Künstliche neuronale Netzwerke}

Künstliche neuronale Netzwerke setzen sich namensgebend aus kleinen funktionellen Untereinheiten, den Neuronen, zusammen. Diese orientieren sich an der physiologischen Beschaffenheit von biologischen Neuronen, welche sich vorrangig im Zerebrum befinden und zur Reizverarbeitung notwendig sind.

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 544 193]{neuronen.pdf}
\caption{Links: Das Neuron als Grundbestandteil eines künstlichen neuronales Netzwerks. Abbildung nach \cite[S. 200]{sosnovshchenko_machine_2018}. Rechts: Physiologischer Aufbau eines biologischen Neurons. Lizenz: Wikimedia Commons.}\label{fig:neuronen}
\end{figure}

\noindent Wie in \Cref{fig:neuronen} illustriert, besitzt jedes Neuron eine oder mehrere Eingaben, welche mit einem Gewichtsvektor über das Skalarprodukt verrechnet werden. Der Gewichtsvektor kann einen zusätzlichen \textit{Bias}-Faktor zur Regularisierung inkludieren\footnote{Der Bias-Faktor dient als linearer Verschiebungsfaktor für den Wertebereich der Aktivierungsfunktion, konfiguriert also, \enquote{wie früh} die Aktivierung stattfindet.}. Der resultierende skalare Wert wird anschließend mit einer sogenannten Aktivierungsfunktion verrechnet und ausgegeben. Die Aktivierungsfunktion hat den Zweck, das Verhalten eines biologischen Neurons zu simulieren. Biologische Neurone leiten einen Reiz erst weiter, wenn der Eingangsreiz ein bestimmtes Schwellenpotenzial erreicht. Die biologische Reizweiterleitung geschieht dann durch schlagartige Depolarisation und Öffnung verschiedener Ionenkanälen am Axon und eine anschließende Kaskade, hin zu den nachfolgenden Neuronen. Unabhängig von der Intensität des Eingangsreizes hat das so gebildete Aktionspotenzial jedoch immer die gleiche Stärke, die Intensität des Reizes wird durch die Frequenz der Aktionspotenziale moduliert. Die Aktivierungsfunktion eines biologischen Neurons lässt sich durch eine binäre Schrittfunktion beschreiben. Ist die Reizstärke unterschwellig, so wird kein Aktionspotenzial ausgelöst. Ist die Reizstärke über dem Schwellenpotenzial, wird ein einheitliches Aktionspotenzial ausgelöst (mit anschließender Repolarisation der Zelle). Bei künstlichen Neuronen soll dieses Verhalten durch eine nichtlineare Aktivierungsfunktion nachgebildet werden.

\begin{table}[H]\centering
\begin{tabular}{@{}*{3}{p{.33\textwidth}@{}}}
\toprule
Name der Aktivierungsfunktion & Formel & Erste Ableitung \\
\midrule
Step & $f(x)={\begin{cases}0&{\text{für }}x< 0\\1&{\text{für }}x \geq 0\\\end{cases}}$ & Nicht differenzierbar \\
\addlinespace[0.5em]
Sigmoidal & $f(x)=\frac{1}{1+e^{-x}}$ & $f^{\prime}=f(x)(1 - f(x))$ \\
\addlinespace[0.5em]
\midrule
\addlinespace[0.5em]
Rectified Linear Unit (ReLU) & $f(x)={\begin{cases}0&{\text{für }}x< 0\\x&{\text{für }}x \geq 0\\\end{cases}}$ & $f^{\prime}(x)={\begin{cases}0&{\text{für }}x< 0\\1&{\text{für }}x \geq 0\\\end{cases}}$ \\
\addlinespace[0.5em]
Leaky ReLU & $f(x)={\begin{cases}ax&{\text{für }}x< 0\\x&{\text{für }}x \geq 0\\\end{cases}}$ & $f^{\prime}(x)={\begin{cases}a&{\text{für }}x< 0\\1&{\text{für }}x \geq 0\\\end{cases}}$ \\
\bottomrule
\end{tabular}\caption{Verschiedene Aktivierungsfunktionen im Überblick.}
\end{table}

\noindent Die Step-Funktion bildet das biologische Verhalten gut nach und ist einfach zu berechnen, jedoch ist sie wegen der Diskontinuität bei $x=0$ nicht differenzierbar und daher nicht für künstliche neuronale Netzwerke anwendbar, welche mithilfe des vorgestellten Gradientenabstiegsverfahrens trainiert werden sollen (siehe \Cref{par:training-vanishing-grads}). Die sigmoidale Aktivierungsfunktion bildet im Kurvenverlauf annähernd die Step-Funktion nach (\textit{step-like}). Die ReLU-Aktivierungsfunktion hingegen eliminiert alle negativen Eingaben und skaliert im positiven Bereich die Eingaben linear (\textit{rectifier-like})\footnote{Rectifier, engl. für Gleichrichter, ein elektrisches Bauteil zur Signalverarbeitung. \url{https://de.wikipedia.org/wiki/Gleichrichter} (Abgerufen am 15.5.2021)} \cite[S. 203]{sosnovshchenko_machine_2018}. Da die ReLU-Aktivierungsfunktion nach ihrer Definition differenzierbar und sehr leicht und effizient über $max(0, x)$ zu berechnen ist, ist sie eine häufig verwendete Aktivierungsfunktion für künstliche neuronale Netze und wird auch durch \cite{matusek_anwendung_2019}, \cite{werner_kontinuierliche_2020} und \cite{stojanov_continuous_2020} genutzt.

\begin{figure}[H]
\includegraphics[width=0.75\linewidth, bb=0 0 371 217]{neuronales-netz.pdf}
\caption{Ein simples neuronales Netzwerk im Überblick.}\label{fig:neuronales-netz}
\end{figure}

\noindent Neuronale Netzwerke bestehen aus Vernetzungen mehrerer Neurone. \Cref{fig:neuronales-netz} zeigt eine simple Modellarchitektur, bei der die Neuronen in Schichten eingeteilt und untereinander voll vermascht werden. Diese Architektur wird als \textit{Feed-Forward Network} bezeichnet, denn die Eingaben werden auf der linken Seite durch die Eingabeschicht empfangen, durch einen oder mehrere Hidden Layer verarbeitet und anschließend über die Ausgabeschicht ausgegeben. Die Anzahl der Neuronen pro Schicht, die Art der Vermaschung, sowie die Anzahl von Hidden Layers kann frei gewählt werden. Prinzipiell gilt, je mehr Hidden Layers und Neuronen pro Schicht, desto flexibler ist die interne Repräsentation des Netzwerkes. Gleichzeitig steigt jedoch die Gefahr eines Overfittings und die Trainingsdauer.

\paragraph{Training und das Problem schwindender Gradienten:}\label{par:training-vanishing-grads} Die Anzahl der Neuronen und deren Anordnung bleibt beim Training statisch. Das Modell vergrößert sich also nicht dynamisch während des Trainings, wie beispielsweise bei Decision Trees. Künstliche Neuronale Netzwerke werden beim Supervised Learning typischerweise über das Gradientenabstiegsverfahren anhand einer definierten Kostenfunktion trainiert. Dazu werden die Gewichtungen der Neuronen iterativ in Abhängigkeit von ihrem individuellen Fehler angepasst. Der erste Schritt des Trainingsprozesses ist die Inferenz einer Vorhersage auf Eingangsdaten. Anschließend wird der Fehler zum erwarteten Label berechnet. Der Fehler wird in entgegengesetzter Richtung durch das Neuronale Netzwerk zurückgeführt (\textit{Error Backpropagation}), wobei die Gewichtungen in Richtung des absteigenden Gradienten der Kostenfunktion angepasst werden. Die Berechnungsoperationen der Neuronen werden rückwärts durchgeführt, die Aktivierungsfunktion ist also stets das erste Glied bei der Berechnung des Gradienten. Da die Berechnung des Gradienten durch die (partiellen) Ableitungen der Kostenfunktion durchgeführt wird, muss die Aktivierungsfunktion bei der Error Backpropagation differenzierbar sein. Die rückwärts gerichtete Berechnung der individuellen Fehler ist durch ein weiteres Problem geprägt. Sowohl bei der sigmoidalen Aktivierungsfunktion als auch bei der Aktivierungsfunktion ReLU resultieren Skalarprodukte $x < 0$ in sehr kleinen Werten $f^{\prime}(x)\approx 0$ der ersten Ableitung. Auch wegen des inhärenten numerischen Fehlers von Fließkommazahlen führt dies dazu, dass die Gewichtungen des Neurons nicht sinnvoll angepasst werden können, aufgrund der resultierenden Unschärfe in der Abstiegsrichtung des Gradienten. Das Neuron kann auf diese Weise \enquote{absterben}\cite[S. 21]{werner_kontinuierliche_2020}. \cite{werner_kontinuierliche_2020} nutzt daher eine Abwandlung der ReLU-Aktivierungsfunktion, Leaky ReLU, welche negative Eingabewerte mit einem Faktor $a$ skaliert. Dies soll die sonst \enquote{sterbenden} Neuronen wieder aktivieren, wenn auch nur mit einem sehr kleinen Faktor $a \approx 0.01$.

\subsubsection{Recurrent Neural Networks}

In der vorigen Sektion wurden Neuronen als Grundbaustein neuronaler Netzwerke und ein Feed-Forward-Network, wie es \cite{matusek_anwendung_2019} anwendet, gezeigt. Solche Netzwerke sind bereits in der Lage, komplexe Klassifikationen von Eingabedaten durchzuführen und viele weitere Anwendungsfälle zu bedienen. In Abhängigkeit von der Art der Aufgabe (Verkehrsmittelklassifikation) und der Struktur der Eingabedaten (Zeitliniendaten) können jedoch auch spezialisierte neuronale Architekturen gewählt werden. \textit{Recurrent Neural Networks} (RNNs) sind auf die Analyse (und die Vorhersage) von Zeitliniendaten spezialisiert\cite[S. 385]{geron_praxiseinstieg_2018}. Hierzu werden die Neuronen zusätzlich innerhalb einer Schicht miteinander verknüpft.

% Werner: S. 34, Geron: S. 389

\begin{figure}[H]
\includegraphics[width=\linewidth, bb=0 0 473 185]{rnn.pdf}
\caption{Ein einschichtiges RNN mit LSTM-Neuronen.}\label{fig:r}
\end{figure}

% Regularisierung

\subsubsection{Convolutional Neural Networks}

% Regularisierung

% energie- und speicherverbrauch
% portierung: quantisierung, ...
% verwandte arbeiten analysieren
% technologien: coreml(tools), tensorflow lite, ...
