
@book{sosnovshchenko_machine_2018,
	title = {Machine {Learning} with {Swift}: {Artificial} {Intelligence} for {iOS}},
	isbn = {978-1-78712-352-6},
	shorttitle = {Machine {Learning} with {Swift}},
	abstract = {Leverage the power of machine learning and Swift programming to build intelligent iOS applications with easeKey FeaturesImplement effective machine learning solutions for your iOS applicationsUse Swift and Core ML to build and deploy popular machine learning modelsDevelop neural networks for natural language processing and computer visionBook DescriptionMachine learning as a field promises to bring increased intelligence to the software by helping us learn and analyse information efficiently and discover certain patterns that humans cannot. This book will be your guide as you embark on an exciting journey in machine learning using the popular Swift language. We’ll start with machine learning basics in the first part of the book to develop a lasting intuition about fundamental machine learning concepts. We explore various supervised and unsupervised statistical learning techniques and how to implement them in Swift, while the third section walks you through deep learning techniques with the help of typical real-world cases. In the last section, we will dive into some hard core topics such as model compression, GPU acceleration and provide some recommendations to avoid common mistakes during machine learning application development. By the end of the book, you'll be able to develop intelligent applications written in Swift that can learn for themselves.What you will learnLearn rapid model prototyping with Python and SwiftDeploy pre-trained models to iOS using Core MLFind hidden patterns in the data using unsupervised learningGet a deeper understanding of the clustering techniquesLearn modern compact architectures of neural networks for iOS devicesTrain neural networks for image processing and natural language processingWho this book is foriOS developers who wish to create smarter iOS applications using the power of machine learning will find this book to be useful. This book will also benefit data science professionals who are interested in performing machine learning on mobile devices. Familiarity with Swift programming is all you need to get started with this book.},
	language = {en},
	publisher = {Packt Publishing Ltd},
	author = {Sosnovshchenko, Oleksandr and Baiev, Oleksandr},
	month = feb,
	year = {2018},
	note = {Google-Books-ID: lOpODwAAQBAJ},
	keywords = {Computers / Intelligence (AI) \& Semantics, Computers / Neural Networks, Computers / Operating Systems / Apple (Mac OS \& iOS)}
}

@book{mckinney_datenanalyse_2018,
	title = {Datenanalyse mit {Python}: {Auswertung} von {Daten} mit {Pandas}, {NumPy} und {IPython}},
	isbn = {978-3-96010-214-4},
	shorttitle = {Datenanalyse mit {Python}},
	abstract = {Erfahren Sie alles über das Manipulieren, Bereinigen, Verarbeiten und Aufbereiten von Datensätzen mit Python: Aktualisiert auf Python 3.6, zeigt Ihnen dieses konsequent praxisbezogene Buch anhand konkreter Fallbeispiele, wie Sie eine Vielzahl von typischen Datenanalyse-Problemen effektiv lösen. Gleichzeitig lernen Sie die neuesten Versionen von pandas, NumPy, IPython und Jupyter kennen. Geschrieben von Wes McKinney, dem Begründer des pandas-Projekts, bietet Datenanalyse mit Python einen praktischen Einstieg in die Data-Science-Tools von Python. Das Buch eignet sich sowohl für Datenanalysten, für die Python Neuland ist, als auch für Python-Programmierer, die sich in Data Science und Scientific Computing einarbeiten wollen. Daten und zugehöriges Material des Buchs sind auf GitHub verfügbar. Aus dem Inhalt:  Nutzen Sie die IPython-Shell und Jupyter Notebook für das explorative Computing Lernen Sie Grundfunktionen und fortgeschrittene Features von NumPy kennen Setzen Sie die Datenanalyse-Tools der pandasBibliothek ein Verwenden Sie flexible Werkzeuge zum Laden, Bereinigen, Transformieren, Zusammenführen und Umformen von Daten Erstellen Sie interformative Visualisierungen mit matplotlib Wenden Sie die GroupBy-Mechanismen von pandas an, um Datensätzen zurechtzuschneiden, umzugestalten und zusammenzufassen Analysieren und manipulieren Sie verschiedenste Zeitreihen-Daten  Für diese aktualisierte 2. Auflage wurde der gesamte Code an Python 3.6 und die neuesten Versionen der pandas-Bibliothek angepasst. Neu in dieser Auflage: Informationen zu fortgeschrittenen pandas-Tools sowie eine kurze Einführung in statsmodels und scikit-learn.},
	language = {de},
	publisher = {O'Reilly},
	author = {McKinney, Wes},
	month = oct,
	year = {2018},
	note = {Google-Books-ID: d9N3DwAAQBAJ},
	keywords = {Computers / Databases / Data Mining, Computers / Programming Languages / Python}
}

@book{geron_praxiseinstieg_2018,
	title = {Praxiseinstieg {Machine} {Learning} mit {Scikit}-{Learn} und {TensorFlow}: {Konzepte}, {Tools} und {Techniken} für intelligente {Systeme}},
	isbn = {978-3-96010-114-7},
	shorttitle = {Praxiseinstieg {Machine} {Learning} mit {Scikit}-{Learn} und {TensorFlow}},
	abstract = {Durchbrüche beim Deep Learning haben das maschinelle Lernen in den letzten Jahren eindrucksvoll vorangebracht. Inzwischen können sogar Programmierer, die kaum etwas über diese Technologie wissen, mit einfachen, effizienten Werkzeugen Machine-Learning-Programme implementieren. Dieses praxisorientierte Buch zeigt Ihnen wie. Mit konkreten Beispielen, einem Minimum an Theorie und zwei unmittelbar anwendbaren Python-Frameworks – Scikit-Learn und TensorFlow – verhilft Ihnen der Autor Aurélien Géron zu einem intuitiven Verständnis der Konzepte und Tools für das Entwickeln intelligenter Systeme. Sie lernen eine Vielzahl von Techniken kennen, beginnend mit einfacher linearer Regression bis hin zu neuronalen Netzen. Übungen zu jedem Kapitel helfen Ihnen, das Gelernte in die Praxis umzusetzen. Sie benötigen lediglich etwas Programmiererfahrung, um direkt zu starten. - Entdecken Sie Machine Learning, insbesondere neuronale Netze und das Deep Learning - Verwenden Sie Scikit-Learn, um ein Machine-Learning-Beispielprojekt vom Anfang bis zum Ende nachzuvollziehen - Erkunden Sie verschiedene trainierbare Modelle, darunter Support Vector Machines, Entscheidungsbäume, Random Forests und Ensemble-Methoden - Nutzen Sie die Bibliothek TensorFlow, um neuronale Netze zu erstellen und zu trainieren - Lernen Sie Architekturen neuronaler Netze kennen, darunter Convolutional Nets, Recurrent Nets und Deep Reinforcement Learning - Eignen Sie sich Techniken zum Trainieren und Skalieren von neuronalen Netzen an - Wenden Sie Codebeispiele an, ohne exzessiv die Theorie von Machine Learning oder die Algorithmik durcharbeiten zu müssen},
	language = {de},
	publisher = {O'Reilly},
	author = {Géron, Aurélien},
	month = jan,
	year = {2018},
	note = {Google-Books-ID: Qq72DwAAQBAJ},
	keywords = {Computers / Databases / Data Mining}
}

@article{jahangiri_applying_2015,
	title = {Applying {Machine} {Learning} {Techniques} to {Transportation} {Mode} {Recognition} {Using} {Mobile} {Phone} {Sensor} {Data}},
	volume = {16},
	issn = {1558-0016},
	doi = {10.1109/TITS.2015.2405759},
	abstract = {This paper adopts different supervised learning methods from the field of machine learning to develop multiclass classifiers that identify the transportation mode, including driving a car, riding a bicycle, riding a bus, walking, and running. Methods that were considered include K-nearest neighbor, support vector machines (SVMs), and tree-based models that comprise a single decision tree, bagging, and random forest (RF) methods. For training and validating purposes, data were obtained from smartphone sensors, including accelerometer, gyroscope, and rotation vector sensors. K-fold cross-validation as well as out-of-bag error was used for model selection and validation purposes. Several features were created from which a subset was identified through the minimum redundancy maximum relevance method. Data obtained from the smartphone sensors were found to provide important information to distinguish between transportation modes. The performance of different methods was evaluated and compared. The RF and SVM methods were found to produce the best performance. Furthermore, an effort was made to develop a new additional feature that entails creating a combination of other features by adopting a simulated annealing algorithm and a random forest method.},
	number = {5},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Jahangiri, A. and Rakha, H. A.},
	month = oct,
	year = {2015},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Accelerometers, Cellular phone sensor data, Data models, decision tree, decision trees, feature selection, Global Positioning System, Gyroscopes, intelligent transportation systems, k-nearest neighbor, Kernel, learning (artificial intelligence), machine learning algorithms, machine learning technique, model selection, multiclass classifier, pattern classification, random forest method, RF method, simulated annealing, simulated annealing algorithm, smart phone sensor data, smart phones, supervised learning method, support vector machine, support vector machines, Support vector machines, SVM, Transportation, transportation mode recognition, tree-based model},
	pages = {2406--2417},
	file = {IEEE Xplore Full Text PDF:/Users/philippmatthes/Zotero/storage/LWXGYU74/Jahangiri und Rakha - 2015 - Applying Machine Learning Techniques to Transporta.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/philippmatthes/Zotero/storage/EL8GWPK8/7063936.html:text/html}
}

@article{stojanov_continuous_2020,
	title = {Continuous segmentation of recognized {Transport} {Modes} by using {Convolutional} {Neural} {Networks}},
	language = {en},
	author = {Stojanov, Viktor},
	month = aug,
	year = {2020},
	pages = {114},
	file = {Stojanov - Continuous segmentation of recognized Transport Mo.pdf:/Users/philippmatthes/Zotero/storage/4JI96HAU/Stojanov - Continuous segmentation of recognized Transport Mo.pdf:application/pdf}
}

@article{matusek_anwendung_2019,
	title = {Anwendung von {Deep}-{Learning} zur {Optimierung} der {Datenvorverarbeitung} von {Sensorrohdaten} im {Movebis}-{Projekt}},
	language = {de},
	author = {Matusek, Daniel},
	month = sep,
	year = {2019},
	pages = {130},
	file = {Matusek - Anwendung von Deep-Learning zur Optimierung der Da.pdf:/Users/philippmatthes/Zotero/storage/3SJGNPS6/Matusek - Anwendung von Deep-Learning zur Optimierung der Da.pdf:application/pdf}
}

@article{werner_kontinuierliche_2020,
	title = {Kontinuierliche {Segmentbildung} erkannter {Verkehrsmittel} durch {Anwendung} rekurrenter neuronaler {Netze}},
	language = {de},
	author = {Werner, Elias},
	month = aug,
	year = {2020},
	pages = {88},
	file = {Werner - Kontinuierliche Segmentbildung erkannter Verkehrsm.pdf:/Users/philippmatthes/Zotero/storage/R3HDN5AU/Werner - Kontinuierliche Segmentbildung erkannter Verkehrsm.pdf:application/pdf}
}

@article{ravi_deep_2017,
	title = {A {Deep} {Learning} {Approach} to on-{Node} {Sensor} {Data} {Analytics} for {Mobile} or {Wearable} {Devices}},
	volume = {21},
	issn = {2168-2208},
	doi = {10.1109/JBHI.2016.2633287},
	abstract = {The increasing popularity of wearable devices in recent years means that a diverse range of physiological and functional data can now be captured continuously for applications in sports, wellbeing, and healthcare. This wealth of information requires efficient methods of classification and analysis where deep learning is a promising technique for large-scale data analytics. While deep learning has been successful in implementations that utilize high-performance computing platforms, its use on low-power wearable devices is limited by resource constraints. In this paper, we propose a deep learning methodology, which combines features learned from inertial sensor data together with complementary information from a set of shallow features to enable accurate and real-time activity classification. The design of this combined method aims to overcome some of the limitations present in a typical deep learning framework where on-node computation is required. To optimize the proposed method for real-time on-node computation, spectral domain preprocessing is used before the data are passed onto the deep learning framework. The classification accuracy of our proposed deep learning approach is evaluated against state-of-the-art methods using both laboratory and real world activity datasets. Our results show the validity of the approach on different human activity datasets, outperforming other methods, including the two methods used within our combined pipeline. We also demonstrate that the computation times for the proposed method are consistent with the constraints of real-time on-node processing on smartphones and a wearable sensor platform.},
	number = {1},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Ravì, D. and Wong, C. and Lo, B. and Yang, G.},
	month = jan,
	year = {2017},
	note = {Conference Name: IEEE Journal of Biomedical and Health Informatics},
	keywords = {ActiveMiles, data analysis, deep learning, deep learning approach, Feature extraction, HAR, health care, Human Activities, Human Activity Recognition, Human Activity Recognition (HAR), Humans, inertial sensor, Internet of Things, Internet-of-Things, Internet-of-Things (IoT), learning (artificial intelligence), low-power devices, Machine learning, Machine Learning, Monitoring, Ambulatory, Neural Networks (Computer), on-node sensor data analytics, Performance evaluation, Pipelines, Real-time systems, Signal Processing, Computer-Assisted, smartphones, spectral domain preprocessing, Spectrogram, Time-frequency analysis, wearable, wearable computers, wearable devices},
	pages = {56--64},
	file = {IEEE Xplore Abstract Record:/Users/philippmatthes/Zotero/storage/AUQM9MBR/7797232.html:text/html;Eingereichte Version:/Users/philippmatthes/Zotero/storage/29WFGL9Q/Ravì et al. - 2017 - A Deep Learning Approach to on-Node Sensor Data An.pdf:application/pdf}
}

@inproceedings{ravi_deep_2016,
	title = {Deep learning for human activity recognition: {A} resource efficient implementation on low-power devices},
	shorttitle = {Deep learning for human activity recognition},
	doi = {10.1109/BSN.2016.7516235},
	abstract = {Human Activity Recognition provides valuable contextual information for wellbeing, healthcare, and sport applications. Over the past decades, many machine learning approaches have been proposed to identify activities from inertial sensor data for specific applications. Most methods, however, are designed for offline processing rather than processing on the sensor node. In this paper, a human activity recognition technique based on a deep learning methodology is designed to enable accurate and real-time classification for low-power wearable devices. To obtain invariance against changes in sensor orientation, sensor placement, and in sensor acquisition rates, we design a feature generation process that is applied to the spectral domain of the inertial data. Specifically, the proposed method uses sums of temporal convolutions of the transformed input. Accuracy of the proposed approach is evaluated against the current state-of-the-art methods using both laboratory and real world activity datasets. A systematic analysis of the feature generation parameters and a comparison of activity recognition computation times on mobile devices and sensor nodes are also presented.},
	booktitle = {2016 {IEEE} 13th {International} {Conference} on {Wearable} and {Implantable} {Body} {Sensor} {Networks} ({BSN})},
	author = {Ravi, D. and Wong, C. and Lo, B. and Yang, G.},
	month = jun,
	year = {2016},
	note = {ISSN: 2376-8894},
	keywords = {ActiveMiles, contextual information, convolution, Convolution, Data mining, deep learning, Deep Learning, feature extraction, Feature extraction, feature generation, HAR, human activity recognition, image recognition, inertial sensor data, learning (artificial intelligence), Low-Power Devices, low-power wearable devices, machine learning, Machine learning, mobile devices, offline processing, resource efficient implementation, sensor acquisition rates, sensor nodes, sensor placement, spectral domain, Spectrogram, temporal convolutions, Time-frequency analysis},
	pages = {71--76},
	file = {IEEE Xplore Abstract Record:/Users/philippmatthes/Zotero/storage/W9V29SU4/7516235.html:text/html;Eingereichte Version:/Users/philippmatthes/Zotero/storage/C6RWKQCW/Ravi et al. - 2016 - Deep learning for human activity recognition A re.pdf:application/pdf}
}

@inproceedings{zeng_convolutional_2014,
	title = {Convolutional {Neural} {Networks} for human activity recognition using mobile sensors},
	doi = {10.4108/icst.mobicase.2014.257786},
	abstract = {A variety of real-life mobile sensing applications are becoming available, especially in the life-logging, fitness tracking and health monitoring domains. These applications use mobile sensors embedded in smart phones to recognize human activities in order to get a better understanding of human behavior. While progress has been made, human activity recognition remains a challenging task. This is partly due to the broad range of human activities as well as the rich variation in how a given activity can be performed. Using features that clearly separate between activities is crucial. In this paper, we propose an approach to automatically extract discriminative features for activity recognition. Specifically, we develop a method based on Convolutional Neural Networks (CNN), which can capture local dependency and scale invariance of a signal as it has been shown in speech recognition and image recognition domains. In addition, a modified weight sharing technique, called partial weight sharing, is proposed and applied to accelerometer signals to get further improvements. The experimental results on three public datasets, Skoda (assembly line activities), Opportunity (activities in kitchen), Actitracker (jogging, walking, etc.), indicate that our novel CNN-based approach is practical and achieves higher accuracy than existing state-of-the-art methods.},
	booktitle = {6th {International} {Conference} on {Mobile} {Computing}, {Applications} and {Services}},
	author = {Zeng, M. and Nguyen, L. T. and Yu, B. and Mengshoel, O. J. and Zhu, J. and Wu, P. and Zhang, J.},
	month = nov,
	year = {2014},
	keywords = {Activity Recognition, behavioural sciences computing, CNN, Convolution, Convolutional Neural Network, convolutional neural networks, Data models, Deep Learning, Feature extraction, fitness tracking, health care, health monitoring, human activity recognition, human behavior, image recognition, Image recognition, life-logging, mobile computing, mobile sensors, neural nets, Neural networks, partial weight sharing, Principal component analysis, real-life mobile sensing applications, smart phones, speech recognition, Training},
	pages = {197--205},
	file = {Volltext:/Users/philippmatthes/Zotero/storage/WK8EFPNE/Zeng et al. - 2014 - Convolutional Neural Networks for human activity r.pdf:application/pdf}
}

@inproceedings{chen_deep_2015,
	title = {A {Deep} {Learning} {Approach} to {Human} {Activity} {Recognition} {Based} on {Single} {Accelerometer}},
	doi = {10.1109/SMC.2015.263},
	abstract = {In this paper, we propose an acceleration-based human activity recognition method using popular deep architecture, Convolution Neural Network (CNN). In particular, we construct a CNN model and modify the convolution kernel to adapt the characteristics of tri-axial acceleration signals. Also, for comparison, we use some widely used methods to accomplish the recognition task on the same dataset. The large dataset we constructed consists of 31688 samples from eight typical activities. The experiment results show that the CNN works well, which can reach an average accuracy of 93.8\% without any feature extraction methods.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}},
	author = {Chen, Y. and Xue, Y.},
	month = oct,
	year = {2015},
	keywords = {Acceleration, acceleration-based human activity recognition method, accelerometers, CNN model, Convolution, convolution kernel, convolution neural network, deep architecture, deep learning approach, Discrete cosine transforms, feature extraction, Feature extraction, feature extraction method, gesture recognition, human activity recognition, Kernel, learning (artificial intelligence), Legged locomotion, neural nets, popular deep architecture, recognition task, single accelerometer, Training, tri-axial acceleration signal},
	pages = {1488--1492}
}

@article{abu_alsheikh_deep_2015,
	title = {Deep {Activity} {Recognition} {Models} with {Triaxial} {Accelerometers}},
	volume = {1511},
	url = {http://adsabs.harvard.edu/abs/2015arXiv151104664A},
	abstract = {Despite the widespread installation of accelerometers in almost all mobile phones and wearable devices, activity recognition using
accelerometers is still immature due to the poor recognition accuracy of existing recognition methods and the scarcity of labeled training data. We consider the problem of human activity recognition using triaxial accelerometers and deep learning paradigms. This paper shows that deep activity recognition models (a) provide better recognition accuracy of human activities, (b) avoid the expensive design of handcrafted features in existing systems, and (c) utilize the massive unlabeled acceleration samples for unsupervised feature extraction. Moreover, a hybrid approach of deep learning and hidden Markov models (DL-HMM) is presented for sequential activity recognition. This hybrid approach integrates the hierarchical representations of deep activity recognition models with the stochastic modeling of temporal sequences in the hidden Markov models. We show substantial recognition improvement on real world datasets over state-of-the-art methods of human activity recognition using triaxial accelerometers.},
	urldate = {2021-02-27},
	journal = {arXiv e-prints},
	author = {Abu Alsheikh, Mohammad and Selim, Ahmed and Niyato, Dusit and Doyle, Linda and Lin, Shaowei and Tan, Hwee-Pink},
	month = nov,
	year = {2015},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	pages = {arXiv:1511.04664},
	file = {Full Text PDF:/Users/philippmatthes/Zotero/storage/T9RRHCQK/Abu Alsheikh et al. - 2015 - Deep Activity Recognition Models with Triaxial Acc.pdf:application/pdf}
}

@article{bulling_tutorial_2014,
	title = {A tutorial on human activity recognition using body-worn inertial sensors},
	volume = {46},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/2499621},
	doi = {10.1145/2499621},
	abstract = {The last 20 years have seen ever-increasing research activity in the field of human activity recognition. With activity recognition having considerably matured, so has the number of challenges in designing, implementing, and evaluating activity recognition systems. This tutorial aims to provide a comprehensive hands-on introduction for newcomers to the field of human activity recognition. It specifically focuses on activity recognition using on-body inertial sensors. We first discuss the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. We then describe the concept of an Activity Recognition Chain (ARC) as a general-purpose framework for designing and evaluating activity recognition systems. We detail each component of the framework, provide references to related research, and introduce the best practice methods developed by the activity recognition research community. We conclude with the educational example problem of recognizing different hand gestures from inertial sensors attached to the upper and lower arm. We illustrate how each component of this framework can be implemented for this specific activity recognition problem and demonstrate how different implementations compare and how they impact overall recognition performance.},
	number = {3},
	urldate = {2021-02-27},
	journal = {ACM Computing Surveys},
	author = {Bulling, Andreas and Blanke, Ulf and Schiele, Bernt},
	month = jan,
	year = {2014},
	keywords = {Activity recognition, Activity Recognition Chain (ARC), gesture recognition, on-body inertial sensors},
	pages = {33:1--33:33}
}

@article{kwapisz_activity_2011,
	title = {Activity recognition using cell phone accelerometers},
	volume = {12},
	issn = {1931-0145},
	url = {https://doi.org/10.1145/1964897.1964918},
	doi = {10.1145/1964897.1964918},
	abstract = {Mobile devices are becoming increasingly sophisticated and the latest generation of smart cell phones now incorporates many diverse and powerful sensors. These sensors include GPS sensors, vision sensors (i.e., cameras), audio sensors (i.e., microphones), light sensors, temperature sensors, direction sensors (i.e., magnetic compasses), and acceleration sensors (i.e., accelerometers). The availability of these sensors in mass-marketed communication devices creates exciting new opportunities for data mining and data mining applications. In this paper we describe and evaluate a system that uses phone-based accelerometers to perform activity recognition, a task which involves identifying the physical activity a user is performing. To implement our system we collected labeled accelerometer data from twenty-nine users as they performed daily activities such as walking, jogging, climbing stairs, sitting, and standing, and then aggregated this time series data into examples that summarize the user activity over 10- second intervals. We then used the resulting training data to induce a predictive model for activity recognition. This work is significant because the activity recognition model permits us to gain useful knowledge about the habits of millions of users passively---just by having them carry cell phones in their pockets. Our work has a wide range of applications, including automatic customization of the mobile device's behavior based upon a user's activity (e.g., sending calls directly to voicemail if a user is jogging) and generating a daily/weekly activity profile to determine if a user (perhaps an obese child) is performing a healthy amount of exercise.},
	number = {2},
	urldate = {2021-02-27},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Kwapisz, Jennifer R. and Weiss, Gary M. and Moore, Samuel A.},
	month = mar,
	year = {2011},
	keywords = {accelerometer, activity recognition, cell phone, induction, sensor mining, sensors},
	pages = {74--82}
}

@inproceedings{nurhanim_classification_2017,
	title = {Classification of human activity based on smartphone inertial sensor using support vector machine},
	doi = {10.1109/ROMA.2017.8231736},
	abstract = {The aim of this paper is to compare the performance of different kernel of classification support vector machine classification for classifying the physical daily living activities. Thirty subjects from a database performed activities such as walking, sitting, standing, laying, walking upstairs and downstairs. Inertial sensors signals ((accelerometer, gyroscope and magnetometer) from the smartphone are used to measure the human movements for each activity. The inertial sensor data were processed using signal processing method with several features of time domain and frequency domain. Multiclass support vector machine polynomial kernel (MC-SVM-Polynomial) and multiclass support vector machine Linear Kernel (MC-SVM-Linear) using One Versus All (OVA) methods were employed. These classification methods are assessed using the performance criteria such as precision percentage, recall percentage and correct accuracy classification rate percentage using 10-fold cross validation procedure. The results show that MC-SVM-Polynomial produces the best result with 98.57\% compared to MC-SVM-Linear with 97.04\% based on correct accuracy classification rate.},
	booktitle = {2017 {IEEE} 3rd {International} {Symposium} in {Robotics} and {Manufacturing} {Automation} ({ROMA})},
	author = {Nurhanim, K. and Elamvazuthi, I. and Izhar, L. I. and Ganesan, T.},
	month = sep,
	year = {2017},
	keywords = {Accelerometer, Activity recognition, Classification, feature extraction, Feature Extraction, frequency domain, Frequency-domain analysis, gyroscope, human activity classification, Human Activity Recognition, human movements, Inertial sensor, inertial sensor data, inertial sensors signals, Kernel, Legged locomotion, magnetometer, MC-SVM-Linear, MC-SVM-Polynomial, multiclass support vector machine Linear Kernel, multiclass support vector machine polynomial kernel, One Versus All method, pattern classification, Performance evaluation, physical daily living activities, polynomials, Robot sensing systems, signal classification, signal processing, smart phones, smartphone inertial sensor, support vector machine classification, support vector machines, Support vector machines, time domain},
	pages = {1--5},
	file = {IEEE Xplore Abstract Record:/Users/philippmatthes/Zotero/storage/8KKC5F7Q/8231736.html:text/html}
}

@misc{ken_taylor_activity_2011,
	title = {Activity classification with smart phones for sports activities {\textbar} {Elsevier} {Enhanced} {Reader}},
	url = {https://reader.elsevier.com/reader/sd/pii/S187770581101023X?token=52A037BAA5646FEF19ADB784CBC7202AF2EC555B64F6297DBD6108BAC6A1721DA85AE0A336A430885DEBB30B49C19AFA},
	language = {en},
	urldate = {2021-02-27},
	author = {Ken Taylor and {Umran A. Abdulla} and {Richard J. N. Helmer} and {Jungoo Lee} and {Ian Blanchonette}},
	year = {2011},
	doi = {10.1016/j.proeng.2011.05.109},
	file = {Snapshot:/Users/philippmatthes/Zotero/storage/C86WMTK2/S187770581101023X.html:text/html;Volltext:/Users/philippmatthes/Zotero/storage/REPEF99K/Activity classification with smart phones for spor.pdf:application/pdf}
}

@article{martin_activity_2013,
	title = {Activity logging using lightweight classification techniques in mobile devices},
	volume = {17},
	issn = {1617-4917},
	url = {https://doi.org/10.1007/s00779-012-0515-4},
	doi = {10.1007/s00779-012-0515-4},
	abstract = {Automated activity recognition enables a wide variety of applications related to child and elderly care, disease diagnosis and treatment, personal health or sports training, for which it is key to seamlessly determine and log the user’s motion. This work focuses on exploring the use of smartphones to perform activity recognition without interfering in the user’s lifestyle. Thus, we study how to build an activity recognition system to be continuously executed in a mobile device in background mode. The system relies on device’s sensing, processing and storing capabilities to estimate significant movements/postures (walking at different paces—slow, normal, rush, running, sitting, standing). In order to evaluate the combinations of sensors, features and algorithms, an activity dataset of 16 individuals has been gathered. The performance of a set of lightweight classifiers (Naïve Bayes, Decision Table and Decision Tree) working on different sensor data has been fully evaluated and optimized in terms of accuracy, computational cost and memory fingerprint. Results have pointed out that a priori information on the relative position of the mobile device with respect to the user’s body enhances the estimation accuracy. Results show that computational low-cost Decision Tables using the best set of features among mean and variance and considering all the sensors (acceleration, gravity, linear acceleration, magnetometer, gyroscope) may be enough to get an activity estimation accuracy of around 88 \% (78 \% is the accuracy of the Naïve Bayes algorithm with the same characteristics used as a baseline). To demonstrate its applicability, the activity recognition system has been used to enable a mobile application to promote active lifestyles.},
	language = {en},
	number = {4},
	urldate = {2021-02-27},
	journal = {Personal and Ubiquitous Computing},
	author = {Martín, Henar and Bernardos, Ana M. and Iglesias, Josué and Casar, José R.},
	month = apr,
	year = {2013},
	pages = {675--695},
	file = {Springer Full Text PDF:/Users/philippmatthes/Zotero/storage/HTXVGDB4/Martín et al. - 2013 - Activity logging using lightweight classification .pdf:application/pdf}
}

@article{mairittha_-device_2019,
	title = {On-{Device} {Deep} {Learning} {Inference} for {Efficient} {Activity} {Data} {Collection}},
	volume = {19},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/19/15/3434},
	doi = {10.3390/s19153434},
	abstract = {Labeling activity data is a central part of the design and evaluation of human activity recognition systems. The performance of the systems greatly depends on the quantity and \&ldquo;quality\&rdquo; of annotations; therefore, it is inevitable to rely on users and to keep them motivated to provide activity labels. While mobile and embedded devices are increasingly using deep learning models to infer user context, we propose to exploit on-device deep learning inference using a long short-term memory (LSTM)-based method to alleviate the labeling effort and ground truth data collection in activity recognition systems using smartphone sensors. The novel idea behind this is that estimated activities are used as feedback for motivating users to collect accurate activity labels. To enable us to perform evaluations, we conduct the experiments with two conditional methods. We compare the proposed method showing estimated activities using on-device deep learning inference with the traditional method showing sentences without estimated activities through smartphone notifications. By evaluating with the dataset gathered, the results show our proposed method has improvements in both data quality (i.e., the performance of a classification model) and data quantity (i.e., the number of data collected) that reflect our method could improve activity data collection, which can enhance human activity recognition systems. We discuss the results, limitations, challenges, and implications for on-device deep learning inference that support activity data collection. Also, we publish the preliminary dataset collected to the research community for activity recognition.},
	language = {en},
	number = {15},
	urldate = {2021-02-27},
	journal = {Sensors},
	author = {Mairittha, Nattaya and Mairittha, Tittaya and Inoue, Sozo},
	month = jan,
	year = {2019},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {activity recognition, data collection, on-device deep learning inference, smartphone sensors, user feedback},
	pages = {3434},
	file = {Snapshot:/Users/philippmatthes/Zotero/storage/SPYW8GMZ/3434.html:text/html;Full Text PDF:/Users/philippmatthes/Zotero/storage/WDDNZLER/Mairittha et al. - 2019 - On-Device Deep Learning Inference for Efficient Ac.pdf:application/pdf}
}

@article{mairittha_-device_2021,
	title = {On-{Device} {Deep} {Personalization} for {Robust} {Activity} {Data} {Collection}},
	volume = {21},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/21/1/41},
	doi = {10.3390/s21010041},
	abstract = {One of the biggest challenges of activity data collection is the need to rely on users and keep them engaged to continually provide labels. Recent breakthroughs in mobile platforms have proven effective in bringing deep neural networks powered intelligence into mobile devices. This study proposes a novel on-device personalization for data labeling for an activity recognition system using mobile sensing. The key idea behind this system is that estimated activities personalized for a specific individual user can be used as feedback to motivate user contribution and improve data labeling quality. First, we exploited fine-tuning using a Deep Recurrent Neural Network to address the lack of sufficient training data and minimize the need for training deep learning on mobile devices from scratch. Second, we utilized a model pruning technique to reduce the computation cost of on-device personalization without affecting the accuracy. Finally, we built a robust activity data labeling system by integrating the two techniques outlined above, allowing the mobile application to create a personalized experience for the user. To demonstrate the proposed model\&rsquo;s capability and feasibility, we developed and deployed the proposed system to realistic settings. For our experimental setup, we gathered more than 16,800 activity windows from 12 activity classes using smartphone sensors. We empirically evaluated the proposed quality by comparing it with a baseline using machine learning. Our results indicate that the proposed system effectively improved activity accuracy recognition for individual users and reduced cost and latency for inference for mobile devices. Based on our findings, we highlight critical and promising future research directions regarding the design of efficient activity data collection with on-device personalization.},
	language = {en},
	number = {1},
	urldate = {2021-02-27},
	journal = {Sensors},
	author = {Mairittha, Nattaya and Mairittha, Tittaya and Inoue, Sozo},
	month = jan,
	year = {2021},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {activity recognition, data collection, deep learning, fine-tuning, on-device personalization, smartphone sensors, user feedback},
	pages = {41},
	file = {Snapshot:/Users/philippmatthes/Zotero/storage/EDS25LFF/41.html:text/html;Full Text PDF:/Users/philippmatthes/Zotero/storage/6EDBKBQR/Mairittha et al. - 2021 - On-Device Deep Personalization for Robust Activity.pdf:application/pdf}
}

@article{li_deep_2020,
	title = {Deep {Transfer} {Learning} for {Time} {Series} {Data} {Based} on {Sensor} {Modality} {Classification}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/20/15/4271},
	doi = {10.3390/s20154271},
	abstract = {The scarcity of labelled time-series data can hinder a proper training of deep learning models. This is especially relevant for the growing field of ubiquitous computing, where data coming from wearable devices have to be analysed using pattern recognition techniques to provide meaningful applications. To address this problem, we propose a transfer learning method based on attributing sensor modality labels to a large amount of time-series data collected from various application fields. Using these data, our method firstly trains a Deep Neural Network (DNN) that can learn general characteristics of time-series data, then transfers it to another DNN designed to solve a specific target problem. In addition, we propose a general architecture that can adapt the transferred DNN regardless of the sensors used in the target field making our approach in particular suitable for multichannel data. We test our method for two ubiquitous computing problems\&mdash;Human Activity Recognition (HAR) and Emotion Recognition (ER)\&mdash;and compare it a baseline training the DNN without using transfer learning. For HAR, we also introduce a new dataset, Cognitive Village-MSBand (CogAge), which contains data for 61 atomic activities acquired from three wearable devices (smartphone, smartwatch, and smartglasses). Our results show that our transfer learning approach outperforms the baseline for both HAR and ER.},
	language = {en},
	number = {15},
	urldate = {2021-02-27},
	journal = {Sensors},
	author = {Li, Frédéric and Shirahama, Kimiaki and Nisar, Muhammad Adeel and Huang, Xinyu and Grzegorzek, Marcin},
	month = jan,
	year = {2020},
	note = {Number: 15
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {deep learning, emotion recognition, human activity recognition, time-series classification, transfer learning, wearable computing},
	pages = {4271},
	file = {Snapshot:/Users/philippmatthes/Zotero/storage/6LNS9DJX/4271.html:text/html;Full Text PDF:/Users/philippmatthes/Zotero/storage/W6QYZPFA/Li et al. - 2020 - Deep Transfer Learning for Time Series Data Based .pdf:application/pdf}
}

@inproceedings{mairittha_improving_2020,
	address = {New York, NY, USA},
	series = {{UbiComp}-{ISWC} '20},
	title = {Improving activity data collection with on-device personalization using fine-tuning},
	isbn = {978-1-4503-8076-8},
	url = {https://doi.org/10.1145/3410530.3414370},
	doi = {10.1145/3410530.3414370},
	abstract = {One of the biggest challenges of activity data collection is the unavoidability of relying on users and keep them engaged to provide labels consistently. Recent breakthroughs in mobile platforms have proven effective in bringing deep neural networks powered intelligence into mobile devices. In this study, we propose on-device personalization using fine-tuning convolutional neural networks as a mechanism in optimizing human effort in data labeling. First, we transfer the knowledge gained by on-cloud pre-training based on crowdsourced data to mobile devices. Second, we incrementally fine-tune a personalized model on every individual device using its locally accumulated input. Then, we utilize estimated activities customized according to the on-device model inference as feedback to motivate participants to improve data labeling. We conducted a verification study and gathered activity labels with smartphone sensors. Our preliminary evaluation results indicate that the proposed method outperformed the baseline method by approximately 8\% regarding accuracy recognition.},
	urldate = {2021-02-27},
	booktitle = {Adjunct {Proceedings} of the 2020 {ACM} {International} {Joint} {Conference} on {Pervasive} and {Ubiquitous} {Computing} and {Proceedings} of the 2020 {ACM} {International} {Symposium} on {Wearable} {Computers}},
	publisher = {Association for Computing Machinery},
	author = {Mairittha, Nattaya and Mairittha, Tittaya and Inoue, Sozo},
	month = sep,
	year = {2020},
	keywords = {activity recognition, data collection, fine-tuning, on-device deep learning},
	pages = {255--260}
}

@inproceedings{curukoglu_deep_2018,
	title = {Deep {Learning} on {Mobile} {Systems}},
	doi = {10.1109/ASYU.2018.8554039},
	abstract = {Training of deep learning methods which are widely utilized in intelligent systems requires powerful computers, however, they are also used on mobile systems. Hence, application programming interfaces providing execution of pre-trained models on mobile systems have been introduced. In this study, two interfaces running on Android systems are tested on 40 objects for both object detection and labelling. Morever, ease of installations, resource usages were also compared. According to the test results, labelling performance of the model provided by Tensorflow interface is higher than the model of MLKit.},
	booktitle = {2018 {Innovations} in {Intelligent} {Systems} and {Applications} {Conference} ({ASYU})},
	author = {Çürükoğlu, N. and Özyildirim, B. M.},
	month = oct,
	year = {2018},
	keywords = {android systems, application program interfaces, application programming interfaces, Computational modeling, Computer architecture, Deep Learning, deep learning methods, Google, intelligent systems, Labeling, learning (artificial intelligence), MLKit, mobile computing, mobile systems, Mobile Systems, object detection, Object detection, Tensorflow, tensorflow interface},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:/Users/philippmatthes/Zotero/storage/EXQZPMZ6/Çürükoğlu und Özyildirim - 2018 - Deep Learning on Mobile Systems.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/philippmatthes/Zotero/storage/ZMCU2EJ9/8554039.html:text/html}
}
